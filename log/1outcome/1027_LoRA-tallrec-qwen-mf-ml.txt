W1111 10:19:04.321911 33272 site-packages\torch\distributed\elastic\multiprocessing\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.
2025-11-11 10:19:04,355 [INFO] Building datasets...
2025-11-11 10:19:04,546 [INFO] Movie OOD datasets, max history length:10
2025-11-11 10:19:04,576 [INFO] Movie OOD datasets, max history length:10
2025-11-11 10:19:04,734 [INFO] Movie OOD datasets, max history length:10
2025-11-11 10:19:04,877 [INFO] 
=====  Running Parameters    =====
2025-11-11 10:19:04,877 [INFO] {
    "amp": true,
    "batch_size_eval": 64,
    "batch_size_train": 16,
    "device": "cuda",
    "dist_url": "env://",
    "distributed": false,
    "evaluate": false,
    "init_lr": 1e-05,
    "iters_per_epoch": 50,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 1000,
    "min_lr": 8e-05,
    "mode": "v2",
    "num_workers": 0,
    "output_dir": "Qwen/Qwen2.5-1.5rec_log/collm",
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "rec_pretrain",
    "test_splits": [
        "test",
        "valid"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "valid"
    ],
    "warmup_lr": 1e-05,
    "warmup_steps": 200,
    "weight_decay": 0.001,
    "world_size": 1
}
2025-11-11 10:19:04,877 [INFO] 
======  Dataset Attributes  ======
2025-11-11 10:19:04,877 [INFO] 
======== amazon_ood =======
2025-11-11 10:19:04,877 [INFO] {
    "build_info": {
        "storage": "D:\\Pycoding\\CoLLM-main\\CoLLM-main\\collm-datasets\\ml-1m\\ml-1m\\"
    },
    "data_type": "default",
    "path": "D:\\Pycoding\\CoLLM-main\\CoLLM-main\\collm-datasets\\ml-1m\\ml-1m\\"
}
2025-11-11 10:19:04,877 [INFO] 
======  Model Attributes  ======
2025-11-11 10:19:04,877 [INFO] {
    "ans_type": "v2",
    "arch": "mini_gpt4rec_v2",
    "end_sym": "###",
    "freeze_lora": false,
    "freeze_proj": true,
    "freeze_rec": true,
    "item_num": -100,
    "llama_model": "Qwen/Qwen2-1.5B",
    "lora_config": {
        "alpha": 16,
        "dropout": 0.05,
        "r": 8,
        "target_modules": [
            "q_proj",
            "v_proj"
        ],
        "use_lora": true
    },
    "max_txt_len": 1024,
    "model_type": "pretrain_vicuna",
    "proj_drop": 0,
    "proj_mid_times": 10,
    "proj_token_num": 1,
    "prompt_path": "prompts/tallrec_movie.txt",
    "prompt_template": "{}",
    "rec_config": {
        "embedding_size": 256,
        "item_num": 3256,
        "pretrained_path": "collm-trained-models/my-collm-trained-models/mf_0912_ml1m_oodv2_best_model_d256lr-0.001wd0.0001.pth",
        "user_num": 839
    },
    "user_num": -100
}
2025-11-11 10:19:04,891 [INFO] freeze rec encoder
`torch_dtype` is deprecated! Use `dtype` instead!
2025-11-11 10:19:05,510 [INFO] !!!! freeze llama_proj...
2025-11-11 10:19:06,576 [INFO] Start training
2025-11-11 10:19:06,583 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2025-11-11 10:19:06,583 [INFO] Loaded 33891 records for train split from the dataset.
2025-11-11 10:19:06,583 [INFO] Loaded 5200 records for valid split from the dataset.
2025-11-11 10:19:06,583 [INFO] Loaded 7331 records for test split from the dataset.
2025-11-11 10:19:06,589 [INFO] number of trainable parameters: 1089536
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\runners\runner_base.py:153: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()
2025-11-11 10:19:06,599 [INFO] Start training epoch 0, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:19:32,025 [INFO] Averaged stats: lr: 0.000010  loss: 5.378874
2025-11-11 10:19:32,026 [INFO] Evaluating on valid.
2025-11-11 10:21:38,089 [INFO] Averaged stats: loss: 5.037400  acc: 0.530297 ***auc: 0.506184222385522 ***uauc: 0.5280365103061108 ***u-nDCG: 0.8080459843123784
2025-11-11 10:21:38,095 [INFO] Saving checkpoint at epoch 0 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:21:38,527 [INFO] Start training
2025-11-11 10:21:38,532 [INFO] Start training epoch 1, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:22:03,798 [INFO] Averaged stats: lr: 0.000010  loss: 3.630992
2025-11-11 10:22:03,800 [INFO] Evaluating on valid.

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
binary_path: D:\Anaconda3\envs\minigpt4\lib\site-packages\bitsandbytes\cuda_setup\libbitsandbytes_cuda116.dll
CUDA SETUP: Loading binary D:\Anaconda3\envs\minigpt4\lib\site-packages\bitsandbytes\cuda_setup\libbitsandbytes_cuda116.dll...
Not using distributed mode
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\train data size: (33891, 7)
Movie OOD datasets, max history length: 10
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\valid_small data size: (5200, 7)
Movie OOD datasets, max history length: 10
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\test data size: (7331, 7)
Movie OOD datasets, max history length: 10
data dir: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\
正在计算全局流行度以进行偏见评估...
已计算 3087 个物品的流行度。总物品数为 3256。
正在将流行度数据注入评估任务...
runing MiniGPT4Rec_v2 ...... 
Loading Rec_model
### rec_encoder: MF
creat MF model, user num: 839 item num: 3256
successfully load the pretrained model......
freeze rec encoder
Loading Rec_model Done
Loading LLama model: Qwen/Qwen2-1.5B
Loading LLAMA Done
Setting Lora
Setting Lora Done
type: <class 'int'> 10
Load 4 training prompts
Prompt List: 
['#Question: A user has given high ratings to the following movies: <ItemTitleList>. Leverage the information to predict whether the user would enjoy the movie titled <TargetItemTitle>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Leverage the information to predict whether the user would enjoy the movie titled <TargetItemTitle>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Leverage the information to predict whether the user would enjoy the movie titled <TargetItemTitle>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Leverage the information to predict whether the user would enjoy the movie titled <TargetItemTitle>? Answer with "Yes" or "No". \\n#Answer:']
answer token ids: pos: 9454 neg ids: 2753
Prompt Pos Example 
#Question: A user has given high ratings to the following movies: <ItemTitleList>. Leverage the information to predict whether the user would enjoy the movie titled <TargetItemTitle>? Answer with "Yes" or "No". \n#Answer: Yes or No
llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight
2025-11-11 10:24:12,012 [INFO] Averaged stats: loss: 1.925984  acc: 0.530297 ***auc: 0.48663025138836524 ***uauc: 0.4923672389335247 ***u-nDCG: 0.7935622648927295
2025-11-11 10:24:12,018 [INFO] Start training
2025-11-11 10:24:12,025 [INFO] Start training epoch 2, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:24:36,847 [INFO] Averaged stats: lr: 0.000010  loss: 0.986421
2025-11-11 10:24:36,849 [INFO] Evaluating on valid.
2025-11-11 10:26:44,357 [INFO] Averaged stats: loss: 0.702084  acc: 0.477134 ***auc: 0.5105369652393812 ***uauc: 0.4709417006952556 ***u-nDCG: 0.7907475490533019
2025-11-11 10:26:44,363 [INFO] Saving checkpoint at epoch 2 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:26:44,835 [INFO] Start training
2025-11-11 10:26:44,843 [INFO] Start training epoch 3, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:27:09,735 [INFO] Averaged stats: lr: 0.000010  loss: 0.702662
2025-11-11 10:27:09,736 [INFO] Evaluating on valid.
2025-11-11 10:29:15,967 [INFO] Averaged stats: loss: 0.701706  acc: 0.473704 ***auc: 0.5140074886569135 ***uauc: 0.4836200374451069 ***u-nDCG: 0.7911732982329805
2025-11-11 10:29:15,973 [INFO] Saving checkpoint at epoch 3 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:29:16,445 [INFO] Start training
2025-11-11 10:29:16,451 [INFO] Start training epoch 4, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:29:41,323 [INFO] Averaged stats: lr: 0.000010  loss: 0.703101
2025-11-11 10:29:41,325 [INFO] Evaluating on valid.
2025-11-11 10:31:47,870 [INFO] Averaged stats: loss: 0.700406  acc: 0.475419 ***auc: 0.5145680168690037 ***uauc: 0.49065853840727724 ***u-nDCG: 0.7950555239091475
2025-11-11 10:31:47,877 [INFO] Saving checkpoint at epoch 4 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:31:48,376 [INFO] Start training
2025-11-11 10:31:48,384 [INFO] Start training epoch 5, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:32:13,522 [INFO] Averaged stats: lr: 0.000010  loss: 0.696687
2025-11-11 10:32:13,523 [INFO] Evaluating on valid.
2025-11-11 10:34:17,455 [INFO] Averaged stats: loss: 0.700044  acc: 0.487233 ***auc: 0.5151335935471101 ***uauc: 0.49388710267541747 ***u-nDCG: 0.7958317458179892
2025-11-11 10:34:17,464 [INFO] Saving checkpoint at epoch 5 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:34:17,962 [INFO] Start training
2025-11-11 10:34:17,970 [INFO] Start training epoch 6, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:34:43,075 [INFO] Averaged stats: lr: 0.000010  loss: 0.701042
2025-11-11 10:34:43,076 [INFO] Evaluating on valid.
2025-11-11 10:36:51,511 [INFO] Averaged stats: loss: 0.697827  acc: 0.478849 ***auc: 0.5165718124245422 ***uauc: 0.4924014826967659 ***u-nDCG: 0.7956927554855207
2025-11-11 10:36:51,519 [INFO] Saving checkpoint at epoch 6 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:36:52,016 [INFO] Start training
2025-11-11 10:36:52,023 [INFO] Start training epoch 7, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:37:16,838 [INFO] Averaged stats: lr: 0.000010  loss: 0.698794
2025-11-11 10:37:16,839 [INFO] Evaluating on valid.
llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight
prompt example: <s>#Question: A user has given high ratings to the following movies: "Best in Show (2000)", "High Fidelity (2000)", "Bring It On (2000)", "28 Days (2000)", "Perfect Storm, The (2000)", "Return to Me (2000)", "Thomas Crown Affair, The (1999)". Leverage the information to predict whether the user would enjoy the movie titled "My Dog Skip (1999)"? Answer with "Yes" or "No". \n#Answer:
#######prmpt decoded example:  <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <s ># Question :  A  user  has  given  high  ratings  to  the  following  movies :  " Dave  ( 1 9 9 3 )",  " Add ams  Family ,  The  ( 1 9 9 1 )",  " Ham let  ( 1 9 9 0 )",  " Cour age  Under  Fire  ( 1 9 9 6 )",  " P ump  Up  the  Volume  ( 1 9 9 0 )",  " B ul worth  ( 1 9 9 8 )",  " M ight y  Aph rod ite  ( 1 9 9 5 )",  " Four  Wed dings  and  a  Funeral  ( 1 9 9 4 )",  " In  the  Name  of  the  Father  ( 1 9 9 3 )",  " S cream  ( 1 9 9 6 )".  Le verage  the  information  to  predict  whether  the  user  would  enjoy  the  movie  titled  " Last  Sup per ,  The  ( 1 9 9 5 )" ?  Answer  with  " Yes "  or  " No ".  \ n # Answer :
Train: data epoch: [0]  [ 0/50]  eta: 0:00:39  lr: 0.000010  loss: 6.5522  time: 0.7987  data: 0.0000  max mem: 17609
Train: data epoch: [0]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 6.0445  time: 0.5035  data: 0.0000  max mem: 20337
Train: data epoch: [0] Total time: 0:00:25 (0.5085 s / it)
Evaluation  [ 0/82]  eta: 0:01:26  loss: 4.6729  acc: 0.5625  time: 1.0543  data: 0.0046  max mem: 22304
Evaluation  [16/82]  eta: 0:01:37  loss: 5.4046  acc: 0.5000  time: 1.4842  data: 0.0029  max mem: 26592
Evaluation  [32/82]  eta: 0:01:16  loss: 6.6948  acc: 0.3750  time: 1.5656  data: 0.0030  max mem: 27639
Evaluation  [48/82]  eta: 0:00:52  loss: 5.8555  acc: 0.4531  time: 1.5639  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 5.5222  acc: 0.4844  time: 1.5685  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 4.6941  acc: 0.5625  time: 1.5395  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 5.3345  acc: 0.5000  time: 1.4809  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:05 (1.5362 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07726335525512695 uauc: 0.5280365103061108
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003072023391723633 u-nDCG: 0.8080459843123784
rank_0 auc: 0.506184222385522
Train: data epoch: [1]  [ 0/50]  eta: 0:00:26  lr: 0.000010  loss: 6.8472  time: 0.5211  data: 0.0000  max mem: 28728
Train: data epoch: [1]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 1.8370  time: 0.4934  data: 0.0000  max mem: 28728
Train: data epoch: [1] Total time: 0:00:25 (0.5053 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 1.7443  acc: 0.5625  time: 0.9209  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:38  loss: 2.0851  acc: 0.5000  time: 1.4884  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:17  loss: 2.5504  acc: 0.3750  time: 1.5891  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:53  loss: 2.2379  acc: 0.4531  time: 1.5919  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 2.0862  acc: 0.4844  time: 1.6157  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 1.7700  acc: 0.5625  time: 1.5556  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 2.0536  acc: 0.5000  time: 1.4960  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:08 (1.5625 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0750429630279541 uauc: 0.4923672389335247
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
2025-11-11 10:39:18,716 [INFO] Averaged stats: loss: 0.697260  acc: 0.483994 ***auc: 0.5189794852613747 ***uauc: 0.49490921114088327 ***u-nDCG: 0.7972002326467569
2025-11-11 10:39:18,721 [INFO] Saving checkpoint at epoch 7 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:39:19,181 [INFO] Start training
2025-11-11 10:39:19,189 [INFO] Start training epoch 8, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:39:44,465 [INFO] Averaged stats: lr: 0.000010  loss: 0.704333
2025-11-11 10:39:44,466 [INFO] Evaluating on valid.
2025-11-11 10:41:47,128 [INFO] Averaged stats: loss: 0.698263  acc: 0.470655 ***auc: 0.5217159765685844 ***uauc: 0.49882606603153473 ***u-nDCG: 0.7984361274898742
2025-11-11 10:41:47,134 [INFO] Saving checkpoint at epoch 8 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:41:47,609 [INFO] Start training
2025-11-11 10:41:47,615 [INFO] Start training epoch 9, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:42:12,661 [INFO] Averaged stats: lr: 0.000010  loss: 0.706297
2025-11-11 10:42:12,663 [INFO] Evaluating on valid.
2025-11-11 10:44:14,407 [INFO] Averaged stats: loss: 0.695629  acc: 0.478087 ***auc: 0.5206152624927634 ***uauc: 0.49278229200629037 ***u-nDCG: 0.7947589983603103
2025-11-11 10:44:14,413 [INFO] Start training
2025-11-11 10:44:14,420 [INFO] Start training epoch 10, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:44:39,252 [INFO] Averaged stats: lr: 0.000010  loss: 0.693464
2025-11-11 10:44:39,254 [INFO] Evaluating on valid.
2025-11-11 10:46:40,981 [INFO] Averaged stats: loss: 0.694919  acc: 0.477515 ***auc: 0.5219933452308849 ***uauc: 0.49560846795111035 ***u-nDCG: 0.7951464355928981
2025-11-11 10:46:40,987 [INFO] Saving checkpoint at epoch 10 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:46:41,459 [INFO] Start training
2025-11-11 10:46:41,466 [INFO] Start training epoch 11, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:47:06,511 [INFO] Averaged stats: lr: 0.000010  loss: 0.707558
2025-11-11 10:47:06,513 [INFO] Evaluating on valid.
2025-11-11 10:49:08,494 [INFO] Averaged stats: loss: 0.693837  acc: 0.471799 ***auc: 0.5248083104877872 ***uauc: 0.49641395816986855 ***u-nDCG: 0.79718401377266
2025-11-11 10:49:08,500 [INFO] Saving checkpoint at epoch 11 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:49:08,985 [INFO] Start training
2025-11-11 10:49:08,991 [INFO] Start training epoch 12, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:49:34,094 [INFO] Averaged stats: lr: 0.000010  loss: 0.683969
2025-11-11 10:49:34,095 [INFO] Evaluating on valid.
2025-11-11 10:51:35,993 [INFO] Averaged stats: loss: 0.700634  acc: 0.503239 ***auc: 0.5220269769236103 ***uauc: 0.4858819802945911 ***u-nDCG: 0.7881726523581501
2025-11-11 10:51:36,000 [INFO] Start training
2025-11-11 10:51:36,007 [INFO] Start training epoch 13, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:52:00,835 [INFO] Averaged stats: lr: 0.000010  loss: 0.705221
2025-11-11 10:52:00,836 [INFO] Evaluating on valid.
u-nDCG for validation Cost: 0.003076314926147461 u-nDCG: 0.7935622648927295
rank_0 auc: 0.48663025138836524
Train: data epoch: [2]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 2.6995  time: 0.4612  data: 0.0000  max mem: 28728
Train: data epoch: [2]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7257  time: 0.4954  data: 0.0000  max mem: 28728
Train: data epoch: [2] Total time: 0:00:24 (0.4964 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6958  acc: 0.4688  time: 0.9081  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.6991  acc: 0.5312  time: 1.4843  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.6984  acc: 0.6094  time: 1.5788  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:53  loss: 0.7238  acc: 0.5000  time: 1.6023  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6968  acc: 0.5312  time: 1.5850  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7102  acc: 0.4375  time: 1.5551  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7119  acc: 0.4375  time: 1.4967  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:07 (1.5538 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07847142219543457 uauc: 0.4709417006952556
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003065347671508789 u-nDCG: 0.7907475490533019
rank_0 auc: 0.5105369652393812
Train: data epoch: [3]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6453  time: 0.4735  data: 0.0000  max mem: 28728
Train: data epoch: [3]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7498  time: 0.5028  data: 0.0000  max mem: 28728
Train: data epoch: [3] Total time: 0:00:24 (0.4978 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.7026  acc: 0.4375  time: 0.8978  data: 0.0063  max mem: 28728
Evaluation  [16/82]  eta: 0:01:36  loss: 0.6959  acc: 0.5156  time: 1.4689  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.6832  acc: 0.6406  time: 1.5856  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.7149  acc: 0.5156  time: 1.5705  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6963  acc: 0.5312  time: 1.5681  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7120  acc: 0.4375  time: 1.5368  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7094  acc: 0.4375  time: 1.4818  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:06 (1.5383 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0754854679107666 uauc: 0.4836200374451069
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003034830093383789 u-nDCG: 0.7911732982329805
rank_0 auc: 0.5140074886569135
Train: data epoch: [4]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.7641  time: 0.4663  data: 0.0000  max mem: 28728
Train: data epoch: [4]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6410  time: 0.5040  data: 0.0000  max mem: 28728
Train: data epoch: [4] Total time: 0:00:24 (0.4974 s / it)
Evaluation  [ 0/82]  eta: 0:01:27  loss: 0.7013  acc: 0.4375  time: 1.0669  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7015  acc: 0.5156  time: 1.4831  data: 0.0025  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.6848  acc: 0.6406  time: 1.5683  data: 0.0024  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.7114  acc: 0.5156  time: 1.5729  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6968  acc: 0.5312  time: 1.5660  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7073  acc: 0.4375  time: 1.5517  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7085  acc: 0.4375  time: 1.4950  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:06 (1.5422 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07444381713867188 uauc: 0.49065853840727724
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030634403228759766 u-nDCG: 0.7950555239091475
rank_0 auc: 0.5145680168690037
Train: data epoch: [5]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.7185  time: 0.4975  data: 0.0000  max mem: 28728
Train: data epoch: [5]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6565  time: 0.4977  data: 0.0000  max mem: 28728
Train: data epoch: [5] Total time: 0:00:25 (0.5028 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6946  acc: 0.4531  time: 0.8994  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:36  loss: 0.7125  acc: 0.5000  time: 1.4583  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7071  acc: 0.5938  time: 1.5346  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7190  acc: 0.5156  time: 1.5488  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.7030  acc: 0.5625  time: 1.5463  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6978  acc: 0.4844  time: 1.5146  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7138  acc: 0.5000  time: 1.4527  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:03 (1.5103 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07756161689758301 uauc: 0.49388710267541747
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015249252319335938 u-nDCG: 0.7958317458179892
rank_0 auc: 0.5151335935471101
Train: data epoch: [6]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6256  time: 0.4894  data: 0.0000  max mem: 28728
Train: data epoch: [6]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7924  time: 0.4974  data: 0.0000  max mem: 28728
Train: data epoch: [6] Total time: 0:00:25 (0.5021 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6940  acc: 0.4531  time: 0.8703  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7048  acc: 0.5312  time: 1.4355  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6923  acc: 0.6406  time: 1.5247  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.7101  acc: 0.5156  time: 1.6457  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6969  acc: 0.5312  time: 1.8106  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7015  acc: 0.4375  time: 1.4809  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7083  acc: 0.4375  time: 1.4249  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:08 (1.5652 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07874226570129395 uauc: 0.4924014826967659
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015113353729248047 u-nDCG: 0.7956927554855207
rank_0 auc: 0.5165718124245422
Train: data epoch: [7]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.7211  time: 0.4820  data: 0.0000  max mem: 28728
Train: data epoch: [7]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6769  time: 0.4973  data: 0.0000  max mem: 28728
Train: data epoch: [7] Total time: 0:00:24 (0.4963 s / it)
Evaluation  [ 0/82]  eta: 0:01:10  loss: 0.6929  acc: 0.4375  time: 0.8537  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7105  acc: 0.5312  time: 1.4202  data: 0.0031  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7004  acc: 0.6094  time: 1.5399  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7092  acc: 0.5312  time: 1.5333  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.7005  acc: 0.5312  time: 1.4990  data: 0.0025  max mem: 28728
2025-11-11 10:54:02,964 [INFO] Averaged stats: loss: 0.700717  acc: 0.511052 ***auc: 0.5266054159052516 ***uauc: 0.48319225092720436 ***u-nDCG: 0.7872175961086705
2025-11-11 10:54:02,970 [INFO] Saving checkpoint at epoch 13 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:54:03,440 [INFO] Start training
2025-11-11 10:54:03,446 [INFO] Start training epoch 14, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:54:28,502 [INFO] Averaged stats: lr: 0.000010  loss: 0.696007
2025-11-11 10:54:28,504 [INFO] Evaluating on valid.
2025-11-11 10:56:30,523 [INFO] Averaged stats: loss: 0.692617  acc: 0.471989 ***auc: 0.528616709917667 ***uauc: 0.4905939407006148 ***u-nDCG: 0.7932743285426176
2025-11-11 10:56:30,529 [INFO] Saving checkpoint at epoch 14 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:56:30,971 [INFO] Start training
2025-11-11 10:56:30,977 [INFO] Start training epoch 15, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:56:55,997 [INFO] Averaged stats: lr: 0.000010  loss: 0.693254
2025-11-11 10:56:55,999 [INFO] Evaluating on valid.
2025-11-11 10:58:59,090 [INFO] Averaged stats: loss: 0.695133  acc: 0.471037 ***auc: 0.5325860663228859 ***uauc: 0.48854984411173374 ***u-nDCG: 0.7911345253755971
2025-11-11 10:58:59,096 [INFO] Saving checkpoint at epoch 15 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 10:58:59,548 [INFO] Start training
2025-11-11 10:58:59,555 [INFO] Start training epoch 16, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 10:59:25,109 [INFO] Averaged stats: lr: 0.000010  loss: 0.693184
2025-11-11 10:59:25,110 [INFO] Evaluating on valid.
2025-11-11 11:01:32,399 [INFO] Averaged stats: loss: 0.691446  acc: 0.471227 ***auc: 0.5325779739288306 ***uauc: 0.49689752058783987 ***u-nDCG: 0.792729825898006
2025-11-11 11:01:32,407 [INFO] Start training
2025-11-11 11:01:32,413 [INFO] Start training epoch 17, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:01:57,460 [INFO] Averaged stats: lr: 0.000010  loss: 0.692250
2025-11-11 11:01:57,462 [INFO] Evaluating on valid.
2025-11-11 11:04:02,117 [INFO] Averaged stats: loss: 0.691115  acc: 0.474657 ***auc: 0.5338005193683656 ***uauc: 0.49202969897704213 ***u-nDCG: 0.79264061636409
2025-11-11 11:04:02,123 [INFO] Saving checkpoint at epoch 17 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:04:02,579 [INFO] Start training
2025-11-11 11:04:02,586 [INFO] Start training epoch 18, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:04:27,706 [INFO] Averaged stats: lr: 0.000010  loss: 0.688838
2025-11-11 11:04:27,708 [INFO] Evaluating on valid.
2025-11-11 11:06:31,249 [INFO] Averaged stats: loss: 0.702544  acc: 0.519436 ***auc: 0.5317850677957017 ***uauc: 0.4877905363543379 ***u-nDCG: 0.7884892731134737
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6960  acc: 0.4688  time: 1.4709  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7117  acc: 0.4375  time: 1.4151  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4852 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07615542411804199 uauc: 0.49490921114088327
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003030061721801758 u-nDCG: 0.7972002326467569
rank_0 auc: 0.5189794852613747
Train: data epoch: [8]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.7423  time: 0.4709  data: 0.0000  max mem: 28728
Train: data epoch: [8]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7404  time: 0.5064  data: 0.0000  max mem: 28728
Train: data epoch: [8] Total time: 0:00:25 (0.5055 s / it)
Evaluation  [ 0/82]  eta: 0:01:10  loss: 0.6993  acc: 0.4375  time: 0.8548  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7021  acc: 0.5000  time: 1.4761  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.6739  acc: 0.6406  time: 1.5418  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6971  acc: 0.5312  time: 1.5113  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6944  acc: 0.5156  time: 1.5165  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7058  acc: 0.4531  time: 1.4830  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7065  acc: 0.4375  time: 1.4268  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:02 (1.4947 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07781696319580078 uauc: 0.49882606603153473
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003022432327270508 u-nDCG: 0.7984361274898742
rank_0 auc: 0.5217159765685844
Train: data epoch: [9]  [ 0/50]  eta: 0:00:25  lr: 0.000010  loss: 0.6934  time: 0.5086  data: 0.0000  max mem: 28728
Train: data epoch: [9]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.8224  time: 0.4988  data: 0.0000  max mem: 28728
Train: data epoch: [9] Total time: 0:00:25 (0.5009 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6876  acc: 0.4375  time: 1.0212  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7044  acc: 0.5469  time: 1.4384  data: 0.0032  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6990  acc: 0.6094  time: 1.5158  data: 0.0031  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7105  acc: 0.5625  time: 1.5045  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6963  acc: 0.5469  time: 1.5109  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6984  acc: 0.4531  time: 1.4863  data: 0.0021  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7049  acc: 0.4375  time: 1.4326  data: 0.0021  max mem: 28728
Evaluation Total time: 0:02:01 (1.4835 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0786130428314209 uauc: 0.49278229200629037
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030622482299804688 u-nDCG: 0.7947589983603103
rank_0 auc: 0.5206152624927634
Train: data epoch: [10]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6536  time: 0.4894  data: 0.0000  max mem: 28728
Train: data epoch: [10]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7054  time: 0.4991  data: 0.0000  max mem: 28728
Train: data epoch: [10] Total time: 0:00:24 (0.4967 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6875  acc: 0.4531  time: 1.0240  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7046  acc: 0.5469  time: 1.4270  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6969  acc: 0.6250  time: 1.5146  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7079  acc: 0.5469  time: 1.5094  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6960  acc: 0.5312  time: 1.5130  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6969  acc: 0.4688  time: 1.4851  data: 0.0029  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7046  acc: 0.4375  time: 1.4283  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:01 (1.4834 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0775454044342041 uauc: 0.49560846795111035
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003009319305419922 u-nDCG: 0.7951464355928981
rank_0 auc: 0.5219933452308849
Train: data epoch: [11]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6983  time: 0.4955  data: 0.0000  max mem: 28728
Train: data epoch: [11]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7596  time: 0.5047  data: 0.0000  max mem: 28728
Train: data epoch: [11] Total time: 0:00:25 (0.5009 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6873  acc: 0.4375  time: 1.0002  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7015  acc: 0.5312  time: 1.4381  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6890  acc: 0.6406  time: 1.5080  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7028  acc: 0.5469  time: 1.5158  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6930  acc: 0.5156  time: 1.5119  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6973  acc: 0.4531  time: 1.4874  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7008  acc: 0.4375  time: 1.4302  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:01 (1.4864 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08010268211364746 uauc: 0.49641395816986855
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003025054931640625 u-nDCG: 0.79718401377266
rank_0 auc: 0.5248083104877872
Train: data epoch: [12]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6794  time: 0.4943  data: 0.0000  max mem: 28728
Train: data epoch: [12]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6513  time: 0.5036  data: 0.0000  max mem: 28728
Train: data epoch: [12] Total time: 0:00:25 (0.5021 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6801  acc: 0.5469  time: 1.0090  data: 0.0062  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7183  acc: 0.5156  time: 1.4374  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7380  acc: 0.6406  time: 1.5165  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7285  acc: 0.5469  time: 1.5142  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.7088  acc: 0.5312  time: 1.5092  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7002  acc: 0.4062  time: 1.4872  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7147  acc: 0.5625  time: 1.4293  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4855 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07609891891479492 uauc: 0.4858819802945911
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015399456024169922 u-nDCG: 0.7881726523581501
rank_0 auc: 0.5220269769236103
Train: data epoch: [13]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.7578  time: 0.4784  data: 0.0000  max mem: 28728
Train: data epoch: [13]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7313  time: 0.4966  data: 0.0000  max mem: 28728
Train: data epoch: [13] Total time: 0:00:24 (0.4966 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6828  acc: 0.5312  time: 1.0071  data: 0.0045  max mem: 28728
2025-11-11 11:06:31,255 [INFO] Start training
2025-11-11 11:06:31,261 [INFO] Start training epoch 19, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:06:56,253 [INFO] Averaged stats: lr: 0.000010  loss: 0.692889
2025-11-11 11:06:56,254 [INFO] Evaluating on valid.
2025-11-11 11:09:01,557 [INFO] Averaged stats: loss: 0.703448  acc: 0.470465 ***auc: 0.5383047162027101 ***uauc: 0.4864256264138005 ***u-nDCG: 0.790687245073189
2025-11-11 11:09:01,563 [INFO] Saving checkpoint at epoch 19 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:09:02,020 [INFO] Start training
2025-11-11 11:09:02,026 [INFO] Start training epoch 20, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:09:27,163 [INFO] Averaged stats: lr: 0.000010  loss: 0.686554
2025-11-11 11:09:27,164 [INFO] Evaluating on valid.
2025-11-11 11:11:30,377 [INFO] Averaged stats: loss: 0.693705  acc: 0.470655 ***auc: 0.5389401547414228 ***uauc: 0.492745961239937 ***u-nDCG: 0.7935246994183848
2025-11-11 11:11:30,384 [INFO] Saving checkpoint at epoch 20 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:11:30,847 [INFO] Start training
2025-11-11 11:11:30,853 [INFO] Start training epoch 21, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:11:56,251 [INFO] Averaged stats: lr: 0.000010  loss: 0.692416
2025-11-11 11:11:56,252 [INFO] Evaluating on valid.
2025-11-11 11:14:01,953 [INFO] Averaged stats: loss: 0.690402  acc: 0.478849 ***auc: 0.5375542765778349 ***uauc: 0.4903404578792657 ***u-nDCG: 0.7929833233654744
2025-11-11 11:14:01,961 [INFO] Start training
2025-11-11 11:14:01,967 [INFO] Start training epoch 22, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:14:27,220 [INFO] Averaged stats: lr: 0.000010  loss: 0.695552
2025-11-11 11:14:27,221 [INFO] Evaluating on valid.
2025-11-11 11:16:31,918 [INFO] Averaged stats: loss: 0.689396  acc: 0.475229 ***auc: 0.5394764057713469 ***uauc: 0.4838481063065096 ***u-nDCG: 0.7896309389108369
2025-11-11 11:16:31,923 [INFO] Saving checkpoint at epoch 22 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:16:32,384 [INFO] Start training
2025-11-11 11:16:32,392 [INFO] Start training epoch 23, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:16:57,470 [INFO] Averaged stats: lr: 0.000010  loss: 0.689385
2025-11-11 11:16:57,471 [INFO] Evaluating on valid.
2025-11-11 11:19:13,368 [INFO] Averaged stats: loss: 0.690052  acc: 0.470846 ***auc: 0.5408980686499317 ***uauc: 0.4873940788134621 ***u-nDCG: 0.7929570442825753
2025-11-11 11:19:13,375 [INFO] Saving checkpoint at epoch 23 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:19:13,819 [INFO] Start training
2025-11-11 11:19:13,825 [INFO] Start training epoch 24, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:19:38,970 [INFO] Averaged stats: lr: 0.000010  loss: 0.681525
2025-11-11 11:19:38,972 [INFO] Evaluating on valid.
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7240  acc: 0.4688  time: 1.4316  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7448  acc: 0.6406  time: 1.5188  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7282  acc: 0.5469  time: 1.5270  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.7129  acc: 0.5312  time: 1.5145  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6906  acc: 0.4219  time: 1.4931  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7149  acc: 0.6250  time: 1.4365  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:02 (1.4882 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07927346229553223 uauc: 0.48319225092720436
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.002999544143676758 u-nDCG: 0.7872175961086705
rank_0 auc: 0.5266054159052516
Train: data epoch: [14]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6861  time: 0.4844  data: 0.0000  max mem: 28728
Train: data epoch: [14]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6857  time: 0.4950  data: 0.0000  max mem: 28728
Train: data epoch: [14] Total time: 0:00:25 (0.5011 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6880  acc: 0.4375  time: 1.0165  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7065  acc: 0.4844  time: 1.4362  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6924  acc: 0.6250  time: 1.5215  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6982  acc: 0.5469  time: 1.5254  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6942  acc: 0.5156  time: 1.5069  data: 0.0030  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6895  acc: 0.4531  time: 1.4781  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6976  acc: 0.4375  time: 1.4249  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4869 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07533550262451172 uauc: 0.4905939407006148
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030493736267089844 u-nDCG: 0.7932743285426176
rank_0 auc: 0.528616709917667
Train: data epoch: [15]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6529  time: 0.4625  data: 0.0000  max mem: 28728
Train: data epoch: [15]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7153  time: 0.4999  data: 0.0000  max mem: 28728
Train: data epoch: [15] Total time: 0:00:25 (0.5004 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6962  acc: 0.4375  time: 1.0108  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.6996  acc: 0.5156  time: 1.4427  data: 0.0031  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6733  acc: 0.6250  time: 1.5115  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6924  acc: 0.5469  time: 1.5198  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6904  acc: 0.5000  time: 1.5370  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6988  acc: 0.4531  time: 1.5215  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6935  acc: 0.5000  time: 1.4659  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:03 (1.5000 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0771646499633789 uauc: 0.48854984411173374
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003074169158935547 u-nDCG: 0.7911345253755971
rank_0 auc: 0.5325860663228859
Train: data epoch: [16]  [ 0/50]  eta: 0:00:26  lr: 0.000010  loss: 0.6949  time: 0.5378  data: 0.0000  max mem: 28728
Train: data epoch: [16]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6871  time: 0.4978  data: 0.0000  max mem: 28728
Train: data epoch: [16] Total time: 0:00:25 (0.5111 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6844  acc: 0.4375  time: 0.8696  data: 0.0060  max mem: 28728
Evaluation  [16/82]  eta: 0:01:36  loss: 0.7021  acc: 0.5156  time: 1.4548  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.6895  acc: 0.6250  time: 1.5399  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6970  acc: 0.5469  time: 1.5440  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6903  acc: 0.5000  time: 1.6234  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6911  acc: 0.4531  time: 1.6756  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6934  acc: 0.4375  time: 1.6189  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:07 (1.5512 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07597184181213379 uauc: 0.49689752058783987
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003029346466064453 u-nDCG: 0.792729825898006
rank_0 auc: 0.5325779739288306
Train: data epoch: [17]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6891  time: 0.4782  data: 0.0000  max mem: 28728
Train: data epoch: [17]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6962  time: 0.4971  data: 0.0000  max mem: 28728
Train: data epoch: [17] Total time: 0:00:25 (0.5009 s / it)
Evaluation  [ 0/82]  eta: 0:01:10  loss: 0.6835  acc: 0.4531  time: 0.8548  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7048  acc: 0.5312  time: 1.4421  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7031  acc: 0.6094  time: 1.5275  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.7029  acc: 0.5625  time: 1.5907  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6943  acc: 0.5156  time: 1.5922  data: 0.0024  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6865  acc: 0.4844  time: 1.5005  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6920  acc: 0.4375  time: 1.4428  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:04 (1.5191 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07609295845031738 uauc: 0.49202969897704213
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015485286712646484 u-nDCG: 0.79264061636409
rank_0 auc: 0.5338005193683656
Train: data epoch: [18]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6435  time: 0.4864  data: 0.0000  max mem: 28728
Train: data epoch: [18]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7889  time: 0.5000  data: 0.0000  max mem: 28728
Train: data epoch: [18] Total time: 0:00:25 (0.5024 s / it)
Evaluation  [ 0/82]  eta: 0:01:09  loss: 0.6818  acc: 0.5312  time: 0.8459  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7241  acc: 0.5156  time: 1.4393  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.7571  acc: 0.6094  time: 1.5586  data: 0.0023  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7365  acc: 0.5625  time: 1.5249  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.7155  acc: 0.5312  time: 1.5324  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6933  acc: 0.4062  time: 1.5035  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7126  acc: 0.5625  time: 1.4454  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:03 (1.5055 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07762789726257324 uauc: 0.4877905363543379
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0031414031982421875 u-nDCG: 0.7884892731134737
rank_0 auc: 2025-11-11 11:21:42,261 [INFO] Averaged stats: loss: 0.689116  acc: 0.472561 ***auc: 0.5421092550409304 ***uauc: 0.4837749707241608 ***u-nDCG: 0.7899651094127262
2025-11-11 11:21:42,267 [INFO] Saving checkpoint at epoch 24 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:21:42,735 [INFO] Start training
2025-11-11 11:21:42,743 [INFO] Start training epoch 25, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:22:08,295 [INFO] Averaged stats: lr: 0.000010  loss: 0.695116
2025-11-11 11:22:08,297 [INFO] Evaluating on valid.
2025-11-11 11:24:13,931 [INFO] Averaged stats: loss: 0.693372  acc: 0.470274 ***auc: 0.5468688448619757 ***uauc: 0.48175313486626825 ***u-nDCG: 0.7891060641654659
2025-11-11 11:24:13,937 [INFO] Saving checkpoint at epoch 25 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:24:14,401 [INFO] Start training
2025-11-11 11:24:14,408 [INFO] Start training epoch 26, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:24:39,496 [INFO] Averaged stats: lr: 0.000010  loss: 0.692223
2025-11-11 11:24:39,498 [INFO] Evaluating on valid.
2025-11-11 11:26:44,084 [INFO] Averaged stats: loss: 0.691114  acc: 0.471037 ***auc: 0.5478908622616623 ***uauc: 0.4850159974917989 ***u-nDCG: 0.7893141757777895
2025-11-11 11:26:44,090 [INFO] Saving checkpoint at epoch 26 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:26:44,547 [INFO] Start training
2025-11-11 11:26:44,553 [INFO] Start training epoch 27, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:27:09,670 [INFO] Averaged stats: lr: 0.000010  loss: 0.691980
2025-11-11 11:27:09,671 [INFO] Evaluating on valid.
2025-11-11 11:29:12,576 [INFO] Averaged stats: loss: 0.687899  acc: 0.472561 ***auc: 0.5485825021058786 ***uauc: 0.4847098143545775 ***u-nDCG: 0.7891695951918949
2025-11-11 11:29:12,582 [INFO] Saving checkpoint at epoch 27 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:29:13,049 [INFO] Start training
2025-11-11 11:29:13,055 [INFO] Start training epoch 28, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:29:38,449 [INFO] Averaged stats: lr: 0.000010  loss: 0.698217
2025-11-11 11:29:38,450 [INFO] Evaluating on valid.
2025-11-11 11:31:40,860 [INFO] Averaged stats: loss: 0.689765  acc: 0.471227 ***auc: 0.5480223451045247 ***uauc: 0.48370472376366364 ***u-nDCG: 0.7919359041974222
2025-11-11 11:31:40,866 [INFO] Start training
2025-11-11 11:31:40,874 [INFO] Start training epoch 29, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:32:06,168 [INFO] Averaged stats: lr: 0.000010  loss: 0.689607
2025-11-11 11:32:06,170 [INFO] Evaluating on valid.
2025-11-11 11:34:06,526 [INFO] Averaged stats: loss: 0.689997  acc: 0.470846 ***auc: 0.5503534000453472 ***uauc: 0.49055294555940937 ***u-nDCG: 0.7927041483523435
2025-11-11 11:34:06,532 [INFO] Saving checkpoint at epoch 29 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:34:06,991 [INFO] Start training
2025-11-11 11:34:06,997 [INFO] Start training epoch 30, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:34:31,970 [INFO] Averaged stats: lr: 0.000010  loss: 0.691245
2025-11-11 11:34:31,972 [INFO] Evaluating on valid.
0.5317850677957017
Train: data epoch: [19]  [ 0/50]  eta: 0:00:25  lr: 0.000010  loss: 0.7793  time: 0.5040  data: 0.0000  max mem: 28728
Train: data epoch: [19]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7297  time: 0.5022  data: 0.0000  max mem: 28728
Train: data epoch: [19] Total time: 0:00:24 (0.4998 s / it)
Evaluation  [ 0/82]  eta: 0:01:09  loss: 0.7082  acc: 0.4375  time: 0.8514  data: 0.0060  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.6976  acc: 0.5000  time: 1.5523  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:17  loss: 0.6595  acc: 0.6250  time: 1.5563  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6927  acc: 0.5469  time: 1.5300  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6909  acc: 0.5156  time: 1.5344  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7141  acc: 0.4531  time: 1.5103  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6894  acc: 0.5000  time: 1.4545  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:05 (1.5270 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07739400863647461 uauc: 0.4864256264138005
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003020048141479492 u-nDCG: 0.790687245073189
rank_0 auc: 0.5383047162027101
Train: data epoch: [20]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.7559  time: 0.4719  data: 0.0000  max mem: 28728
Train: data epoch: [20]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7054  time: 0.4994  data: 0.0000  max mem: 28728
Train: data epoch: [20] Total time: 0:00:25 (0.5027 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6925  acc: 0.4375  time: 1.0086  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.6964  acc: 0.5000  time: 1.4489  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6728  acc: 0.6250  time: 1.5163  data: 0.0024  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6906  acc: 0.5469  time: 1.5271  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6883  acc: 0.5000  time: 1.5350  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6984  acc: 0.4531  time: 1.5161  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6866  acc: 0.5000  time: 1.4620  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:03 (1.5015 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07776498794555664 uauc: 0.492745961239937
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0031614303588867188 u-nDCG: 0.7935246994183848
rank_0 auc: 0.5389401547414228
Train: data epoch: [21]  [ 0/50]  eta: 0:00:26  lr: 0.000010  loss: 0.7310  time: 0.5306  data: 0.0000  max mem: 28728
Train: data epoch: [21]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7597  time: 0.5021  data: 0.0000  max mem: 28728
Train: data epoch: [21] Total time: 0:00:25 (0.5080 s / it)
Evaluation  [ 0/82]  eta: 0:01:10  loss: 0.6809  acc: 0.4531  time: 0.8597  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7037  acc: 0.5312  time: 1.4478  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7059  acc: 0.6250  time: 1.5417  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7031  acc: 0.5625  time: 1.5396  data: 0.0030  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6951  acc: 0.5000  time: 1.5817  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6854  acc: 0.4844  time: 1.6128  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6905  acc: 0.5000  time: 1.5565  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:05 (1.5318 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07608342170715332 uauc: 0.4903404578792657
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030488967895507812 u-nDCG: 0.7929833233654744
rank_0 auc: 0.5375542765778349
Train: data epoch: [22]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6644  time: 0.4672  data: 0.0000  max mem: 28728
Train: data epoch: [22]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6328  time: 0.5102  data: 0.0000  max mem: 28728
Train: data epoch: [22] Total time: 0:00:25 (0.5051 s / it)
Evaluation  [ 0/82]  eta: 0:01:10  loss: 0.6806  acc: 0.4375  time: 0.8578  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7011  acc: 0.5156  time: 1.4480  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6996  acc: 0.6250  time: 1.5254  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6990  acc: 0.5625  time: 1.5707  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6924  acc: 0.4844  time: 1.6138  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6870  acc: 0.4844  time: 1.4966  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6860  acc: 0.5000  time: 1.4440  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:04 (1.5195 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07837724685668945 uauc: 0.4838481063065096
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003192424774169922 u-nDCG: 0.7896309389108369
rank_0 auc: 0.5394764057713469
Train: data epoch: [23]  [ 0/50]  eta: 0:00:25  lr: 0.000010  loss: 0.6907  time: 0.5187  data: 0.0000  max mem: 28728
Train: data epoch: [23]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6748  time: 0.5008  data: 0.0000  max mem: 28728
Train: data epoch: [23] Total time: 0:00:25 (0.5016 s / it)
Evaluation  [ 0/82]  eta: 0:01:10  loss: 0.6865  acc: 0.4375  time: 0.8545  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.6997  acc: 0.5156  time: 1.4420  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:30  loss: 0.6855  acc: 0.6094  time: 2.0513  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:01:00  loss: 0.6923  acc: 0.5469  time: 1.9007  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6890  acc: 0.5000  time: 1.5260  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6897  acc: 0.4531  time: 1.4992  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6794  acc: 0.5000  time: 1.4436  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:15 (1.6561 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08097338676452637 uauc: 0.4873940788134621
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.004207611083984375 u-nDCG: 0.7929570442825753
rank_0 auc: 0.5408980686499317
Train: data epoch: [24]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6711  time: 0.4727  data: 0.0000  max mem: 28728
Train: data epoch: [24]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7138  time: 0.5027  data: 0.0000  max mem: 28728
Train: data epoch: [24] Total time: 0:00:25 (0.5029 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6827  acc: 0.4375  time: 1.0210  data: 0.0040  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7012  acc: 0.5156  time: 1.4537  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6893  acc: 0.6094  time: 1.5275  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6944  acc: 0.5469  time: 1.5260  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6879  acc: 0.5000  time: 1.5331  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6889  acc: 0.4844  time: 1.5032  data: 0.0025  max mem: 28728
2025-11-11 11:36:32,391 [INFO] Averaged stats: loss: 0.687167  acc: 0.475800 ***auc: 0.5510598140768754 ***uauc: 0.48618873458217543 ***u-nDCG: 0.7898058936538042
2025-11-11 11:36:32,396 [INFO] Saving checkpoint at epoch 30 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:36:32,864 [INFO] Start training
2025-11-11 11:36:32,870 [INFO] Start training epoch 31, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:36:58,161 [INFO] Averaged stats: lr: 0.000010  loss: 0.689290
2025-11-11 11:36:58,163 [INFO] Evaluating on valid.
2025-11-11 11:38:58,692 [INFO] Averaged stats: loss: 0.698300  acc: 0.520960 ***auc: 0.5496107558459381 ***uauc: 0.4835462424811012 ***u-nDCG: 0.7886394510906329
2025-11-11 11:38:58,698 [INFO] Start training
2025-11-11 11:38:58,706 [INFO] Start training epoch 32, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:39:23,662 [INFO] Averaged stats: lr: 0.000010  loss: 0.695775
2025-11-11 11:39:23,664 [INFO] Evaluating on valid.
2025-11-11 11:41:24,101 [INFO] Averaged stats: loss: 0.687099  acc: 0.479992 ***auc: 0.5533588706522128 ***uauc: 0.48254490243583364 ***u-nDCG: 0.7884886556811864
2025-11-11 11:41:24,107 [INFO] Saving checkpoint at epoch 32 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:41:24,573 [INFO] Start training
2025-11-11 11:41:24,579 [INFO] Start training epoch 33, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:41:49,729 [INFO] Averaged stats: lr: 0.000010  loss: 0.687244
2025-11-11 11:41:49,731 [INFO] Evaluating on valid.
2025-11-11 11:43:49,755 [INFO] Averaged stats: loss: 0.688377  acc: 0.487995 ***auc: 0.5535716486463652 ***uauc: 0.49536129545407054 ***u-nDCG: 0.7942340107430842
2025-11-11 11:43:49,763 [INFO] Saving checkpoint at epoch 33 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:43:50,219 [INFO] Start training
2025-11-11 11:43:50,225 [INFO] Start training epoch 34, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:44:15,382 [INFO] Averaged stats: lr: 0.000010  loss: 0.696481
2025-11-11 11:44:15,383 [INFO] Evaluating on valid.
2025-11-11 11:46:15,600 [INFO] Averaged stats: loss: 0.686313  acc: 0.473323 ***auc: 0.5572915514366672 ***uauc: 0.4933357950130722 ***u-nDCG: 0.7921894947769766
2025-11-11 11:46:15,606 [INFO] Saving checkpoint at epoch 34 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:46:16,083 [INFO] Start training
2025-11-11 11:46:16,089 [INFO] Start training epoch 35, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:46:41,302 [INFO] Averaged stats: lr: 0.000010  loss: 0.690571
2025-11-11 11:46:41,304 [INFO] Evaluating on valid.
2025-11-11 11:48:41,806 [INFO] Averaged stats: loss: 0.686916  acc: 0.478849 ***auc: 0.5548953118905184 ***uauc: 0.48973812672309514 ***u-nDCG: 0.7861054282036702
2025-11-11 11:48:41,812 [INFO] Start training
2025-11-11 11:48:41,818 [INFO] Start training epoch 36, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6782  acc: 0.5000  time: 1.4489  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:03 (1.5024 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07919025421142578 uauc: 0.4837749707241608
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030324459075927734 u-nDCG: 0.7899651094127262
rank_0 auc: 0.5421092550409304
Train: data epoch: [25]  [ 0/50]  eta: 0:00:26  lr: 0.000010  loss: 0.6949  time: 0.5360  data: 0.0000  max mem: 28728
Train: data epoch: [25]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7033  time: 0.5066  data: 0.0000  max mem: 28728
Train: data epoch: [25] Total time: 0:00:25 (0.5111 s / it)
Evaluation  [ 0/82]  eta: 0:01:10  loss: 0.6935  acc: 0.4375  time: 0.8561  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6972  acc: 0.5000  time: 1.4388  data: 0.0032  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6711  acc: 0.6250  time: 1.5399  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6889  acc: 0.5469  time: 1.5471  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6855  acc: 0.5000  time: 1.5832  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6978  acc: 0.4531  time: 1.6102  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6747  acc: 0.5000  time: 1.5536  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:05 (1.5310 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07717132568359375 uauc: 0.48175313486626825
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030477046966552734 u-nDCG: 0.7891060641654659
rank_0 auc: 0.5468688448619757
Train: data epoch: [26]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.7178  time: 0.4909  data: 0.0000  max mem: 28728
Train: data epoch: [26]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6541  time: 0.5003  data: 0.0000  max mem: 28728
Train: data epoch: [26] Total time: 0:00:25 (0.5018 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6899  acc: 0.4375  time: 0.8740  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.6974  acc: 0.5000  time: 1.4517  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.6749  acc: 0.6250  time: 1.5413  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6883  acc: 0.5469  time: 1.6100  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6875  acc: 0.5000  time: 1.5710  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6930  acc: 0.4531  time: 1.4723  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6756  acc: 0.5000  time: 1.4188  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:04 (1.5182 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07760119438171387 uauc: 0.4850159974917989
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030579566955566406 u-nDCG: 0.7893141757777895
rank_0 auc: 0.5478908622616623
Train: data epoch: [27]  [ 0/50]  eta: 0:00:25  lr: 0.000010  loss: 0.6410  time: 0.5096  data: 0.0000  max mem: 28728
Train: data epoch: [27]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6907  time: 0.5021  data: 0.0000  max mem: 28728
Train: data epoch: [27] Total time: 0:00:25 (0.5023 s / it)
Evaluation  [ 0/82]  eta: 0:01:07  loss: 0.6834  acc: 0.4375  time: 0.8291  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.6950  acc: 0.5000  time: 1.4105  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.6911  acc: 0.6094  time: 1.5822  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6967  acc: 0.5469  time: 1.5470  data: 0.0023  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6889  acc: 0.5000  time: 1.5158  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6879  acc: 0.4688  time: 1.4748  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6718  acc: 0.5000  time: 1.4195  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:02 (1.4977 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07605361938476562 uauc: 0.4847098143545775
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030243396759033203 u-nDCG: 0.7891695951918949
rank_0 auc: 0.5485825021058786
Train: data epoch: [28]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.7218  time: 0.4843  data: 0.0000  max mem: 28728
Train: data epoch: [28]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6707  time: 0.5074  data: 0.0000  max mem: 28728
Train: data epoch: [28] Total time: 0:00:25 (0.5079 s / it)
Evaluation  [ 0/82]  eta: 0:01:08  loss: 0.6910  acc: 0.4375  time: 0.8322  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:39  loss: 0.6935  acc: 0.5000  time: 1.5143  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.6819  acc: 0.6094  time: 1.5428  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6927  acc: 0.5469  time: 1.5026  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6887  acc: 0.5000  time: 1.4939  data: 0.0023  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6904  acc: 0.4531  time: 1.4690  data: 0.0022  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6705  acc: 0.5000  time: 1.4128  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:02 (1.4917 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07641935348510742 uauc: 0.48370472376366364
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003017902374267578 u-nDCG: 0.7919359041974222
rank_0 auc: 0.5480223451045247
Train: data epoch: [29]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6562  time: 0.4713  data: 0.0000  max mem: 28728
Train: data epoch: [29]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6708  time: 0.5080  data: 0.0000  max mem: 28728
Train: data epoch: [29] Total time: 0:00:25 (0.5059 s / it)
Evaluation  [ 0/82]  eta: 0:01:21  loss: 0.6903  acc: 0.4375  time: 0.9886  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.6933  acc: 0.5000  time: 1.4126  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6770  acc: 0.6250  time: 1.4919  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6906  acc: 0.5469  time: 1.4947  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6863  acc: 0.5000  time: 1.5017  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6929  acc: 0.4531  time: 1.4664  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6704  acc: 0.5000  time: 1.4113  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:00 (1.4667 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07457518577575684 uauc: 0.49055294555940937
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0026061534881591797 u-nDCG: 0.7927041483523435
rank_0 auc: 0.5503534000453472
Train: data epoch: [30]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6848  time: 0.4628  data: 0.0000  max mem: 28728
Train: data epoch: [30]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7100  time: 0.4961  data: 0.0000  max mem: 28728
Train: data epoch: [30] Total time: 0:00:24 (0.4995 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6805  acc: 0.4375  time: 0.9844  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.6945  acc: 0.5156  time: 1.4134  data: 0.0032  max mem: 28728
2025-11-11 11:49:07,118 [INFO] Averaged stats: lr: 0.000010  loss: 0.689333
2025-11-11 11:49:07,120 [INFO] Evaluating on valid.
2025-11-11 11:51:08,406 [INFO] Averaged stats: loss: 0.692418  acc: 0.517721 ***auc: 0.5541750145774456 ***uauc: 0.49243898580951645 ***u-nDCG: 0.7922637119629692
2025-11-11 11:51:08,411 [INFO] Start training
2025-11-11 11:51:08,418 [INFO] Start training epoch 37, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:51:33,652 [INFO] Averaged stats: lr: 0.000010  loss: 0.684833
2025-11-11 11:51:33,653 [INFO] Evaluating on valid.
2025-11-11 11:53:34,929 [INFO] Averaged stats: loss: 0.689489  acc: 0.501334 ***auc: 0.5546396219352285 ***uauc: 0.4962714336130851 ***u-nDCG: 0.7909848378703378
2025-11-11 11:53:34,937 [INFO] Start training
2025-11-11 11:53:34,943 [INFO] Start training epoch 38, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:53:59,999 [INFO] Averaged stats: lr: 0.000010  loss: 0.691279
2025-11-11 11:54:00,001 [INFO] Evaluating on valid.
2025-11-11 11:56:01,589 [INFO] Averaged stats: loss: 0.686131  acc: 0.477706 ***auc: 0.5577506648755501 ***uauc: 0.48740530728066 ***u-nDCG: 0.788919557616738
2025-11-11 11:56:01,597 [INFO] Saving checkpoint at epoch 38 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 11:56:02,061 [INFO] Start training
2025-11-11 11:56:02,067 [INFO] Start training epoch 39, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:56:27,391 [INFO] Averaged stats: lr: 0.000010  loss: 0.683166
2025-11-11 11:56:27,392 [INFO] Evaluating on valid.
2025-11-11 11:58:28,911 [INFO] Averaged stats: loss: 0.687966  acc: 0.491425 ***auc: 0.5560798453506375 ***uauc: 0.5028550586135493 ***u-nDCG: 0.7945933992252463
2025-11-11 11:58:28,919 [INFO] Start training
2025-11-11 11:58:28,925 [INFO] Start training epoch 40, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 11:58:54,280 [INFO] Averaged stats: lr: 0.000010  loss: 0.684321
2025-11-11 11:58:54,282 [INFO] Evaluating on valid.
2025-11-11 12:00:55,866 [INFO] Averaged stats: loss: 0.688331  acc: 0.500762 ***auc: 0.5593786466814725 ***uauc: 0.4970570087269825 ***u-nDCG: 0.7938291480362111
2025-11-11 12:00:55,872 [INFO] Saving checkpoint at epoch 40 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:00:56,340 [INFO] Start training
2025-11-11 12:00:56,347 [INFO] Start training epoch 41, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:01:21,368 [INFO] Averaged stats: lr: 0.000010  loss: 0.686033
2025-11-11 12:01:21,369 [INFO] Evaluating on valid.
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6978  acc: 0.6094  time: 1.4966  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6988  acc: 0.5469  time: 1.5007  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6901  acc: 0.5000  time: 1.4978  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6852  acc: 0.4688  time: 1.4626  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6716  acc: 0.5625  time: 1.4075  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:00 (1.4674 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07884550094604492 uauc: 0.48618873458217543
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030732154846191406 u-nDCG: 0.7898058936538042
rank_0 auc: 0.5510598140768754
Train: data epoch: [31]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6923  time: 0.4707  data: 0.0000  max mem: 28728
Train: data epoch: [31]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7210  time: 0.5035  data: 0.0000  max mem: 28728
Train: data epoch: [31] Total time: 0:00:25 (0.5058 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6805  acc: 0.5312  time: 0.9800  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7202  acc: 0.4844  time: 1.4129  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.7531  acc: 0.6406  time: 1.4977  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7290  acc: 0.5625  time: 1.5014  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.7127  acc: 0.5156  time: 1.4958  data: 0.0024  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6872  acc: 0.4219  time: 1.4730  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6939  acc: 0.5000  time: 1.4172  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:00 (1.4688 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07602286338806152 uauc: 0.4835462424811012
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.001523733139038086 u-nDCG: 0.7886394510906329
rank_0 auc: 0.5496107558459381
Train: data epoch: [32]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.7156  time: 0.4925  data: 0.0000  max mem: 28728
Train: data epoch: [32]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7024  time: 0.4992  data: 0.0000  max mem: 28728
Train: data epoch: [32] Total time: 0:00:24 (0.4991 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6787  acc: 0.4219  time: 0.9834  data: 0.0048  max mem: 28728
Evaluation  [16/82]  eta: 0:01:32  loss: 0.6994  acc: 0.5312  time: 1.4087  data: 0.0025  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.7044  acc: 0.6094  time: 1.4985  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6989  acc: 0.5469  time: 1.4946  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6916  acc: 0.5000  time: 1.4970  data: 0.0022  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6825  acc: 0.4844  time: 1.4697  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6742  acc: 0.5625  time: 1.4136  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:00 (1.4676 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07579278945922852 uauc: 0.48254490243583364
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003052949905395508 u-nDCG: 0.7884886556811864
rank_0 auc: 0.5533588706522128
Train: data epoch: [33]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6802  time: 0.4715  data: 0.0000  max mem: 28728
Train: data epoch: [33]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6788  time: 0.5016  data: 0.0000  max mem: 28728
Train: data epoch: [33] Total time: 0:00:25 (0.5030 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6783  acc: 0.4844  time: 1.0013  data: 0.0056  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7055  acc: 0.5312  time: 1.4138  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.7173  acc: 0.5938  time: 1.4886  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7051  acc: 0.5469  time: 1.4784  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6953  acc: 0.5469  time: 1.4949  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6785  acc: 0.5000  time: 1.4667  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6772  acc: 0.5000  time: 1.4115  data: 0.0023  max mem: 28728
Evaluation Total time: 0:01:59 (1.4626 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07920694351196289 uauc: 0.49536129545407054
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003047466278076172 u-nDCG: 0.7942340107430842
rank_0 auc: 0.5535716486463652
Train: data epoch: [34]  [ 0/50]  eta: 0:00:27  lr: 0.000010  loss: 0.6483  time: 0.5558  data: 0.0000  max mem: 28728
Train: data epoch: [34]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6870  time: 0.5033  data: 0.0000  max mem: 28728
Train: data epoch: [34] Total time: 0:00:25 (0.5031 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6784  acc: 0.4375  time: 0.9843  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.6966  acc: 0.5000  time: 1.4165  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6958  acc: 0.6094  time: 1.4890  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6935  acc: 0.5469  time: 1.5009  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6870  acc: 0.5000  time: 1.4911  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6832  acc: 0.4688  time: 1.4640  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6690  acc: 0.5625  time: 1.4082  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:00 (1.4649 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07811546325683594 uauc: 0.4933357950130722
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003042936325073242 u-nDCG: 0.7921894947769766
rank_0 auc: 0.5572915514366672
Train: data epoch: [35]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.7126  time: 0.4689  data: 0.0000  max mem: 28728
Train: data epoch: [35]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7061  time: 0.4974  data: 0.0000  max mem: 28728
Train: data epoch: [35] Total time: 0:00:25 (0.5043 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6753  acc: 0.4375  time: 0.9844  data: 0.0052  max mem: 28728
Evaluation  [16/82]  eta: 0:01:32  loss: 0.6997  acc: 0.5156  time: 1.4023  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.7073  acc: 0.6094  time: 1.4923  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7019  acc: 0.5469  time: 1.4993  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6899  acc: 0.5000  time: 1.5088  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6829  acc: 0.4844  time: 1.4749  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6701  acc: 0.5625  time: 1.4191  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:00 (1.4684 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08334803581237793 uauc: 0.48973812672309514
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003050565719604492 u-nDCG: 0.7861054282036702
rank_0 auc: 0.5548953118905184
2025-11-11 12:03:22,796 [INFO] Averaged stats: loss: 0.694162  acc: 0.527058 ***auc: 0.5589047590552776 ***uauc: 0.5083512178242555 ***u-nDCG: 0.8003657972644168
2025-11-11 12:03:22,802 [INFO] Start training
2025-11-11 12:03:22,810 [INFO] Start training epoch 42, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:03:50,343 [INFO] Averaged stats: lr: 0.000010  loss: 0.679081
2025-11-11 12:03:50,343 [INFO] Evaluating on valid.
2025-11-11 12:05:51,947 [INFO] Averaged stats: loss: 0.684804  acc: 0.479230 ***auc: 0.5655890023028429 ***uauc: 0.5044494589550373 ***u-nDCG: 0.7978886156602665
2025-11-11 12:05:51,953 [INFO] Saving checkpoint at epoch 42 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:05:52,413 [INFO] Start training
2025-11-11 12:05:52,420 [INFO] Start training epoch 43, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:06:17,418 [INFO] Averaged stats: lr: 0.000010  loss: 0.681856
2025-11-11 12:06:17,420 [INFO] Evaluating on valid.
2025-11-11 12:08:18,749 [INFO] Averaged stats: loss: 0.691999  acc: 0.470084 ***auc: 0.5693224171639529 ***uauc: 0.503046513275755 ***u-nDCG: 0.7956994164306563
2025-11-11 12:08:18,755 [INFO] Saving checkpoint at epoch 43 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:08:19,210 [INFO] Start training
2025-11-11 12:08:19,219 [INFO] Start training epoch 44, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:08:44,531 [INFO] Averaged stats: lr: 0.000010  loss: 0.684803
2025-11-11 12:08:44,532 [INFO] Evaluating on valid.
2025-11-11 12:10:45,791 [INFO] Averaged stats: loss: 0.692127  acc: 0.531059 ***auc: 0.5664172476980851 ***uauc: 0.5108023053689968 ***u-nDCG: 0.8003712206359554
2025-11-11 12:10:45,798 [INFO] Start training
2025-11-11 12:10:45,805 [INFO] Start training epoch 45, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:11:10,892 [INFO] Averaged stats: lr: 0.000010  loss: 0.684966
2025-11-11 12:11:10,893 [INFO] Evaluating on valid.
2025-11-11 12:13:12,561 [INFO] Averaged stats: loss: 0.684522  acc: 0.483422 ***auc: 0.5675887887824272 ***uauc: 0.5228761376105984 ***u-nDCG: 0.8036613501611302
2025-11-11 12:13:12,569 [INFO] Start training
2025-11-11 12:13:12,575 [INFO] Start training epoch 46, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:13:37,863 [INFO] Averaged stats: lr: 0.000010  loss: 0.684965
2025-11-11 12:13:37,865 [INFO] Evaluating on valid.
2025-11-11 12:15:39,595 [INFO] Averaged stats: loss: 0.691603  acc: 0.526677 ***auc: 0.5659420237132389 ***uauc: 0.5194863114187181 ***u-nDCG: 0.8044956868525988
2025-11-11 12:15:39,603 [INFO] Start training
2025-11-11 12:15:39,609 [INFO] Start training epoch 47, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:16:04,799 [INFO] Averaged stats: lr: 0.000010  loss: 0.690314
2025-11-11 12:16:04,800 [INFO] Evaluating on valid.
Train: data epoch: [36]  [ 0/50]  eta: 0:00:25  lr: 0.000010  loss: 0.6777  time: 0.5043  data: 0.0000  max mem: 28728
Train: data epoch: [36]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7089  time: 0.5160  data: 0.0000  max mem: 28728
Train: data epoch: [36] Total time: 0:00:25 (0.5060 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6774  acc: 0.5312  time: 1.0131  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7113  acc: 0.5156  time: 1.4240  data: 0.0032  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7384  acc: 0.6250  time: 1.5068  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7188  acc: 0.5625  time: 1.5132  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.7041  acc: 0.5469  time: 1.5070  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6800  acc: 0.5312  time: 1.4719  data: 0.0023  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6799  acc: 0.6875  time: 1.4188  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:01 (1.4780 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07695817947387695 uauc: 0.49243898580951645
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030357837677001953 u-nDCG: 0.7922637119629692
rank_0 auc: 0.5541750145774456
Train: data epoch: [37]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.7415  time: 0.4981  data: 0.0000  max mem: 28728
Train: data epoch: [37]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6928  time: 0.5067  data: 0.0000  max mem: 28728
Train: data epoch: [37] Total time: 0:00:25 (0.5047 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6739  acc: 0.4844  time: 1.0043  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7037  acc: 0.5000  time: 1.4174  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7237  acc: 0.6406  time: 1.5009  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7135  acc: 0.5469  time: 1.5065  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6971  acc: 0.5312  time: 1.5099  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6847  acc: 0.5000  time: 1.4795  data: 0.0023  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6733  acc: 0.5000  time: 1.4235  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:01 (1.4779 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07811164855957031 uauc: 0.4962714336130851
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015382766723632812 u-nDCG: 0.7909848378703378
rank_0 auc: 0.5546396219352285
Train: data epoch: [38]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6291  time: 0.4900  data: 0.0000  max mem: 28728
Train: data epoch: [38]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6386  time: 0.4979  data: 0.0000  max mem: 28728
Train: data epoch: [38] Total time: 0:00:25 (0.5011 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6756  acc: 0.4375  time: 1.0117  data: 0.0079  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6981  acc: 0.5156  time: 1.4342  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7036  acc: 0.6094  time: 1.5099  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6993  acc: 0.5469  time: 1.5135  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6904  acc: 0.4844  time: 1.5019  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6823  acc: 0.4688  time: 1.4755  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6665  acc: 0.5625  time: 1.4237  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4817 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07490801811218262 uauc: 0.48740530728066
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003065347671508789 u-nDCG: 0.788919557616738
rank_0 auc: 0.5577506648755501
Train: data epoch: [39]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6991  time: 0.4759  data: 0.0000  max mem: 28728
Train: data epoch: [39]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6501  time: 0.5043  data: 0.0000  max mem: 28728
Train: data epoch: [39] Total time: 0:00:25 (0.5065 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6722  acc: 0.4688  time: 1.0083  data: 0.0062  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7054  acc: 0.5312  time: 1.4231  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7152  acc: 0.6250  time: 1.5072  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7065  acc: 0.5781  time: 1.5093  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6932  acc: 0.5312  time: 1.5117  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6846  acc: 0.4844  time: 1.4803  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6708  acc: 0.5000  time: 1.4254  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4808 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07556843757629395 uauc: 0.5028550586135493
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030426979064941406 u-nDCG: 0.7945933992252463
rank_0 auc: 0.5560798453506375
Train: data epoch: [40]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6048  time: 0.4883  data: 0.0000  max mem: 28728
Train: data epoch: [40]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7536  time: 0.5085  data: 0.0000  max mem: 28728
Train: data epoch: [40] Total time: 0:00:25 (0.5071 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6728  acc: 0.5000  time: 1.0093  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7065  acc: 0.5312  time: 1.4258  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7204  acc: 0.6250  time: 1.5182  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7088  acc: 0.5625  time: 1.5129  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6958  acc: 0.5312  time: 1.5113  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6820  acc: 0.5000  time: 1.4792  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6718  acc: 0.5000  time: 1.4243  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4816 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07847905158996582 uauc: 0.4970570087269825
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015094280242919922 u-nDCG: 0.7938291480362111
rank_0 auc: 0.5593786466814725
Train: data epoch: [41]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6364  time: 0.4667  data: 0.0000  max mem: 28728
Train: data epoch: [41]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.5937  time: 0.4975  data: 0.0000  max mem: 28728
Train: data epoch: [41] Total time: 0:00:25 (0.5004 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6793  acc: 0.5625  time: 1.0008  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7169  acc: 0.5000  time: 1.4350  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7453  acc: 0.6406  time: 1.5046  data: 0.0024  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7229  acc: 0.5625  time: 1.5070  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.7078  acc: 0.5312  time: 1.5110  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6800  acc: 0.5312  time: 1.4747  data: 0.0024  max mem: 28728
2025-11-11 12:18:07,447 [INFO] Averaged stats: loss: 0.684409  acc: 0.484375 ***auc: 0.5671595206867576 ***uauc: 0.5267279127668807 ***u-nDCG: 0.8057121248322519
2025-11-11 12:18:07,465 [INFO] Start training
2025-11-11 12:18:07,480 [INFO] Start training epoch 48, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:18:44,840 [INFO] Averaged stats: lr: 0.000010  loss: 0.673761
2025-11-11 12:18:44,841 [INFO] Evaluating on valid.
2025-11-11 12:20:50,481 [INFO] Averaged stats: loss: 0.705601  acc: 0.552020 ***auc: 0.5669580274989944 ***uauc: 0.5272379334264962 ***u-nDCG: 0.8052558319262925
2025-11-11 12:20:50,487 [INFO] Start training
2025-11-11 12:20:50,493 [INFO] Start training epoch 49, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:21:17,926 [INFO] Averaged stats: lr: 0.000010  loss: 0.683348
2025-11-11 12:21:17,928 [INFO] Evaluating on valid.
2025-11-11 12:23:50,063 [INFO] Averaged stats: loss: 0.686795  acc: 0.513910 ***auc: 0.5715443361482491 ***uauc: 0.5195084415008389 ***u-nDCG: 0.8037892691895785
2025-11-11 12:23:50,075 [INFO] Saving checkpoint at epoch 49 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:23:50,892 [INFO] Start training
2025-11-11 12:23:50,907 [INFO] Start training epoch 50, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:24:19,426 [INFO] Averaged stats: lr: 0.000010  loss: 0.670707
2025-11-11 12:24:19,428 [INFO] Evaluating on valid.
2025-11-11 12:26:24,190 [INFO] Averaged stats: loss: 0.686501  acc: 0.517912 ***auc: 0.5743841725244958 ***uauc: 0.5185639833975123 ***u-nDCG: 0.80147126829966
2025-11-11 12:26:24,196 [INFO] Saving checkpoint at epoch 50 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:26:24,657 [INFO] Start training
2025-11-11 12:26:24,664 [INFO] Start training epoch 51, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:26:49,689 [INFO] Averaged stats: lr: 0.000010  loss: 0.684676
2025-11-11 12:26:49,690 [INFO] Evaluating on valid.
2025-11-11 12:29:00,092 [INFO] Averaged stats: loss: 0.682696  acc: 0.476944 ***auc: 0.5775363456144198 ***uauc: 0.5251781784539121 ***u-nDCG: 0.8032247524814731
2025-11-11 12:29:00,099 [INFO] Saving checkpoint at epoch 51 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:29:00,578 [INFO] Start training
2025-11-11 12:29:00,584 [INFO] Start training epoch 52, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:29:25,726 [INFO] Averaged stats: lr: 0.000010  loss: 0.673914
2025-11-11 12:29:25,728 [INFO] Evaluating on valid.
2025-11-11 12:31:30,940 [INFO] Averaged stats: loss: 0.684125  acc: 0.513720 ***auc: 0.577784834081422 ***uauc: 0.5252832565509868 ***u-nDCG: 0.8034313035984636
2025-11-11 12:31:30,946 [INFO] Saving checkpoint at epoch 52 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:31:31,395 [INFO] Start training
2025-11-11 12:31:31,401 [INFO] Start training epoch 53, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6798  acc: 0.6250  time: 1.4178  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:01 (1.4797 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07783794403076172 uauc: 0.5083512178242555
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003049135208129883 u-nDCG: 0.8003657972644168
rank_0 auc: 0.5589047590552776
Train: data epoch: [42]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6486  time: 0.4851  data: 0.0000  max mem: 28728
Train: data epoch: [42]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6467  time: 0.5008  data: 0.0000  max mem: 28728
Train: data epoch: [42] Total time: 0:00:27 (0.5507 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6778  acc: 0.4531  time: 1.0045  data: 0.0051  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6981  acc: 0.5156  time: 1.4331  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7009  acc: 0.6094  time: 1.5097  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6962  acc: 0.5469  time: 1.5048  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6896  acc: 0.5000  time: 1.5120  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6796  acc: 0.4688  time: 1.4815  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6630  acc: 0.5625  time: 1.4266  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4818 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0781862735748291 uauc: 0.5044494589550373
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003049135208129883 u-nDCG: 0.7978886156602665
rank_0 auc: 0.5655890023028429
Train: data epoch: [43]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6606  time: 0.4884  data: 0.0000  max mem: 28728
Train: data epoch: [43]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6631  time: 0.5055  data: 0.0000  max mem: 28728
Train: data epoch: [43] Total time: 0:00:24 (0.5000 s / it)
Evaluation  [ 0/82]  eta: 0:01:21  loss: 0.6937  acc: 0.4375  time: 0.9971  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6955  acc: 0.5000  time: 1.4296  data: 0.0025  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6640  acc: 0.6250  time: 1.5082  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6831  acc: 0.5469  time: 1.5062  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6862  acc: 0.5156  time: 1.5109  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6997  acc: 0.4375  time: 1.4730  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6584  acc: 0.5000  time: 1.4170  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4785 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07594490051269531 uauc: 0.503046513275755
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030412673950195312 u-nDCG: 0.7956994164306563
rank_0 auc: 0.5693224171639529
Train: data epoch: [44]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6831  time: 0.4919  data: 0.0000  max mem: 28728
Train: data epoch: [44]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7792  time: 0.5001  data: 0.0000  max mem: 28728
Train: data epoch: [44] Total time: 0:00:25 (0.5062 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6760  acc: 0.5938  time: 1.0050  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7185  acc: 0.5469  time: 1.4269  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7377  acc: 0.7188  time: 1.5069  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7161  acc: 0.6094  time: 1.5048  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.7048  acc: 0.5625  time: 1.5086  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6830  acc: 0.5000  time: 1.4748  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6753  acc: 0.6875  time: 1.4188  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4777 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0756218433380127 uauc: 0.5108023053689968
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015439987182617188 u-nDCG: 0.8003712206359554
rank_0 auc: 0.5664172476980851
Train: data epoch: [45]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.7133  time: 0.4842  data: 0.0000  max mem: 28728
Train: data epoch: [45]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6930  time: 0.4967  data: 0.0000  max mem: 28728
Train: data epoch: [45] Total time: 0:00:25 (0.5017 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6741  acc: 0.4531  time: 1.0013  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7048  acc: 0.5156  time: 1.4378  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6974  acc: 0.6094  time: 1.5102  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6932  acc: 0.5625  time: 1.5120  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6873  acc: 0.5312  time: 1.5145  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6826  acc: 0.4688  time: 1.4770  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6620  acc: 0.5625  time: 1.4221  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4826 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07758665084838867 uauc: 0.5228761376105984
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030660629272460938 u-nDCG: 0.8036613501611302
rank_0 auc: 0.5675887887824272
Train: data epoch: [46]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.6630  time: 0.4910  data: 0.0000  max mem: 28728
Train: data epoch: [46]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7069  time: 0.5077  data: 0.0000  max mem: 28728
Train: data epoch: [46] Total time: 0:00:25 (0.5058 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6748  acc: 0.5781  time: 1.0012  data: 0.0052  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7211  acc: 0.5312  time: 1.4327  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7324  acc: 0.6875  time: 1.5096  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7122  acc: 0.5938  time: 1.5141  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.7026  acc: 0.5781  time: 1.5125  data: 0.0024  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6831  acc: 0.4844  time: 1.4811  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6750  acc: 0.7500  time: 1.4257  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:01 (1.4834 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07854008674621582 uauc: 0.5194863114187181
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003062009811401367 u-nDCG: 0.8044956868525988
rank_0 auc: 0.5659420237132389
Train: data epoch: [47]  [ 0/50]  eta: 0:00:24  lr: 0.000010  loss: 0.7428  time: 0.4874  data: 0.0000  max mem: 28728
Train: data epoch: [47]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6698  time: 0.5122  data: 0.0000  max mem: 28728
Train: data epoch: [47] Total time: 0:00:25 (0.5038 s / it)
Evaluation  [ 0/82]  eta: 0:01:21  loss: 0.6763  acc: 0.4531  time: 0.9991  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7081  acc: 0.5156  time: 1.4293  data: 0.0027  max mem: 28728
2025-11-11 12:31:57,308 [INFO] Averaged stats: lr: 0.000010  loss: 0.675409
2025-11-11 12:31:57,309 [INFO] Evaluating on valid.
2025-11-11 12:34:02,167 [INFO] Averaged stats: loss: 0.683657  acc: 0.511242 ***auc: 0.579484311075191 ***uauc: 0.5346064628730134 ***u-nDCG: 0.8087771363054936
2025-11-11 12:34:02,173 [INFO] Saving checkpoint at epoch 53 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:34:02,625 [INFO] Start training
2025-11-11 12:34:02,631 [INFO] Start training epoch 54, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:34:27,546 [INFO] Averaged stats: lr: 0.000011  loss: 0.679403
2025-11-11 12:34:27,548 [INFO] Evaluating on valid.
2025-11-11 12:36:31,862 [INFO] Averaged stats: loss: 0.682812  acc: 0.505526 ***auc: 0.578720656348097 ***uauc: 0.5351306155701512 ***u-nDCG: 0.810182531362942
2025-11-11 12:36:31,869 [INFO] Start training
2025-11-11 12:36:31,875 [INFO] Start training epoch 55, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:36:56,849 [INFO] Averaged stats: lr: 0.000011  loss: 0.679346
2025-11-11 12:36:56,850 [INFO] Evaluating on valid.
2025-11-11 12:39:23,693 [INFO] Averaged stats: loss: 0.681641  acc: 0.504573 ***auc: 0.58310213091296 ***uauc: 0.5387633226779022 ***u-nDCG: 0.812719401045452
2025-11-11 12:39:23,709 [INFO] Saving checkpoint at epoch 55 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:39:24,644 [INFO] Start training
2025-11-11 12:39:24,660 [INFO] Start training epoch 56, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:39:53,155 [INFO] Averaged stats: lr: 0.000011  loss: 0.673492
2025-11-11 12:39:53,157 [INFO] Evaluating on valid.
2025-11-11 12:42:03,850 [INFO] Averaged stats: loss: 0.680267  acc: 0.486090 ***auc: 0.5855714247320489 ***uauc: 0.5338102907118708 ***u-nDCG: 0.8072279647028292
2025-11-11 12:42:03,856 [INFO] Saving checkpoint at epoch 56 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:42:04,320 [INFO] Start training
2025-11-11 12:42:04,327 [INFO] Start training epoch 57, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:42:29,577 [INFO] Averaged stats: lr: 0.000011  loss: 0.679145
2025-11-11 12:42:29,578 [INFO] Evaluating on valid.
2025-11-11 12:44:35,230 [INFO] Averaged stats: loss: 0.679975  acc: 0.502668 ***auc: 0.58592348099453 ***uauc: 0.5432652546284518 ***u-nDCG: 0.8137942294991081
2025-11-11 12:44:35,236 [INFO] Saving checkpoint at epoch 57 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:44:35,688 [INFO] Start training
2025-11-11 12:44:35,695 [INFO] Start training epoch 58, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:45:01,128 [INFO] Averaged stats: lr: 0.000011  loss: 0.671791
2025-11-11 12:45:01,130 [INFO] Evaluating on valid.
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6947  acc: 0.6094  time: 1.5107  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6894  acc: 0.5625  time: 1.5128  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6878  acc: 0.5312  time: 1.5192  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6803  acc: 0.4844  time: 1.5194  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6607  acc: 0.5625  time: 1.4654  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:02 (1.4929 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2011563777923584 uauc: 0.5267279127668807
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.00918269157409668 u-nDCG: 0.8057121248322519
rank_0 auc: 0.5671595206867576
Train: data epoch: [48]  [ 0/50]  eta: 0:00:46  lr: 0.000010  loss: 0.5887  time: 0.9363  data: 0.0000  max mem: 28728
Train: data epoch: [48]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.6967  time: 0.5435  data: 0.0000  max mem: 28728
Train: data epoch: [48] Total time: 0:00:37 (0.7472 s / it)
Evaluation  [ 0/82]  eta: 0:01:31  loss: 0.6811  acc: 0.5938  time: 1.1171  data: 0.0223  max mem: 28728
Evaluation  [16/82]  eta: 0:01:38  loss: 0.7394  acc: 0.5156  time: 1.4900  data: 0.0039  max mem: 28728
Evaluation  [32/82]  eta: 0:01:17  loss: 0.7752  acc: 0.5469  time: 1.5894  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.7430  acc: 0.5000  time: 1.5463  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.7205  acc: 0.5938  time: 1.5416  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6948  acc: 0.5156  time: 1.5220  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6908  acc: 0.6250  time: 1.4692  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:05 (1.5310 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07623815536499023 uauc: 0.5272379334264962
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030829906463623047 u-nDCG: 0.8052558319262925
rank_0 auc: 0.5669580274989944
Train: data epoch: [49]  [ 0/50]  eta: 0:00:30  lr: 0.000010  loss: 0.7508  time: 0.6146  data: 0.0000  max mem: 28728
Train: data epoch: [49]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7079  time: 0.5147  data: 0.0000  max mem: 28728
Train: data epoch: [49] Total time: 0:00:27 (0.5487 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6745  acc: 0.5469  time: 1.0226  data: 0.0184  max mem: 28728
Evaluation  [16/82]  eta: 0:01:52  loss: 0.7114  acc: 0.5000  time: 1.7014  data: 0.0084  max mem: 28728
Evaluation  [32/82]  eta: 0:01:27  loss: 0.7187  acc: 0.6250  time: 1.7919  data: 0.0051  max mem: 28728
Evaluation  [48/82]  eta: 0:01:00  loss: 0.7059  acc: 0.5938  time: 1.7805  data: 0.0075  max mem: 28728
Evaluation  [64/82]  eta: 0:00:34  loss: 0.6944  acc: 0.5625  time: 2.1517  data: 0.0089  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6801  acc: 0.5156  time: 1.8932  data: 0.0074  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6622  acc: 0.5625  time: 1.7509  data: 0.0072  max mem: 28728
Evaluation Total time: 0:02:31 (1.8514 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2907893657684326 uauc: 0.5195084415008389
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009193181991577148 u-nDCG: 0.8037892691895785
rank_0 auc: 0.5715443361482491
Train: data epoch: [50]  [ 0/50]  eta: 0:00:27  lr: 0.000010  loss: 0.6117  time: 0.5596  data: 0.0000  max mem: 28728
Train: data epoch: [50]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7314  time: 0.5479  data: 0.0000  max mem: 28728
Train: data epoch: [50] Total time: 0:00:28 (0.5704 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6724  acc: 0.5469  time: 0.9847  data: 0.0153  max mem: 28728
Evaluation  [16/82]  eta: 0:01:39  loss: 0.7119  acc: 0.5000  time: 1.5044  data: 0.0040  max mem: 28728
Evaluation  [32/82]  eta: 0:01:17  loss: 0.7195  acc: 0.6406  time: 1.5674  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.7072  acc: 0.5938  time: 1.5179  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6925  acc: 0.5625  time: 1.5260  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6814  acc: 0.5000  time: 1.5127  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6604  acc: 0.5625  time: 1.4558  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:04 (1.5203 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0747222900390625 uauc: 0.5185639833975123
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003572702407836914 u-nDCG: 0.80147126829966
rank_0 auc: 0.5743841725244958
Train: data epoch: [51]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.7354  time: 0.4613  data: 0.0000  max mem: 28728
Train: data epoch: [51]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.7329  time: 0.4972  data: 0.0000  max mem: 28728
Train: data epoch: [51] Total time: 0:00:25 (0.5005 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6771  acc: 0.4375  time: 0.8881  data: 0.0047  max mem: 28728
Evaluation  [16/82]  eta: 0:01:58  loss: 0.6966  acc: 0.5156  time: 1.7986  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:23  loss: 0.6799  acc: 0.6094  time: 1.5588  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6873  acc: 0.5469  time: 1.5286  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6789  acc: 0.5000  time: 1.5254  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6852  acc: 0.4688  time: 1.5730  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6472  acc: 0.5625  time: 1.5182  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:10 (1.5891 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07803201675415039 uauc: 0.5251781784539121
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015270709991455078 u-nDCG: 0.8032247524814731
rank_0 auc: 0.5775363456144198
Train: data epoch: [52]  [ 0/50]  eta: 0:00:28  lr: 0.000010  loss: 0.7332  time: 0.5608  data: 0.0000  max mem: 28728
Train: data epoch: [52]  [49/50]  eta: 0:00:00  lr: 0.000010  loss: 0.5768  time: 0.4962  data: 0.0000  max mem: 28728
Train: data epoch: [52] Total time: 0:00:25 (0.5028 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6719  acc: 0.5312  time: 0.9029  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:39  loss: 0.7066  acc: 0.5156  time: 1.5021  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.7123  acc: 0.6250  time: 1.5439  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.7053  acc: 0.5781  time: 1.5201  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6870  acc: 0.5625  time: 1.5744  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6785  acc: 0.5156  time: 1.5271  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6528  acc: 0.5625  time: 1.4676  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:05 (1.5259 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07969808578491211 uauc: 0.5252832565509868
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030100345611572266 u-nDCG: 0.8034313035984636
rank_0 auc: 0.577784834081422
2025-11-11 12:47:12,660 [INFO] Averaged stats: loss: 0.681371  acc: 0.527820 ***auc: 0.5904166899910746 ***uauc: 0.535644252574114 ***u-nDCG: 0.8092173506684529
2025-11-11 12:47:12,665 [INFO] Saving checkpoint at epoch 58 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:47:13,144 [INFO] Start training
2025-11-11 12:47:13,150 [INFO] Start training epoch 59, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:47:38,124 [INFO] Averaged stats: lr: 0.000011  loss: 0.670180
2025-11-11 12:47:38,125 [INFO] Evaluating on valid.
2025-11-11 12:49:41,864 [INFO] Averaged stats: loss: 0.683100  acc: 0.540396 ***auc: 0.5910617800089357 ***uauc: 0.5384889504127927 ***u-nDCG: 0.8100626806144615
2025-11-11 12:49:41,869 [INFO] Saving checkpoint at epoch 59 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:49:42,319 [INFO] Start training
2025-11-11 12:49:42,327 [INFO] Start training epoch 60, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:50:07,259 [INFO] Averaged stats: lr: 0.000011  loss: 0.678307
2025-11-11 12:50:07,261 [INFO] Evaluating on valid.
2025-11-11 12:52:10,285 [INFO] Averaged stats: loss: 0.678411  acc: 0.516006 ***auc: 0.5945564321243395 ***uauc: 0.5593763976951187 ***u-nDCG: 0.8176061428195895
2025-11-11 12:52:10,291 [INFO] Saving checkpoint at epoch 60 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:52:10,769 [INFO] Start training
2025-11-11 12:52:10,774 [INFO] Start training epoch 61, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:52:35,854 [INFO] Averaged stats: lr: 0.000011  loss: 0.673469
2025-11-11 12:52:35,855 [INFO] Evaluating on valid.
2025-11-11 12:54:39,558 [INFO] Averaged stats: loss: 0.677145  acc: 0.514863 ***auc: 0.5961181899348732 ***uauc: 0.5549222302187441 ***u-nDCG: 0.8160301975800374
2025-11-11 12:54:39,564 [INFO] Saving checkpoint at epoch 61 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:54:40,026 [INFO] Start training
2025-11-11 12:54:40,034 [INFO] Start training epoch 62, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:55:05,087 [INFO] Averaged stats: lr: 0.000011  loss: 0.671623
2025-11-11 12:55:05,089 [INFO] Evaluating on valid.
2025-11-11 12:57:09,182 [INFO] Averaged stats: loss: 0.681000  acc: 0.544970 ***auc: 0.5975071862686476 ***uauc: 0.5551580807959852 ***u-nDCG: 0.8199890065120905
2025-11-11 12:57:09,188 [INFO] Saving checkpoint at epoch 62 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:57:09,626 [INFO] Start training
2025-11-11 12:57:09,632 [INFO] Start training epoch 63, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 12:57:34,553 [INFO] Averaged stats: lr: 0.000011  loss: 0.671514
2025-11-11 12:57:34,553 [INFO] Evaluating on valid.
2025-11-11 12:59:38,252 [INFO] Averaged stats: loss: 0.681763  acc: 0.483613 ***auc: 0.6014306610268372 ***uauc: 0.5678828319145675 ***u-nDCG: 0.8242439234422487
2025-11-11 12:59:38,258 [INFO] Saving checkpoint at epoch 63 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 12:59:38,715 [INFO] Start training
2025-11-11 12:59:38,720 [INFO] Start training epoch 64, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:00:03,571 [INFO] Averaged stats: lr: 0.000011  loss: 0.680482
2025-11-11 13:00:03,572 [INFO] Evaluating on valid.
Train: data epoch: [53]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6605  time: 0.4718  data: 0.0000  max mem: 28728
Train: data epoch: [53]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6222  time: 0.5075  data: 0.0000  max mem: 28728
Train: data epoch: [53] Total time: 0:00:25 (0.5181 s / it)
Evaluation  [ 0/82]  eta: 0:01:17  loss: 0.6737  acc: 0.5312  time: 0.9472  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:38  loss: 0.7098  acc: 0.5625  time: 1.4870  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.7108  acc: 0.6094  time: 1.5694  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.7018  acc: 0.5469  time: 1.5483  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6872  acc: 0.5625  time: 1.5296  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6755  acc: 0.5156  time: 1.5020  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6529  acc: 0.5625  time: 1.4448  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:04 (1.5216 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07812285423278809 uauc: 0.5346064628730134
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030765533447265625 u-nDCG: 0.8087771363054936
rank_0 auc: 0.579484311075191
Train: data epoch: [54]  [ 0/50]  eta: 0:00:23  lr: 0.000011  loss: 0.7218  time: 0.4607  data: 0.0000  max mem: 28728
Train: data epoch: [54]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.7125  time: 0.5004  data: 0.0000  max mem: 28728
Train: data epoch: [54] Total time: 0:00:24 (0.4983 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6730  acc: 0.5312  time: 0.8914  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7138  acc: 0.5625  time: 1.4512  data: 0.0024  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.7021  acc: 0.6094  time: 1.5552  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6941  acc: 0.5625  time: 1.5514  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6858  acc: 0.5312  time: 1.5365  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6740  acc: 0.4844  time: 1.5118  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6521  acc: 0.5625  time: 1.4545  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:04 (1.5149 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07645964622497559 uauc: 0.5351306155701512
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030357837677001953 u-nDCG: 0.810182531362942
rank_0 auc: 0.578720656348097
Train: data epoch: [55]  [ 0/50]  eta: 0:00:25  lr: 0.000011  loss: 0.6604  time: 0.5009  data: 0.0000  max mem: 28728
Train: data epoch: [55]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.7069  time: 0.5016  data: 0.0000  max mem: 28728
Train: data epoch: [55] Total time: 0:00:24 (0.4995 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6717  acc: 0.5000  time: 0.9039  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:51  loss: 0.7114  acc: 0.5625  time: 1.6826  data: 0.0041  max mem: 28728
Evaluation  [32/82]  eta: 0:01:26  loss: 0.6987  acc: 0.6250  time: 1.7501  data: 0.0072  max mem: 28728
Evaluation  [48/82]  eta: 0:01:00  loss: 0.6938  acc: 0.5781  time: 1.8219  data: 0.0084  max mem: 28728
Evaluation  [64/82]  eta: 0:00:32  loss: 0.6820  acc: 0.5469  time: 1.8091  data: 0.0090  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6748  acc: 0.5156  time: 1.8823  data: 0.0071  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6517  acc: 0.5625  time: 1.8245  data: 0.0066  max mem: 28728
Evaluation Total time: 0:02:26 (1.7872 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.25734519958496094 uauc: 0.5387633226779022
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.013824939727783203 u-nDCG: 0.812719401045452
rank_0 auc: 0.58310213091296
Train: data epoch: [56]  [ 0/50]  eta: 0:00:29  lr: 0.000011  loss: 0.6883  time: 0.5857  data: 0.0000  max mem: 28728
Train: data epoch: [56]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6672  time: 0.5707  data: 0.0000  max mem: 28728
Train: data epoch: [56] Total time: 0:00:28 (0.5699 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6735  acc: 0.4688  time: 0.9869  data: 0.0147  max mem: 28728
Evaluation  [16/82]  eta: 0:01:45  loss: 0.7039  acc: 0.5156  time: 1.5974  data: 0.0056  max mem: 28728
Evaluation  [32/82]  eta: 0:01:22  loss: 0.6817  acc: 0.6094  time: 1.7065  data: 0.0044  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.6867  acc: 0.5781  time: 1.6738  data: 0.0042  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6748  acc: 0.5312  time: 1.5390  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6780  acc: 0.4688  time: 1.4921  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6422  acc: 0.5625  time: 1.4387  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:10 (1.5926 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07903623580932617 uauc: 0.5338102907118708
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.00152587890625 u-nDCG: 0.8072279647028292
rank_0 auc: 0.5855714247320489
Train: data epoch: [57]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.6734  time: 0.4982  data: 0.0000  max mem: 28728
Train: data epoch: [57]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6890  time: 0.5044  data: 0.0000  max mem: 28728
Train: data epoch: [57] Total time: 0:00:25 (0.5050 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 0.6695  acc: 0.5000  time: 0.9262  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7122  acc: 0.5625  time: 1.4833  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.6891  acc: 0.6250  time: 1.5476  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6881  acc: 0.5938  time: 1.5615  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6764  acc: 0.5312  time: 1.5585  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6764  acc: 0.5000  time: 1.5313  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6427  acc: 0.5625  time: 1.4747  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:05 (1.5312 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08069562911987305 uauc: 0.5432652546284518
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0032172203063964844 u-nDCG: 0.8137942294991081
rank_0 auc: 0.58592348099453
Train: data epoch: [58]  [ 0/50]  eta: 0:00:25  lr: 0.000011  loss: 0.6221  time: 0.5054  data: 0.0000  max mem: 28728
Train: data epoch: [58]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6291  time: 0.5151  data: 0.0000  max mem: 28728
Train: data epoch: [58] Total time: 0:00:25 (0.5087 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6679  acc: 0.5625  time: 0.9117  data: 0.0047  max mem: 28728
Evaluation  [16/82]  eta: 0:01:55  loss: 0.7136  acc: 0.5156  time: 1.7477  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:23  loss: 0.7114  acc: 0.6562  time: 1.6079  data: 0.0024  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.7022  acc: 0.5938  time: 1.5794  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6789  acc: 0.5781  time: 1.5769  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6749  acc: 0.5156  time: 1.5594  data: 0.0027  max mem: 28728
2025-11-11 13:02:07,232 [INFO] Averaged stats: loss: 0.679029  acc: 0.488186 ***auc: 0.6024454026960887 ***uauc: 0.5715534846525383 ***u-nDCG: 0.8248045367751449
2025-11-11 13:02:07,238 [INFO] Saving checkpoint at epoch 64 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:02:07,694 [INFO] Start training
2025-11-11 13:02:07,700 [INFO] Start training epoch 65, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:02:32,458 [INFO] Averaged stats: lr: 0.000011  loss: 0.681479
2025-11-11 13:02:32,459 [INFO] Evaluating on valid.
2025-11-11 13:04:35,291 [INFO] Averaged stats: loss: 0.678640  acc: 0.549543 ***auc: 0.6046161688408974 ***uauc: 0.5708432913700454 ***u-nDCG: 0.824964680602238
2025-11-11 13:04:35,296 [INFO] Saving checkpoint at epoch 65 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:04:35,754 [INFO] Start training
2025-11-11 13:04:35,761 [INFO] Start training epoch 66, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:05:00,581 [INFO] Averaged stats: lr: 0.000011  loss: 0.659913
2025-11-11 13:05:00,582 [INFO] Evaluating on valid.
2025-11-11 13:07:03,313 [INFO] Averaged stats: loss: 0.672713  acc: 0.529154 ***auc: 0.6101831420137944 ***uauc: 0.5872824500785294 ***u-nDCG: 0.8309142047080007
2025-11-11 13:07:03,317 [INFO] Saving checkpoint at epoch 66 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:07:03,787 [INFO] Start training
2025-11-11 13:07:03,793 [INFO] Start training epoch 67, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:07:28,608 [INFO] Averaged stats: lr: 0.000011  loss: 0.667395
2025-11-11 13:07:28,610 [INFO] Evaluating on valid.
2025-11-11 13:09:31,231 [INFO] Averaged stats: loss: 0.673162  acc: 0.504192 ***auc: 0.6137610938184651 ***uauc: 0.5912650201867594 ***u-nDCG: 0.8318226159793345
2025-11-11 13:09:31,237 [INFO] Saving checkpoint at epoch 67 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:09:31,691 [INFO] Start training
2025-11-11 13:09:31,697 [INFO] Start training epoch 68, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:09:56,514 [INFO] Averaged stats: lr: 0.000011  loss: 0.657145
2025-11-11 13:09:56,516 [INFO] Evaluating on valid.
2025-11-11 13:11:58,799 [INFO] Averaged stats: loss: 0.670915  acc: 0.540777 ***auc: 0.6128747910640371 ***uauc: 0.5975681853701872 ***u-nDCG: 0.8336616524305709
2025-11-11 13:11:58,805 [INFO] Start training
2025-11-11 13:11:58,812 [INFO] Start training epoch 69, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:12:23,611 [INFO] Averaged stats: lr: 0.000011  loss: 0.653550
2025-11-11 13:12:23,613 [INFO] Evaluating on valid.
2025-11-11 13:14:27,222 [INFO] Averaged stats: loss: 0.672001  acc: 0.559642 ***auc: 0.6152385125496699 ***uauc: 0.6095979552744368 ***u-nDCG: 0.8394997925669963
2025-11-11 13:14:27,228 [INFO] Saving checkpoint at epoch 69 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:14:27,682 [INFO] Start training
2025-11-11 13:14:27,689 [INFO] Start training epoch 70, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6427  acc: 0.5625  time: 1.5012  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:11 (1.6029 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07622933387756348 uauc: 0.535644252574114
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0020165443420410156 u-nDCG: 0.8092173506684529
rank_0 auc: 0.5904166899910746
Train: data epoch: [59]  [ 0/50]  eta: 0:00:23  lr: 0.000011  loss: 0.6633  time: 0.4671  data: 0.0000  max mem: 28728
Train: data epoch: [59]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6564  time: 0.5014  data: 0.0000  max mem: 28728
Train: data epoch: [59] Total time: 0:00:24 (0.4995 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6675  acc: 0.5781  time: 0.8808  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7220  acc: 0.4219  time: 1.4431  data: 0.0025  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7210  acc: 0.7031  time: 1.5294  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7084  acc: 0.5469  time: 1.5244  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6800  acc: 0.5938  time: 1.5567  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6733  acc: 0.5156  time: 1.5311  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6452  acc: 0.6250  time: 1.4733  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:03 (1.5079 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0773930549621582 uauc: 0.5384889504127927
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030803680419921875 u-nDCG: 0.8100626806144615
rank_0 auc: 0.5910617800089357
Train: data epoch: [60]  [ 0/50]  eta: 0:00:23  lr: 0.000011  loss: 0.7010  time: 0.4720  data: 0.0000  max mem: 28728
Train: data epoch: [60]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6278  time: 0.5017  data: 0.0000  max mem: 28728
Train: data epoch: [60] Total time: 0:00:24 (0.4987 s / it)
Evaluation  [ 0/82]  eta: 0:01:10  loss: 0.6674  acc: 0.5625  time: 0.8637  data: 0.0050  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7162  acc: 0.5156  time: 1.4307  data: 0.0025  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6989  acc: 0.6250  time: 1.5141  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6928  acc: 0.5625  time: 1.5353  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6717  acc: 0.5781  time: 1.5633  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6680  acc: 0.5156  time: 1.4971  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6438  acc: 0.5625  time: 1.4410  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:02 (1.4992 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07820796966552734 uauc: 0.5593763976951187
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.002852916717529297 u-nDCG: 0.8176061428195895
rank_0 auc: 0.5945564321243395
Train: data epoch: [61]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.7205  time: 0.4971  data: 0.0000  max mem: 28728
Train: data epoch: [61]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.7139  time: 0.4960  data: 0.0000  max mem: 28728
Train: data epoch: [61] Total time: 0:00:25 (0.5016 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6704  acc: 0.5781  time: 0.8726  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7147  acc: 0.5625  time: 1.4490  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6936  acc: 0.6406  time: 1.5345  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6907  acc: 0.5625  time: 1.5318  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6691  acc: 0.5625  time: 1.5488  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6696  acc: 0.5000  time: 1.5165  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6423  acc: 0.5625  time: 1.4572  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:03 (1.5074 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.077301025390625 uauc: 0.5549222302187441
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003050088882446289 u-nDCG: 0.8160301975800374
rank_0 auc: 0.5961181899348732
Train: data epoch: [62]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.6291  time: 0.4934  data: 0.0000  max mem: 28728
Train: data epoch: [62]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6466  time: 0.5071  data: 0.0000  max mem: 28728
Train: data epoch: [62] Total time: 0:00:25 (0.5011 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6678  acc: 0.5469  time: 0.8839  data: 0.0044  max mem: 28728
Evaluation  [16/82]  eta: 0:01:36  loss: 0.7185  acc: 0.4531  time: 1.4632  data: 0.0025  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.7196  acc: 0.6719  time: 1.5458  data: 0.0023  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7088  acc: 0.5469  time: 1.5321  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6809  acc: 0.6094  time: 1.5359  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6743  acc: 0.5625  time: 1.5112  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6399  acc: 0.6250  time: 1.4555  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:04 (1.5123 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07420134544372559 uauc: 0.5551580807959852
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.002559661865234375 u-nDCG: 0.8199890065120905
rank_0 auc: 0.5975071862686476
Train: data epoch: [63]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.6969  time: 0.4838  data: 0.0000  max mem: 28728
Train: data epoch: [63]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6594  time: 0.4997  data: 0.0000  max mem: 28728
Train: data epoch: [63] Total time: 0:00:24 (0.4984 s / it)
Evaluation  [ 0/82]  eta: 0:01:26  loss: 0.6819  acc: 0.4531  time: 1.0518  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7053  acc: 0.5156  time: 1.4479  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6588  acc: 0.6094  time: 1.5269  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6790  acc: 0.5781  time: 1.5315  data: 0.0023  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6685  acc: 0.5312  time: 1.5315  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6882  acc: 0.5000  time: 1.5321  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6321  acc: 0.5625  time: 1.4757  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:03 (1.5074 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07682561874389648 uauc: 0.5678828319145675
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030481815338134766 u-nDCG: 0.8242439234422487
rank_0 auc: 0.6014306610268372
Train: data epoch: [64]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.7115  time: 0.4961  data: 0.0000  max mem: 28728
Train: data epoch: [64]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6547  time: 0.5035  data: 0.0000  max mem: 28728
Train: data epoch: [64] Total time: 0:00:24 (0.4970 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6822  acc: 0.4688  time: 0.8844  data: 0.0049  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7057  acc: 0.5156  time: 1.4510  data: 0.0028  max mem: 28728
2025-11-11 13:14:52,373 [INFO] Averaged stats: lr: 0.000011  loss: 0.658096
2025-11-11 13:14:52,375 [INFO] Evaluating on valid.
2025-11-11 13:16:55,504 [INFO] Averaged stats: loss: 0.669107  acc: 0.558689 ***auc: 0.6235134680452147 ***uauc: 0.5962398248055334 ***u-nDCG: 0.8347386576875679
2025-11-11 13:16:55,510 [INFO] Saving checkpoint at epoch 70 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:16:55,969 [INFO] Start training
2025-11-11 13:16:55,976 [INFO] Start training epoch 71, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:17:20,883 [INFO] Averaged stats: lr: 0.000011  loss: 0.655608
2025-11-11 13:17:20,885 [INFO] Evaluating on valid.
2025-11-11 13:19:24,015 [INFO] Averaged stats: loss: 0.670378  acc: 0.574695 ***auc: 0.6256244692614495 ***uauc: 0.6099839298929859 ***u-nDCG: 0.8406808575325763
2025-11-11 13:19:24,020 [INFO] Saving checkpoint at epoch 71 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:19:24,474 [INFO] Start training
2025-11-11 13:19:24,480 [INFO] Start training epoch 72, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:19:49,587 [INFO] Averaged stats: lr: 0.000011  loss: 0.667822
2025-11-11 13:19:49,588 [INFO] Evaluating on valid.
2025-11-11 13:21:52,317 [INFO] Averaged stats: loss: 0.668064  acc: 0.529726 ***auc: 0.6254808107064304 ***uauc: 0.6084272044814498 ***u-nDCG: 0.8377879802148437
2025-11-11 13:21:52,323 [INFO] Start training
2025-11-11 13:21:52,330 [INFO] Start training epoch 73, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:22:17,156 [INFO] Averaged stats: lr: 0.000011  loss: 0.661833
2025-11-11 13:22:17,158 [INFO] Evaluating on valid.
2025-11-11 13:24:19,788 [INFO] Averaged stats: loss: 0.666684  acc: 0.570503 ***auc: 0.6273791081706601 ***uauc: 0.6157418804549039 ***u-nDCG: 0.8407962635953722
2025-11-11 13:24:19,794 [INFO] Saving checkpoint at epoch 73 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:24:20,257 [INFO] Start training
2025-11-11 13:24:20,263 [INFO] Start training epoch 74, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:24:45,234 [INFO] Averaged stats: lr: 0.000011  loss: 0.638503
2025-11-11 13:24:45,235 [INFO] Evaluating on valid.
2025-11-11 13:26:48,673 [INFO] Averaged stats: loss: 0.678141  acc: 0.601181 ***auc: 0.6278054808225852 ***uauc: 0.610353214798213 ***u-nDCG: 0.8371169673788674
2025-11-11 13:26:48,679 [INFO] Saving checkpoint at epoch 74 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:26:49,130 [INFO] Start training
2025-11-11 13:26:49,138 [INFO] Start training epoch 75, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:27:13,983 [INFO] Averaged stats: lr: 0.000011  loss: 0.647051
2025-11-11 13:27:13,985 [INFO] Evaluating on valid.
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6628  acc: 0.6094  time: 1.5392  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6779  acc: 0.5781  time: 1.5197  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6727  acc: 0.5312  time: 1.5388  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6835  acc: 0.5000  time: 1.5206  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6314  acc: 0.5625  time: 1.4642  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:03 (1.5070 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07370376586914062 uauc: 0.5715534846525383
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003084421157836914 u-nDCG: 0.8248045367751449
rank_0 auc: 0.6024454026960887
Train: data epoch: [65]  [ 0/50]  eta: 0:00:23  lr: 0.000011  loss: 0.6709  time: 0.4792  data: 0.0000  max mem: 28728
Train: data epoch: [65]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.7852  time: 0.4982  data: 0.0000  max mem: 28728
Train: data epoch: [65] Total time: 0:00:24 (0.4952 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6609  acc: 0.5781  time: 0.8756  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7224  acc: 0.4375  time: 1.4331  data: 0.0025  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7175  acc: 0.6406  time: 1.5190  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7063  acc: 0.5781  time: 1.5397  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6774  acc: 0.5938  time: 1.5570  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6731  acc: 0.5625  time: 1.4850  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6325  acc: 0.6250  time: 1.4304  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:02 (1.4969 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07436728477478027 uauc: 0.5708432913700454
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003033161163330078 u-nDCG: 0.824964680602238
rank_0 auc: 0.6046161688408974
Train: data epoch: [66]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.5587  time: 0.4958  data: 0.0000  max mem: 28728
Train: data epoch: [66]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6897  time: 0.4982  data: 0.0000  max mem: 28728
Train: data epoch: [66] Total time: 0:00:24 (0.4964 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6606  acc: 0.5625  time: 0.8758  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7102  acc: 0.5000  time: 1.4299  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6896  acc: 0.6406  time: 1.5352  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6877  acc: 0.5781  time: 1.5307  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6690  acc: 0.5625  time: 1.5226  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6716  acc: 0.5469  time: 1.4913  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6235  acc: 0.5625  time: 1.4373  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:02 (1.4956 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07545304298400879 uauc: 0.5872824500785294
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030548572540283203 u-nDCG: 0.8309142047080007
rank_0 auc: 0.6101831420137944
Train: data epoch: [67]  [ 0/50]  eta: 0:00:22  lr: 0.000011  loss: 0.6555  time: 0.4552  data: 0.0000  max mem: 28728
Train: data epoch: [67]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6225  time: 0.4981  data: 0.0000  max mem: 28728
Train: data epoch: [67] Total time: 0:00:24 (0.4963 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6683  acc: 0.5156  time: 0.8771  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7070  acc: 0.5312  time: 1.4472  data: 0.0031  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6666  acc: 0.6719  time: 1.5329  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6765  acc: 0.5781  time: 1.5164  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6670  acc: 0.5312  time: 1.5165  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6775  acc: 0.5000  time: 1.4969  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6193  acc: 0.5625  time: 1.4407  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:02 (1.4943 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07597684860229492 uauc: 0.5912650201867594
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030281543731689453 u-nDCG: 0.8318226159793345
rank_0 auc: 0.6137610938184651
Train: data epoch: [68]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.6554  time: 0.4932  data: 0.0000  max mem: 28728
Train: data epoch: [68]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6319  time: 0.4944  data: 0.0000  max mem: 28728
Train: data epoch: [68] Total time: 0:00:24 (0.4963 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6530  acc: 0.5469  time: 1.0207  data: 0.0041  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7205  acc: 0.4375  time: 1.4335  data: 0.0025  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6903  acc: 0.6406  time: 1.5125  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6855  acc: 0.5469  time: 1.5213  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6622  acc: 0.5625  time: 1.5245  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6683  acc: 0.5625  time: 1.5004  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6153  acc: 0.5625  time: 1.4437  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:02 (1.4902 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07587051391601562 uauc: 0.5975681853701872
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015149116516113281 u-nDCG: 0.8336616524305709
rank_0 auc: 0.6128747910640371
Train: data epoch: [69]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.6986  time: 0.4855  data: 0.0000  max mem: 28728
Train: data epoch: [69]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6273  time: 0.4945  data: 0.0000  max mem: 28728
Train: data epoch: [69] Total time: 0:00:24 (0.4960 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6521  acc: 0.5938  time: 1.0256  data: 0.0060  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7347  acc: 0.4688  time: 1.4473  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7058  acc: 0.6406  time: 1.5342  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6909  acc: 0.5469  time: 1.5240  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6682  acc: 0.5781  time: 1.5276  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6627  acc: 0.5938  time: 1.5270  data: 0.0022  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6150  acc: 0.6875  time: 1.4700  data: 0.0021  max mem: 28728
Evaluation Total time: 0:02:03 (1.5063 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07710886001586914 uauc: 0.6095979552744368
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003148794174194336 u-nDCG: 0.8394997925669963
rank_0 auc: 0.6152385125496699
2025-11-11 13:29:16,852 [INFO] Averaged stats: loss: 0.676287  acc: 0.520579 ***auc: 0.6314993988613333 ***uauc: 0.6196641633600348 ***u-nDCG: 0.8404443744389215
2025-11-11 13:29:16,858 [INFO] Saving checkpoint at epoch 75 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:29:17,315 [INFO] Start training
2025-11-11 13:29:17,323 [INFO] Start training epoch 76, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:29:42,395 [INFO] Averaged stats: lr: 0.000011  loss: 0.666169
2025-11-11 13:29:42,397 [INFO] Evaluating on valid.
2025-11-11 13:31:45,983 [INFO] Averaged stats: loss: 0.670498  acc: 0.591082 ***auc: 0.6317772872186649 ***uauc: 0.6178024839560379 ***u-nDCG: 0.8422942136992752
2025-11-11 13:31:45,989 [INFO] Saving checkpoint at epoch 76 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:31:46,439 [INFO] Start training
2025-11-11 13:31:46,447 [INFO] Start training epoch 77, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:32:11,341 [INFO] Averaged stats: lr: 0.000011  loss: 0.664444
2025-11-11 13:32:11,343 [INFO] Evaluating on valid.
2025-11-11 13:34:15,356 [INFO] Averaged stats: loss: 0.665223  acc: 0.533918 ***auc: 0.6344836362140722 ***uauc: 0.6297575715501392 ***u-nDCG: 0.8496506827238691
2025-11-11 13:34:15,363 [INFO] Saving checkpoint at epoch 77 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:34:15,819 [INFO] Start training
2025-11-11 13:34:15,825 [INFO] Start training epoch 78, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:34:40,546 [INFO] Averaged stats: lr: 0.000011  loss: 0.650979
2025-11-11 13:34:40,548 [INFO] Evaluating on valid.
2025-11-11 13:36:45,514 [INFO] Averaged stats: loss: 0.665149  acc: 0.532965 ***auc: 0.6383890701304686 ***uauc: 0.6269316742097296 ***u-nDCG: 0.8463446340009678
2025-11-11 13:36:45,520 [INFO] Saving checkpoint at epoch 78 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:36:45,952 [INFO] Start training
2025-11-11 13:36:45,960 [INFO] Start training epoch 79, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:37:10,792 [INFO] Averaged stats: lr: 0.000011  loss: 0.667045
2025-11-11 13:37:10,794 [INFO] Evaluating on valid.
2025-11-11 13:39:09,141 [INFO] Averaged stats: loss: 0.665848  acc: 0.529154 ***auc: 0.6401292318209564 ***uauc: 0.6142817618838288 ***u-nDCG: 0.8396729885389371
2025-11-11 13:39:09,147 [INFO] Saving checkpoint at epoch 79 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:39:09,610 [INFO] Start training
2025-11-11 13:39:09,618 [INFO] Start training epoch 80, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:39:35,333 [INFO] Averaged stats: lr: 0.000011  loss: 0.650441
2025-11-11 13:39:35,335 [INFO] Evaluating on valid.
2025-11-11 13:41:59,965 [INFO] Averaged stats: loss: 0.665722  acc: 0.586509 ***auc: 0.6403368128647982 ***uauc: 0.6121304633554817 ***u-nDCG: 0.8414749085225032
2025-11-11 13:41:59,980 [INFO] Saving checkpoint at epoch 80 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:42:00,733 [INFO] Start training
2025-11-11 13:42:00,747 [INFO] Start training epoch 81, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:42:28,669 [INFO] Averaged stats: lr: 0.000011  loss: 0.661105
2025-11-11 13:42:28,673 [INFO] Evaluating on valid.
Train: data epoch: [70]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.7123  time: 0.4855  data: 0.0000  max mem: 28728
Train: data epoch: [70]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6362  time: 0.4941  data: 0.0000  max mem: 28728
Train: data epoch: [70] Total time: 0:00:24 (0.4937 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6588  acc: 0.5781  time: 0.8677  data: 0.0056  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7215  acc: 0.4844  time: 1.4398  data: 0.0032  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7101  acc: 0.6250  time: 1.5368  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6962  acc: 0.5781  time: 1.5293  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6700  acc: 0.5781  time: 1.5303  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6539  acc: 0.6094  time: 1.5094  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6088  acc: 0.5625  time: 1.4539  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:03 (1.5005 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07631230354309082 uauc: 0.5962398248055334
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0035686492919921875 u-nDCG: 0.8347386576875679
rank_0 auc: 0.6235134680452147
Train: data epoch: [71]  [ 0/50]  eta: 0:00:23  lr: 0.000011  loss: 0.5693  time: 0.4647  data: 0.0000  max mem: 28728
Train: data epoch: [71]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6536  time: 0.5004  data: 0.0000  max mem: 28728
Train: data epoch: [71] Total time: 0:00:24 (0.4981 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6542  acc: 0.5781  time: 0.8708  data: 0.0047  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7320  acc: 0.5156  time: 1.4312  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7161  acc: 0.6094  time: 1.5273  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6955  acc: 0.5469  time: 1.5406  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6740  acc: 0.6094  time: 1.5589  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6590  acc: 0.6094  time: 1.4944  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6049  acc: 0.6875  time: 1.4367  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:03 (1.5005 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07355332374572754 uauc: 0.6099839298929859
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030913352966308594 u-nDCG: 0.8406808575325763
rank_0 auc: 0.6256244692614495
Train: data epoch: [72]  [ 0/50]  eta: 0:00:25  lr: 0.000011  loss: 0.8444  time: 0.5082  data: 0.0000  max mem: 28728
Train: data epoch: [72]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6597  time: 0.5060  data: 0.0000  max mem: 28728
Train: data epoch: [72] Total time: 0:00:25 (0.5021 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6532  acc: 0.5312  time: 0.8662  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7234  acc: 0.4844  time: 1.4314  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6733  acc: 0.6250  time: 1.5344  data: 0.0024  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6688  acc: 0.5156  time: 1.5216  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6618  acc: 0.5781  time: 1.5267  data: 0.0024  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6630  acc: 0.5781  time: 1.5000  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6000  acc: 0.5625  time: 1.4437  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:02 (1.4956 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07731509208679199 uauc: 0.6084272044814498
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030965805053710938 u-nDCG: 0.8377879802148437
rank_0 auc: 0.6254808107064304
Train: data epoch: [73]  [ 0/50]  eta: 0:00:23  lr: 0.000011  loss: 0.6461  time: 0.4774  data: 0.0000  max mem: 28728
Train: data epoch: [73]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.8067  time: 0.4999  data: 0.0000  max mem: 28728
Train: data epoch: [73] Total time: 0:00:24 (0.4965 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6406  acc: 0.5938  time: 0.8747  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:36  loss: 0.7240  acc: 0.4844  time: 1.4576  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7092  acc: 0.6250  time: 1.5302  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6917  acc: 0.5469  time: 1.5172  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6634  acc: 0.5938  time: 1.5153  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6651  acc: 0.5469  time: 1.4914  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5820  acc: 0.6875  time: 1.4380  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:02 (1.4944 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07455635070800781 uauc: 0.6157418804549039
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003083944320678711 u-nDCG: 0.8407962635953722
rank_0 auc: 0.6273791081706601
Train: data epoch: [74]  [ 0/50]  eta: 0:00:25  lr: 0.000011  loss: 0.6014  time: 0.5165  data: 0.0000  max mem: 28728
Train: data epoch: [74]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.5961  time: 0.4956  data: 0.0000  max mem: 28728
Train: data epoch: [74] Total time: 0:00:24 (0.4994 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6462  acc: 0.6094  time: 1.0211  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7395  acc: 0.6094  time: 1.4377  data: 0.0024  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7504  acc: 0.5781  time: 1.5221  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7235  acc: 0.5156  time: 1.5254  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6795  acc: 0.6250  time: 1.5342  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6709  acc: 0.5938  time: 1.5368  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5792  acc: 0.8125  time: 1.4788  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:03 (1.5043 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07460856437683105 uauc: 0.610353214798213
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003069162368774414 u-nDCG: 0.8371169673788674
rank_0 auc: 0.6278054808225852
Train: data epoch: [75]  [ 0/50]  eta: 0:00:23  lr: 0.000011  loss: 0.7446  time: 0.4798  data: 0.0000  max mem: 28728
Train: data epoch: [75]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.5834  time: 0.4974  data: 0.0000  max mem: 28728
Train: data epoch: [75] Total time: 0:00:24 (0.4969 s / it)
Evaluation  [ 0/82]  eta: 0:01:10  loss: 0.6621  acc: 0.5156  time: 0.8646  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7204  acc: 0.5000  time: 1.4295  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6637  acc: 0.6562  time: 1.5183  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6735  acc: 0.5312  time: 1.5188  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6710  acc: 0.5469  time: 1.5482  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6804  acc: 0.5469  time: 1.5269  data: 0.0026  max mem: 28728
2025-11-11 13:44:52,105 [INFO] Averaged stats: loss: 0.675461  acc: 0.602706 ***auc: 0.6415883127417789 ***uauc: 0.6297387513997008 ***u-nDCG: 0.8460916384265653
2025-11-11 13:44:52,120 [INFO] Saving checkpoint at epoch 81 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:44:52,805 [INFO] Start training
2025-11-11 13:44:52,820 [INFO] Start training epoch 82, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:45:20,155 [INFO] Averaged stats: lr: 0.000011  loss: 0.659700
2025-11-11 13:45:20,155 [INFO] Evaluating on valid.
2025-11-11 13:47:37,948 [INFO] Averaged stats: loss: 0.664365  acc: 0.596037 ***auc: 0.6431102025192142 ***uauc: 0.6259818313355671 ***u-nDCG: 0.8437448612916697
2025-11-11 13:47:37,961 [INFO] Saving checkpoint at epoch 82 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:47:38,667 [INFO] Start training
2025-11-11 13:47:38,689 [INFO] Start training epoch 83, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:48:08,158 [INFO] Averaged stats: lr: 0.000011  loss: 0.650710
2025-11-11 13:48:08,166 [INFO] Evaluating on valid.
2025-11-11 13:50:27,795 [INFO] Averaged stats: loss: 0.670381  acc: 0.604802 ***auc: 0.6442100999314151 ***uauc: 0.6228362479085814 ***u-nDCG: 0.8442454222530626
2025-11-11 13:50:27,808 [INFO] Saving checkpoint at epoch 83 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:50:28,681 [INFO] Start training
2025-11-11 13:50:28,710 [INFO] Start training epoch 84, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:50:58,581 [INFO] Averaged stats: lr: 0.000011  loss: 0.637789
2025-11-11 13:50:58,581 [INFO] Evaluating on valid.
2025-11-11 13:53:13,284 [INFO] Averaged stats: loss: 0.673810  acc: 0.610328 ***auc: 0.6453966379295112 ***uauc: 0.6266442909419586 ***u-nDCG: 0.8451185756385348
2025-11-11 13:53:13,296 [INFO] Saving checkpoint at epoch 84 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:53:14,092 [INFO] Start training
2025-11-11 13:53:14,110 [INFO] Start training epoch 85, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:53:41,817 [INFO] Averaged stats: lr: 0.000011  loss: 0.622993
2025-11-11 13:53:41,819 [INFO] Evaluating on valid.
2025-11-11 13:55:54,708 [INFO] Averaged stats: loss: 0.660244  acc: 0.589367 ***auc: 0.6466485090172285 ***uauc: 0.6202460160646154 ***u-nDCG: 0.841022279237881
2025-11-11 13:55:54,720 [INFO] Saving checkpoint at epoch 85 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:55:55,475 [INFO] Start training
2025-11-11 13:55:55,498 [INFO] Start training epoch 86, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 13:56:22,544 [INFO] Averaged stats: lr: 0.000011  loss: 0.660359
2025-11-11 13:56:22,551 [INFO] Evaluating on valid.
2025-11-11 13:58:37,016 [INFO] Averaged stats: loss: 0.658491  acc: 0.560213 ***auc: 0.6480891036433739 ***uauc: 0.6345460740152302 ***u-nDCG: 0.8462887032772624
2025-11-11 13:58:37,029 [INFO] Saving checkpoint at epoch 86 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 13:58:37,742 [INFO] Start training
2025-11-11 13:58:37,760 [INFO] Start training epoch 87, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5808  acc: 0.5625  time: 1.4725  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:02 (1.4972 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07645630836486816 uauc: 0.6196641633600348
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015056133270263672 u-nDCG: 0.8404443744389215
rank_0 auc: 0.6314993988613333
Train: data epoch: [76]  [ 0/50]  eta: 0:00:23  lr: 0.000011  loss: 0.5929  time: 0.4721  data: 0.0000  max mem: 28728
Train: data epoch: [76]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.5879  time: 0.4975  data: 0.0000  max mem: 28728
Train: data epoch: [76] Total time: 0:00:25 (0.5014 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6601  acc: 0.6562  time: 0.8753  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7297  acc: 0.5312  time: 1.4370  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7312  acc: 0.6250  time: 1.5349  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7062  acc: 0.5625  time: 1.5478  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6873  acc: 0.6719  time: 1.5388  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6574  acc: 0.5938  time: 1.5121  data: 0.0022  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5874  acc: 0.7500  time: 1.4552  data: 0.0021  max mem: 28728
Evaluation Total time: 0:02:03 (1.5060 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07516312599182129 uauc: 0.6178024839560379
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030329227447509766 u-nDCG: 0.8422942136992752
rank_0 auc: 0.6317772872186649
Train: data epoch: [77]  [ 0/50]  eta: 0:00:25  lr: 0.000011  loss: 0.7963  time: 0.5052  data: 0.0000  max mem: 28728
Train: data epoch: [77]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.7099  time: 0.4940  data: 0.0000  max mem: 28728
Train: data epoch: [77] Total time: 0:00:24 (0.4979 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6511  acc: 0.5469  time: 0.8954  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7166  acc: 0.4844  time: 1.4279  data: 0.0024  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.6736  acc: 0.6562  time: 1.5626  data: 0.0023  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6670  acc: 0.5469  time: 1.5315  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6662  acc: 0.5781  time: 1.5441  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6594  acc: 0.5625  time: 1.5130  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5820  acc: 0.5625  time: 1.4554  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:03 (1.5113 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0758671760559082 uauc: 0.6297575715501392
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030639171600341797 u-nDCG: 0.8496506827238691
rank_0 auc: 0.6344836362140722
Train: data epoch: [78]  [ 0/50]  eta: 0:00:23  lr: 0.000011  loss: 0.5467  time: 0.4651  data: 0.0000  max mem: 28728
Train: data epoch: [78]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6101  time: 0.4983  data: 0.0000  max mem: 28728
Train: data epoch: [78] Total time: 0:00:24 (0.4944 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6494  acc: 0.5312  time: 0.8868  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:48  loss: 0.7089  acc: 0.4688  time: 1.6386  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:21  loss: 0.6736  acc: 0.6562  time: 1.6689  data: 0.0022  max mem: 28728
Evaluation  [48/82]  eta: 0:00:53  loss: 0.6693  acc: 0.5469  time: 1.4657  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6646  acc: 0.5312  time: 1.4744  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6605  acc: 0.5469  time: 1.4464  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5699  acc: 0.5625  time: 1.3915  data: 0.0028  max mem: 28728
Evaluation Total time: 0:02:04 (1.5229 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07545089721679688 uauc: 0.6269316742097296
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003042459487915039 u-nDCG: 0.8463446340009678
rank_0 auc: 0.6383890701304686
Train: data epoch: [79]  [ 0/50]  eta: 0:00:22  lr: 0.000011  loss: 0.6429  time: 0.4544  data: 0.0000  max mem: 28728
Train: data epoch: [79]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6938  time: 0.5002  data: 0.0000  max mem: 28728
Train: data epoch: [79] Total time: 0:00:24 (0.4966 s / it)
Evaluation  [ 0/82]  eta: 0:01:19  loss: 0.6594  acc: 0.5312  time: 0.9692  data: 0.0048  max mem: 28728
Evaluation  [16/82]  eta: 0:01:31  loss: 0.7108  acc: 0.5312  time: 1.3926  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:11  loss: 0.6763  acc: 0.6406  time: 1.4697  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:49  loss: 0.6735  acc: 0.5469  time: 1.4530  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6688  acc: 0.5312  time: 1.4673  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6528  acc: 0.5625  time: 1.4499  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5838  acc: 0.5625  time: 1.3951  data: 0.0025  max mem: 28728
Evaluation Total time: 0:01:58 (1.4421 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07606840133666992 uauc: 0.6142817618838288
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003026723861694336 u-nDCG: 0.8396729885389371
rank_0 auc: 0.6401292318209564
Train: data epoch: [80]  [ 0/50]  eta: 0:00:22  lr: 0.000011  loss: 0.8122  time: 0.4587  data: 0.0000  max mem: 28728
Train: data epoch: [80]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6187  time: 0.5356  data: 0.0000  max mem: 28728
Train: data epoch: [80] Total time: 0:00:25 (0.5143 s / it)
Evaluation  [ 0/82]  eta: 0:01:40  loss: 0.6484  acc: 0.5625  time: 1.2261  data: 0.0150  max mem: 28728
Evaluation  [16/82]  eta: 0:01:48  loss: 0.7159  acc: 0.5156  time: 1.6491  data: 0.0055  max mem: 28728
Evaluation  [32/82]  eta: 0:01:25  loss: 0.7357  acc: 0.6406  time: 1.7593  data: 0.0062  max mem: 28728
Evaluation  [48/82]  eta: 0:00:58  loss: 0.7055  acc: 0.5156  time: 1.7236  data: 0.0050  max mem: 28728
Evaluation  [64/82]  eta: 0:00:31  loss: 0.6727  acc: 0.6250  time: 1.7545  data: 0.0052  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6437  acc: 0.6094  time: 1.9350  data: 0.0044  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5782  acc: 0.7500  time: 1.8710  data: 0.0040  max mem: 28728
Evaluation Total time: 0:02:24 (1.7598 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.25715184211730957 uauc: 0.6121304633554817
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.01233983039855957 u-nDCG: 0.8414749085225032
rank_0 auc: 0.6403368128647982
Train: data epoch: [81]  [ 0/50]  eta: 0:00:25  lr: 0.000011  loss: 0.7608  time: 0.5125  data: 0.0000  max mem: 28728
Train: data epoch: [81]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.5533  time: 0.5571  data: 0.0000  max mem: 28728
Train: data epoch: [81] Total time: 0:00:27 (0.5584 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6527  acc: 0.5938  time: 0.9795  data: 0.0123  max mem: 28728
Evaluation  [16/82]  eta: 0:01:48  loss: 0.7333  acc: 0.5938  time: 1.6416  data: 0.0064  max mem: 28728
2025-11-11 13:59:05,379 [INFO] Averaged stats: lr: 0.000011  loss: 0.644425
2025-11-11 13:59:05,380 [INFO] Evaluating on valid.
2025-11-11 14:01:19,350 [INFO] Averaged stats: loss: 0.683664  acc: 0.614520 ***auc: 0.6454737755205525 ***uauc: 0.6150013506713357 ***u-nDCG: 0.842598123276717
2025-11-11 14:01:19,365 [INFO] Start training
2025-11-11 14:01:19,382 [INFO] Start training epoch 88, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:01:46,556 [INFO] Averaged stats: lr: 0.000011  loss: 0.658530
2025-11-11 14:01:46,557 [INFO] Evaluating on valid.
2025-11-11 14:03:59,514 [INFO] Averaged stats: loss: 0.660081  acc: 0.552210 ***auc: 0.6482170971053134 ***uauc: 0.636817558298782 ***u-nDCG: 0.8469438778043034
2025-11-11 14:03:59,526 [INFO] Saving checkpoint at epoch 88 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:04:00,237 [INFO] Start training
2025-11-11 14:04:00,252 [INFO] Start training epoch 89, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:04:28,201 [INFO] Averaged stats: lr: 0.000011  loss: 0.670166
2025-11-11 14:04:28,202 [INFO] Evaluating on valid.
2025-11-11 14:06:43,452 [INFO] Averaged stats: loss: 0.656929  acc: 0.573361 ***auc: 0.6476339992804451 ***uauc: 0.6339968046092229 ***u-nDCG: 0.8469432174436162
2025-11-11 14:06:43,472 [INFO] Start training
2025-11-11 14:06:43,494 [INFO] Start training epoch 90, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:07:10,987 [INFO] Averaged stats: lr: 0.000011  loss: 0.654202
2025-11-11 14:07:10,992 [INFO] Evaluating on valid.
2025-11-11 14:09:30,986 [INFO] Averaged stats: loss: 0.657104  acc: 0.552591 ***auc: 0.64997596781692 ***uauc: 0.6368001375742649 ***u-nDCG: 0.8467951837378047
2025-11-11 14:09:30,999 [INFO] Saving checkpoint at epoch 90 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:09:31,727 [INFO] Start training
2025-11-11 14:09:31,748 [INFO] Start training epoch 91, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:09:59,243 [INFO] Averaged stats: lr: 0.000011  loss: 0.634103
2025-11-11 14:09:59,244 [INFO] Evaluating on valid.
2025-11-11 14:12:14,022 [INFO] Averaged stats: loss: 0.656280  acc: 0.591654 ***auc: 0.6501878549053048 ***uauc: 0.6345295035641183 ***u-nDCG: 0.8458721576736822
2025-11-11 14:12:14,028 [INFO] Saving checkpoint at epoch 91 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:12:14,487 [INFO] Start training
2025-11-11 14:12:14,495 [INFO] Start training epoch 92, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:12:39,689 [INFO] Averaged stats: lr: 0.000011  loss: 0.650805
2025-11-11 14:12:39,691 [INFO] Evaluating on valid.
Evaluation  [32/82]  eta: 0:01:24  loss: 0.7613  acc: 0.5625  time: 1.7246  data: 0.0060  max mem: 28728
Evaluation  [48/82]  eta: 0:01:02  loss: 0.7185  acc: 0.5625  time: 2.0158  data: 0.0083  max mem: 28728
Evaluation  [64/82]  eta: 0:00:32  loss: 0.6846  acc: 0.6094  time: 1.7733  data: 0.0058  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6616  acc: 0.5781  time: 1.6510  data: 0.0050  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5818  acc: 0.8750  time: 1.5932  data: 0.0049  max mem: 28728
Evaluation Total time: 0:02:23 (1.7461 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.21765446662902832 uauc: 0.6297387513997008
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010720014572143555 u-nDCG: 0.8460916384265653
rank_0 auc: 0.6415883127417789
Train: data epoch: [82]  [ 0/50]  eta: 0:00:26  lr: 0.000011  loss: 0.6848  time: 0.5214  data: 0.0000  max mem: 28728
Train: data epoch: [82]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6455  time: 0.5470  data: 0.0000  max mem: 28728
Train: data epoch: [82] Total time: 0:00:27 (0.5467 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6429  acc: 0.6250  time: 0.9791  data: 0.0177  max mem: 28728
Evaluation  [16/82]  eta: 0:01:47  loss: 0.7193  acc: 0.5312  time: 1.6322  data: 0.0060  max mem: 28728
Evaluation  [32/82]  eta: 0:01:23  loss: 0.7327  acc: 0.5781  time: 1.7249  data: 0.0049  max mem: 28728
Evaluation  [48/82]  eta: 0:00:57  loss: 0.7014  acc: 0.5781  time: 1.6974  data: 0.0038  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6691  acc: 0.5938  time: 1.7017  data: 0.0043  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6546  acc: 0.6406  time: 1.6817  data: 0.0053  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5575  acc: 0.8125  time: 1.6220  data: 0.0051  max mem: 28728
Evaluation Total time: 0:02:17 (1.6771 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2501213550567627 uauc: 0.6259818313355671
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.00923299789428711 u-nDCG: 0.8437448612916697
rank_0 auc: 0.6431102025192142
Train: data epoch: [83]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.8459  time: 0.4967  data: 0.0000  max mem: 28728
Train: data epoch: [83]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.7573  time: 0.6525  data: 0.0000  max mem: 28728
Train: data epoch: [83] Total time: 0:00:29 (0.5894 s / it)
Evaluation  [ 0/82]  eta: 0:01:36  loss: 0.6520  acc: 0.5938  time: 1.1740  data: 0.0154  max mem: 28728
Evaluation  [16/82]  eta: 0:01:47  loss: 0.7290  acc: 0.5469  time: 1.6243  data: 0.0043  max mem: 28728
Evaluation  [32/82]  eta: 0:01:23  loss: 0.7547  acc: 0.5938  time: 1.7142  data: 0.0051  max mem: 28728
Evaluation  [48/82]  eta: 0:00:57  loss: 0.7162  acc: 0.5156  time: 1.7200  data: 0.0050  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6786  acc: 0.6094  time: 1.7216  data: 0.0042  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6561  acc: 0.6094  time: 1.7368  data: 0.0035  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5664  acc: 0.8125  time: 1.6775  data: 0.0033  max mem: 28728
Evaluation Total time: 0:02:19 (1.6991 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.25687241554260254 uauc: 0.6228362479085814
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007611274719238281 u-nDCG: 0.8442454222530626
rank_0 auc: 0.6442100999314151
Train: data epoch: [84]  [ 0/50]  eta: 0:00:26  lr: 0.000011  loss: 0.7237  time: 0.5362  data: 0.0000  max mem: 28728
Train: data epoch: [84]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6415  time: 0.6546  data: 0.0000  max mem: 28728
Train: data epoch: [84] Total time: 0:00:29 (0.5974 s / it)
Evaluation  [ 0/82]  eta: 0:01:16  loss: 0.6556  acc: 0.6406  time: 0.9302  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7345  acc: 0.5781  time: 1.5606  data: 0.0063  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.7675  acc: 0.5938  time: 1.6520  data: 0.0047  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.7249  acc: 0.5469  time: 1.6891  data: 0.0049  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6829  acc: 0.5938  time: 1.7195  data: 0.0039  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6606  acc: 0.6250  time: 1.6213  data: 0.0052  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5621  acc: 0.8125  time: 1.5635  data: 0.0052  max mem: 28728
Evaluation Total time: 0:02:14 (1.6400 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.19643044471740723 uauc: 0.6266442909419586
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007680416107177734 u-nDCG: 0.8451185756385348
rank_0 auc: 0.6453966379295112
Train: data epoch: [85]  [ 0/50]  eta: 0:00:26  lr: 0.000011  loss: 0.5420  time: 0.5308  data: 0.0000  max mem: 28728
Train: data epoch: [85]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6741  time: 0.5508  data: 0.0000  max mem: 28728
Train: data epoch: [85] Total time: 0:00:27 (0.5541 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 0.6554  acc: 0.5781  time: 0.9243  data: 0.0138  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.7255  acc: 0.4844  time: 1.5319  data: 0.0041  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.7202  acc: 0.6094  time: 1.6768  data: 0.0044  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6917  acc: 0.5312  time: 1.6603  data: 0.0049  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6681  acc: 0.6406  time: 1.6425  data: 0.0061  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6502  acc: 0.6250  time: 1.5913  data: 0.0060  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5506  acc: 0.7500  time: 1.5335  data: 0.0057  max mem: 28728
Evaluation Total time: 0:02:12 (1.6175 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.22508955001831055 uauc: 0.6202460160646154
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009164094924926758 u-nDCG: 0.841022279237881
rank_0 auc: 0.6466485090172285
Train: data epoch: [86]  [ 0/50]  eta: 0:00:27  lr: 0.000011  loss: 0.5972  time: 0.5552  data: 0.0000  max mem: 28728
Train: data epoch: [86]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6881  time: 0.5478  data: 0.0000  max mem: 28728
Train: data epoch: [86] Total time: 0:00:27 (0.5409 s / it)
Evaluation  [ 0/82]  eta: 0:01:44  loss: 0.6494  acc: 0.5469  time: 1.2787  data: 0.0163  max mem: 28728
Evaluation  [16/82]  eta: 0:01:43  loss: 0.7037  acc: 0.5625  time: 1.5742  data: 0.0051  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6848  acc: 0.6094  time: 1.6275  data: 0.0064  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6743  acc: 0.5625  time: 1.6618  data: 0.0055  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6617  acc: 0.5938  time: 1.6519  data: 0.0055  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6568  acc: 0.5938  time: 1.6941  data: 0.0043  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5439  acc: 0.5625  time: 1.6357  data: 0.0041  max mem: 28728
Evaluation Total time: 0:02:14 (1.6362 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2564983367919922 uauc: 0.6345460740152302
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010677337646484375 u-nDCG: 0.8462887032772624
rank_0 auc: 0.6480891036433739
2025-11-11 14:14:47,556 [INFO] Averaged stats: loss: 0.655810  acc: 0.587843 ***auc: 0.6504797007863283 ***uauc: 0.637124642224492 ***u-nDCG: 0.8475832129656036
2025-11-11 14:14:47,563 [INFO] Saving checkpoint at epoch 92 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:14:48,010 [INFO] Start training
2025-11-11 14:14:48,016 [INFO] Start training epoch 93, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:15:13,042 [INFO] Averaged stats: lr: 0.000011  loss: 0.641172
2025-11-11 14:15:13,043 [INFO] Evaluating on valid.
2025-11-11 14:17:18,002 [INFO] Averaged stats: loss: 0.658298  acc: 0.562500 ***auc: 0.6495686753968501 ***uauc: 0.6308589587087374 ***u-nDCG: 0.8458373352832698
2025-11-11 14:17:18,008 [INFO] Start training
2025-11-11 14:17:18,014 [INFO] Start training epoch 94, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:17:43,162 [INFO] Averaged stats: lr: 0.000012  loss: 0.649233
2025-11-11 14:17:43,163 [INFO] Evaluating on valid.
2025-11-11 14:19:47,897 [INFO] Averaged stats: loss: 0.654613  acc: 0.568026 ***auc: 0.653191172489899 ***uauc: 0.6311891146231664 ***u-nDCG: 0.8453579717891987
2025-11-11 14:19:47,904 [INFO] Saving checkpoint at epoch 94 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:19:48,367 [INFO] Start training
2025-11-11 14:19:48,374 [INFO] Start training epoch 95, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:20:13,223 [INFO] Averaged stats: lr: 0.000012  loss: 0.623712
2025-11-11 14:20:13,225 [INFO] Evaluating on valid.
2025-11-11 14:22:18,108 [INFO] Averaged stats: loss: 0.662926  acc: 0.597180 ***auc: 0.6480994975439955 ***uauc: 0.6269440697749248 ***u-nDCG: 0.8440338462684074
2025-11-11 14:22:18,114 [INFO] Start training
2025-11-11 14:22:18,120 [INFO] Start training epoch 96, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:22:43,218 [INFO] Averaged stats: lr: 0.000012  loss: 0.635063
2025-11-11 14:22:43,220 [INFO] Evaluating on valid.
2025-11-11 14:24:49,971 [INFO] Averaged stats: loss: 0.655081  acc: 0.580030 ***auc: 0.6534008323138649 ***uauc: 0.6313753693315208 ***u-nDCG: 0.8441057008195195
2025-11-11 14:24:49,978 [INFO] Saving checkpoint at epoch 96 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:24:50,437 [INFO] Start training
2025-11-11 14:24:50,443 [INFO] Start training epoch 97, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:25:15,943 [INFO] Averaged stats: lr: 0.000012  loss: 0.646253
2025-11-11 14:25:15,945 [INFO] Evaluating on valid.
2025-11-11 14:27:27,947 [INFO] Averaged stats: loss: 0.655131  acc: 0.580793 ***auc: 0.6532155239142123 ***uauc: 0.631428635577277 ***u-nDCG: 0.8456653208261803
2025-11-11 14:27:27,953 [INFO] Start training
2025-11-11 14:27:27,959 [INFO] Start training epoch 98, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:27:53,185 [INFO] Averaged stats: lr: 0.000012  loss: 0.640982
2025-11-11 14:27:53,187 [INFO] Evaluating on valid.
Train: data epoch: [87]  [ 0/50]  eta: 0:00:28  lr: 0.000011  loss: 0.6678  time: 0.5663  data: 0.0000  max mem: 28728
Train: data epoch: [87]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6499  time: 0.5427  data: 0.0000  max mem: 28728
Train: data epoch: [87] Total time: 0:00:27 (0.5524 s / it)
Evaluation  [ 0/82]  eta: 0:01:18  loss: 0.6645  acc: 0.6406  time: 0.9559  data: 0.0404  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.7509  acc: 0.6094  time: 1.5451  data: 0.0058  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.7873  acc: 0.5469  time: 1.6369  data: 0.0061  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.7457  acc: 0.5469  time: 1.6379  data: 0.0047  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6937  acc: 0.5781  time: 1.7164  data: 0.0048  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6610  acc: 0.6250  time: 1.6370  data: 0.0063  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5673  acc: 0.8750  time: 1.5791  data: 0.0058  max mem: 28728
Evaluation Total time: 0:02:13 (1.6308 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.22151470184326172 uauc: 0.6150013506713357
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007639169692993164 u-nDCG: 0.842598123276717
rank_0 auc: 0.6454737755205525
Train: data epoch: [88]  [ 0/50]  eta: 0:00:26  lr: 0.000011  loss: 0.7396  time: 0.5227  data: 0.0000  max mem: 28728
Train: data epoch: [88]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6137  time: 0.5472  data: 0.0000  max mem: 28728
Train: data epoch: [88] Total time: 0:00:27 (0.5435 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6519  acc: 0.5156  time: 0.9779  data: 0.0236  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7050  acc: 0.5312  time: 1.5468  data: 0.0066  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6776  acc: 0.6094  time: 1.6577  data: 0.0049  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6712  acc: 0.5625  time: 1.6530  data: 0.0050  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6594  acc: 0.6094  time: 1.6479  data: 0.0047  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6597  acc: 0.5781  time: 1.6247  data: 0.0049  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5455  acc: 0.5625  time: 1.5661  data: 0.0047  max mem: 28728
Evaluation Total time: 0:02:12 (1.6185 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.21000385284423828 uauc: 0.636817558298782
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007756233215332031 u-nDCG: 0.8469438778043034
rank_0 auc: 0.6482170971053134
Train: data epoch: [89]  [ 0/50]  eta: 0:00:27  lr: 0.000011  loss: 0.7290  time: 0.5485  data: 0.0000  max mem: 28728
Train: data epoch: [89]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.5876  time: 0.5604  data: 0.0000  max mem: 28728
Train: data epoch: [89] Total time: 0:00:27 (0.5589 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6462  acc: 0.5781  time: 0.9126  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:48  loss: 0.7063  acc: 0.5000  time: 1.6500  data: 0.0058  max mem: 28728
Evaluation  [32/82]  eta: 0:01:23  loss: 0.6959  acc: 0.6406  time: 1.6586  data: 0.0059  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.6787  acc: 0.5156  time: 1.6333  data: 0.0050  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6647  acc: 0.6562  time: 1.6724  data: 0.0052  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6537  acc: 0.6250  time: 1.6543  data: 0.0044  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5530  acc: 0.6875  time: 1.5960  data: 0.0043  max mem: 28728
Evaluation Total time: 0:02:14 (1.6462 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.22639012336730957 uauc: 0.6339968046092229
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.012191534042358398 u-nDCG: 0.8469432174436162
rank_0 auc: 0.6476339992804451
Train: data epoch: [90]  [ 0/50]  eta: 0:00:28  lr: 0.000011  loss: 0.5739  time: 0.5765  data: 0.0000  max mem: 28728
Train: data epoch: [90]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.6329  time: 0.5529  data: 0.0000  max mem: 28728
Train: data epoch: [90] Total time: 0:00:27 (0.5499 s / it)
Evaluation  [ 0/82]  eta: 0:01:17  loss: 0.6466  acc: 0.5469  time: 0.9472  data: 0.0184  max mem: 28728
Evaluation  [16/82]  eta: 0:01:43  loss: 0.7005  acc: 0.5312  time: 1.5722  data: 0.0045  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6791  acc: 0.6094  time: 1.6464  data: 0.0055  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6689  acc: 0.5469  time: 1.6459  data: 0.0044  max mem: 28728
Evaluation  [64/82]  eta: 0:00:31  loss: 0.6569  acc: 0.5781  time: 2.0146  data: 0.0043  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6554  acc: 0.5938  time: 1.6282  data: 0.0042  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5484  acc: 0.6250  time: 1.5656  data: 0.0041  max mem: 28728
Evaluation Total time: 0:02:19 (1.7043 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2142198085784912 uauc: 0.6368001375742649
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.01071929931640625 u-nDCG: 0.8467951837378047
rank_0 auc: 0.64997596781692
Train: data epoch: [91]  [ 0/50]  eta: 0:00:25  lr: 0.000011  loss: 0.6306  time: 0.5057  data: 0.0000  max mem: 28728
Train: data epoch: [91]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.5716  time: 0.5490  data: 0.0000  max mem: 28728
Train: data epoch: [91] Total time: 0:00:27 (0.5499 s / it)
Evaluation  [ 0/82]  eta: 0:01:18  loss: 0.6351  acc: 0.5938  time: 0.9569  data: 0.0123  max mem: 28728
Evaluation  [16/82]  eta: 0:01:45  loss: 0.7084  acc: 0.5312  time: 1.6039  data: 0.0073  max mem: 28728
Evaluation  [32/82]  eta: 0:01:22  loss: 0.7098  acc: 0.6250  time: 1.6944  data: 0.0052  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.6859  acc: 0.5625  time: 1.6837  data: 0.0039  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6594  acc: 0.6406  time: 1.6870  data: 0.0063  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6565  acc: 0.6250  time: 1.5861  data: 0.0035  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5267  acc: 0.7500  time: 1.5239  data: 0.0034  max mem: 28728
Evaluation Total time: 0:02:14 (1.6425 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0778360366821289 uauc: 0.6345295035641183
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003096342086791992 u-nDCG: 0.8458721576736822
rank_0 auc: 0.6501878549053048
Train: data epoch: [92]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.5919  time: 0.4955  data: 0.0000  max mem: 28728
Train: data epoch: [92]  [49/50]  eta: 0:00:00  lr: 0.000011  loss: 0.7473  time: 0.5041  data: 0.0000  max mem: 28728
Train: data epoch: [92] Total time: 0:00:25 (0.5039 s / it)
Evaluation  [ 0/82]  eta: 0:01:25  loss: 0.6351  acc: 0.6094  time: 1.0417  data: 0.0056  max mem: 28728
Evaluation  [16/82]  eta: 0:01:36  loss: 0.7078  acc: 0.5312  time: 1.4618  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.7045  acc: 0.6250  time: 1.5524  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:53  loss: 0.6807  acc: 0.5625  time: 1.6150  data: 0.0032  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6573  acc: 0.6250  time: 1.6087  data: 0.0038  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6631  acc: 0.6094  time: 1.5574  data: 0.0025  max mem: 28728
2025-11-11 14:29:59,287 [INFO] Averaged stats: loss: 0.737949  acc: 0.600419 ***auc: 0.652601170145332 ***uauc: 0.6410482137379522 ***u-nDCG: 0.8500023637659185
2025-11-11 14:29:59,294 [INFO] Start training
2025-11-11 14:29:59,300 [INFO] Start training epoch 99, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:30:24,120 [INFO] Averaged stats: lr: 0.000012  loss: 0.641139
2025-11-11 14:30:24,121 [INFO] Evaluating on valid.
2025-11-11 14:32:31,987 [INFO] Averaged stats: loss: 0.654351  acc: 0.567454 ***auc: 0.6526160185747912 ***uauc: 0.6355242031035309 ***u-nDCG: 0.847030033966948
2025-11-11 14:32:31,993 [INFO] Start training
2025-11-11 14:32:32,000 [INFO] Start training epoch 100, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:32:57,104 [INFO] Averaged stats: lr: 0.000012  loss: 0.626383
2025-11-11 14:32:57,105 [INFO] Evaluating on valid.
2025-11-11 14:35:07,009 [INFO] Averaged stats: loss: 0.653285  acc: 0.581745 ***auc: 0.6539486651187675 ***uauc: 0.634212990407739 ***u-nDCG: 0.8483567890657454
2025-11-11 14:35:07,023 [INFO] Saving checkpoint at epoch 100 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:35:07,892 [INFO] Start training
2025-11-11 14:35:07,907 [INFO] Start training epoch 101, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:35:36,506 [INFO] Averaged stats: lr: 0.000012  loss: 0.635500
2025-11-11 14:35:36,510 [INFO] Evaluating on valid.
2025-11-11 14:38:03,102 [INFO] Averaged stats: loss: 0.654867  acc: 0.570312 ***auc: 0.6558354550501662 ***uauc: 0.6349275570632148 ***u-nDCG: 0.8477136841370674
2025-11-11 14:38:03,119 [INFO] Saving checkpoint at epoch 101 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:38:03,917 [INFO] Start training
2025-11-11 14:38:03,933 [INFO] Start training epoch 102, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:38:33,373 [INFO] Averaged stats: lr: 0.000012  loss: 0.648891
2025-11-11 14:38:33,382 [INFO] Evaluating on valid.
2025-11-11 14:40:57,245 [INFO] Averaged stats: loss: 0.704737  acc: 0.504192 ***auc: 0.6545644294884463 ***uauc: 0.6363974432997765 ***u-nDCG: 0.8457308470601428
2025-11-11 14:40:57,260 [INFO] Start training
2025-11-11 14:40:57,276 [INFO] Start training epoch 103, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:41:22,974 [INFO] Averaged stats: lr: 0.000012  loss: 0.654013
2025-11-11 14:41:22,976 [INFO] Evaluating on valid.
2025-11-11 14:43:31,359 [INFO] Averaged stats: loss: 0.655550  acc: 0.594512 ***auc: 0.6539855634659737 ***uauc: 0.6391583016764959 ***u-nDCG: 0.8483360388046747
2025-11-11 14:43:31,367 [INFO] Start training
2025-11-11 14:43:31,374 [INFO] Start training epoch 104, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5189  acc: 0.7500  time: 1.5007  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:07 (1.5582 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08005809783935547 uauc: 0.637124642224492
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015456676483154297 u-nDCG: 0.8475832129656036
rank_0 auc: 0.6504797007863283
Train: data epoch: [93]  [ 0/50]  eta: 0:00:24  lr: 0.000011  loss: 0.6542  time: 0.4806  data: 0.0000  max mem: 28728
Train: data epoch: [93]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.7371  time: 0.4990  data: 0.0000  max mem: 28728
Train: data epoch: [93] Total time: 0:00:25 (0.5005 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6511  acc: 0.5625  time: 0.8859  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7114  acc: 0.4844  time: 1.4711  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.6866  acc: 0.5781  time: 1.5570  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6664  acc: 0.5625  time: 1.5418  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6538  acc: 0.6094  time: 1.5615  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6528  acc: 0.5938  time: 1.5124  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5508  acc: 0.6250  time: 1.4548  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:04 (1.5227 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07832694053649902 uauc: 0.6308589587087374
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030701160430908203 u-nDCG: 0.8458373352832698
rank_0 auc: 0.6495686753968501
Train: data epoch: [94]  [ 0/50]  eta: 0:00:24  lr: 0.000012  loss: 0.6771  time: 0.4942  data: 0.0000  max mem: 28728
Train: data epoch: [94]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.7553  time: 0.5003  data: 0.0000  max mem: 28728
Train: data epoch: [94] Total time: 0:00:25 (0.5030 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6413  acc: 0.5781  time: 0.8827  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7010  acc: 0.5781  time: 1.4544  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.6890  acc: 0.6094  time: 1.5487  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6735  acc: 0.5625  time: 1.5616  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6527  acc: 0.6250  time: 1.5484  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6565  acc: 0.6094  time: 1.5262  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5312  acc: 0.6875  time: 1.4686  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:04 (1.5200 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07728290557861328 uauc: 0.6311891146231664
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030214786529541016 u-nDCG: 0.8453579717891987
rank_0 auc: 0.653191172489899
Train: data epoch: [95]  [ 0/50]  eta: 0:00:25  lr: 0.000012  loss: 0.7291  time: 0.5041  data: 0.0000  max mem: 28728
Train: data epoch: [95]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5854  time: 0.4947  data: 0.0000  max mem: 28728
Train: data epoch: [95] Total time: 0:00:24 (0.4970 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6363  acc: 0.5938  time: 0.8811  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7301  acc: 0.5625  time: 1.4543  data: 0.0031  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.7351  acc: 0.5938  time: 1.5501  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.7017  acc: 0.5312  time: 1.5322  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6572  acc: 0.6094  time: 1.5533  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6464  acc: 0.5938  time: 1.5445  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5337  acc: 0.7500  time: 1.4862  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:04 (1.5218 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07888174057006836 uauc: 0.6269440697749248
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003019094467163086 u-nDCG: 0.8440338462684074
rank_0 auc: 0.6480994975439955
Train: data epoch: [96]  [ 0/50]  eta: 0:00:24  lr: 0.000012  loss: 0.5153  time: 0.4821  data: 0.0000  max mem: 28728
Train: data epoch: [96]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.6277  time: 0.4992  data: 0.0000  max mem: 28728
Train: data epoch: [96] Total time: 0:00:25 (0.5020 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6436  acc: 0.5938  time: 0.9109  data: 0.0062  max mem: 28728
Evaluation  [16/82]  eta: 0:01:40  loss: 0.7106  acc: 0.5625  time: 1.5203  data: 0.0033  max mem: 28728
Evaluation  [32/82]  eta: 0:01:17  loss: 0.6969  acc: 0.5938  time: 1.5724  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:53  loss: 0.6762  acc: 0.5469  time: 1.5743  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6494  acc: 0.6562  time: 1.5661  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6530  acc: 0.6094  time: 1.5334  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5243  acc: 0.7500  time: 1.4752  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:06 (1.5446 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07832884788513184 uauc: 0.6313753693315208
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030128955841064453 u-nDCG: 0.8441057008195195
rank_0 auc: 0.6534008323138649
Train: data epoch: [97]  [ 0/50]  eta: 0:00:24  lr: 0.000012  loss: 0.6231  time: 0.4975  data: 0.0000  max mem: 28728
Train: data epoch: [97]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.6297  time: 0.5091  data: 0.0000  max mem: 28728
Train: data epoch: [97] Total time: 0:00:25 (0.5100 s / it)
Evaluation  [ 0/82]  eta: 0:01:10  loss: 0.6479  acc: 0.5625  time: 0.8652  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7128  acc: 0.5625  time: 1.4792  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.6994  acc: 0.5938  time: 1.5734  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6744  acc: 0.5625  time: 1.7249  data: 0.0064  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6457  acc: 0.6562  time: 1.7051  data: 0.0054  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6515  acc: 0.6094  time: 1.5659  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5322  acc: 0.7500  time: 1.5073  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:11 (1.6086 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08182883262634277 uauc: 0.631428635577277
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030879974365234375 u-nDCG: 0.8456653208261803
rank_0 auc: 0.6532155239142123
Train: data epoch: [98]  [ 0/50]  eta: 0:00:24  lr: 0.000012  loss: 0.7954  time: 0.4805  data: 0.0000  max mem: 28728
Train: data epoch: [98]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.7594  time: 0.4988  data: 0.0000  max mem: 28728
Train: data epoch: [98] Total time: 0:00:25 (0.5045 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.7142  acc: 0.5781  time: 0.8803  data: 0.0043  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.8361  acc: 0.5312  time: 1.4776  data: 0.0026  max mem: 28728
2025-11-11 14:43:58,032 [INFO] Averaged stats: lr: 0.000012  loss: 0.629975
2025-11-11 14:43:58,034 [INFO] Evaluating on valid.
2025-11-11 14:46:05,668 [INFO] Averaged stats: loss: 0.654332  acc: 0.597942 ***auc: 0.655260672345795 ***uauc: 0.6408460500103669 ***u-nDCG: 0.8484209491745852
2025-11-11 14:46:05,674 [INFO] Start training
2025-11-11 14:46:05,681 [INFO] Start training epoch 105, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:46:31,029 [INFO] Averaged stats: lr: 0.000012  loss: 0.625505
2025-11-11 14:46:31,031 [INFO] Evaluating on valid.
2025-11-11 14:48:38,858 [INFO] Averaged stats: loss: 0.656957  acc: 0.568788 ***auc: 0.6569470084794926 ***uauc: 0.6314429247977191 ***u-nDCG: 0.8459865891945249
2025-11-11 14:48:38,864 [INFO] Saving checkpoint at epoch 105 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:48:39,347 [INFO] Start training
2025-11-11 14:48:39,352 [INFO] Start training epoch 106, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:49:04,401 [INFO] Averaged stats: lr: 0.000012  loss: 0.626843
2025-11-11 14:49:04,403 [INFO] Evaluating on valid.
2025-11-11 14:51:24,400 [INFO] Averaged stats: loss: 0.653281  acc: 0.581174 ***auc: 0.6577533524412822 ***uauc: 0.6292495654462831 ***u-nDCG: 0.8449794636359466
2025-11-11 14:51:24,407 [INFO] Saving checkpoint at epoch 106 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:51:24,858 [INFO] Start training
2025-11-11 14:51:24,865 [INFO] Start training epoch 107, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:51:49,973 [INFO] Averaged stats: lr: 0.000012  loss: 0.657092
2025-11-11 14:51:49,975 [INFO] Evaluating on valid.
2025-11-11 14:53:56,236 [INFO] Averaged stats: loss: 0.651622  acc: 0.574695 ***auc: 0.6589049966301489 ***uauc: 0.6330916887915501 ***u-nDCG: 0.8484611826127956
2025-11-11 14:53:56,242 [INFO] Saving checkpoint at epoch 107 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:53:56,709 [INFO] Start training
2025-11-11 14:53:56,715 [INFO] Start training epoch 108, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:54:22,078 [INFO] Averaged stats: lr: 0.000012  loss: 0.632076
2025-11-11 14:54:22,080 [INFO] Evaluating on valid.
2025-11-11 14:56:36,019 [INFO] Averaged stats: loss: 0.651622  acc: 0.587843 ***auc: 0.6592138439629032 ***uauc: 0.6339094642639029 ***u-nDCG: 0.8488508657986014
2025-11-11 14:56:36,025 [INFO] Saving checkpoint at epoch 108 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:56:36,488 [INFO] Start training
2025-11-11 14:56:36,496 [INFO] Start training epoch 109, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:57:01,307 [INFO] Averaged stats: lr: 0.000012  loss: 0.637893
2025-11-11 14:57:01,309 [INFO] Evaluating on valid.
Evaluation  [32/82]  eta: 0:01:15  loss: 0.8782  acc: 0.4844  time: 1.5528  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.8131  acc: 0.6094  time: 1.5896  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.7592  acc: 0.5312  time: 1.5630  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7348  acc: 0.5469  time: 1.5385  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6086  acc: 0.8125  time: 1.4795  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:06 (1.5367 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07669544219970703 uauc: 0.6410482137379522
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0032279491424560547 u-nDCG: 0.8500023637659185
rank_0 auc: 0.652601170145332
Train: data epoch: [99]  [ 0/50]  eta: 0:00:23  lr: 0.000012  loss: 0.6110  time: 0.4733  data: 0.0000  max mem: 28728
Train: data epoch: [99]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.6224  time: 0.4944  data: 0.0001  max mem: 28728
Train: data epoch: [99] Total time: 0:00:24 (0.4964 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6539  acc: 0.5469  time: 0.8943  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7131  acc: 0.5000  time: 1.4752  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.6821  acc: 0.5938  time: 1.5800  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6602  acc: 0.5781  time: 1.5612  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6464  acc: 0.6094  time: 1.6415  data: 0.0036  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6591  acc: 0.5938  time: 1.5696  data: 0.0030  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5513  acc: 0.6875  time: 1.5065  data: 0.0029  max mem: 28728
Evaluation Total time: 0:02:07 (1.5582 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0784909725189209 uauc: 0.6355242031035309
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030634403228759766 u-nDCG: 0.847030033966948
rank_0 auc: 0.6526160185747912
Train: data epoch: [100]  [ 0/50]  eta: 0:00:25  lr: 0.000012  loss: 0.5929  time: 0.5104  data: 0.0000  max mem: 28728
Train: data epoch: [100]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5710  time: 0.5050  data: 0.0000  max mem: 28728
Train: data epoch: [100] Total time: 0:00:25 (0.5021 s / it)
Evaluation  [ 0/82]  eta: 0:01:25  loss: 0.6559  acc: 0.5938  time: 1.0367  data: 0.0051  max mem: 28728
Evaluation  [16/82]  eta: 0:01:36  loss: 0.7135  acc: 0.5000  time: 1.4678  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.6907  acc: 0.6094  time: 1.5604  data: 0.0024  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6686  acc: 0.5469  time: 1.5873  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6517  acc: 0.6406  time: 1.5839  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6576  acc: 0.6250  time: 1.6973  data: 0.0042  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5444  acc: 0.6875  time: 1.6424  data: 0.0042  max mem: 28728
Evaluation Total time: 0:02:09 (1.5808 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.24904084205627441 uauc: 0.634212990407739
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009229421615600586 u-nDCG: 0.8483567890657454
rank_0 auc: 0.6539486651187675
Train: data epoch: [101]  [ 0/50]  eta: 0:00:29  lr: 0.000012  loss: 0.6655  time: 0.5852  data: 0.0000  max mem: 28728
Train: data epoch: [101]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5426  time: 0.5666  data: 0.0000  max mem: 28728
Train: data epoch: [101] Total time: 0:00:28 (0.5720 s / it)
Evaluation  [ 0/82]  eta: 0:01:25  loss: 0.6628  acc: 0.5625  time: 1.0401  data: 0.0118  max mem: 28728
Evaluation  [16/82]  eta: 0:01:51  loss: 0.7169  acc: 0.5156  time: 1.6854  data: 0.0061  max mem: 28728
Evaluation  [32/82]  eta: 0:01:27  loss: 0.6808  acc: 0.6250  time: 1.8007  data: 0.0057  max mem: 28728
Evaluation  [48/82]  eta: 0:01:00  loss: 0.6619  acc: 0.5781  time: 1.8084  data: 0.0078  max mem: 28728
Evaluation  [64/82]  eta: 0:00:32  loss: 0.6489  acc: 0.6250  time: 1.8623  data: 0.0078  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6688  acc: 0.6250  time: 1.7883  data: 0.0083  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5388  acc: 0.6875  time: 1.7282  data: 0.0080  max mem: 28728
Evaluation Total time: 0:02:26 (1.7843 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.23492169380187988 uauc: 0.6349275570632148
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.018549680709838867 u-nDCG: 0.8477136841370674
rank_0 auc: 0.6558354550501662
Train: data epoch: [102]  [ 0/50]  eta: 0:00:30  lr: 0.000012  loss: 0.5633  time: 0.6194  data: 0.0000  max mem: 28728
Train: data epoch: [102]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5812  time: 0.5956  data: 0.0000  max mem: 28728
Train: data epoch: [102] Total time: 0:00:29 (0.5888 s / it)
Evaluation  [ 0/82]  eta: 0:01:25  loss: 0.7249  acc: 0.4844  time: 1.0473  data: 0.0121  max mem: 28728
Evaluation  [16/82]  eta: 0:01:52  loss: 0.7449  acc: 0.5312  time: 1.7066  data: 0.0088  max mem: 28728
Evaluation  [32/82]  eta: 0:01:28  loss: 0.6565  acc: 0.6250  time: 1.8164  data: 0.0065  max mem: 28728
Evaluation  [48/82]  eta: 0:01:00  loss: 0.6724  acc: 0.5469  time: 1.7378  data: 0.0049  max mem: 28728
Evaluation  [64/82]  eta: 0:00:32  loss: 0.6789  acc: 0.5469  time: 1.7898  data: 0.0078  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7275  acc: 0.5312  time: 1.7442  data: 0.0060  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6078  acc: 0.5625  time: 1.6789  data: 0.0055  max mem: 28728
Evaluation Total time: 0:02:23 (1.7517 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.19165420532226562 uauc: 0.6363974432997765
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007666349411010742 u-nDCG: 0.8457308470601428
rank_0 auc: 0.6545644294884463
Train: data epoch: [103]  [ 0/50]  eta: 0:00:26  lr: 0.000012  loss: 0.6719  time: 0.5307  data: 0.0000  max mem: 28728
Train: data epoch: [103]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5476  time: 0.5084  data: 0.0000  max mem: 28728
Train: data epoch: [103] Total time: 0:00:25 (0.5140 s / it)
Evaluation  [ 0/82]  eta: 0:01:25  loss: 0.6434  acc: 0.5938  time: 1.0412  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:36  loss: 0.7183  acc: 0.5781  time: 1.4685  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.7065  acc: 0.5938  time: 1.5768  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6803  acc: 0.5625  time: 1.5774  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6492  acc: 0.6406  time: 1.5630  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6721  acc: 0.5781  time: 1.6315  data: 0.0029  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5388  acc: 0.6875  time: 1.5878  data: 0.0028  max mem: 28728
Evaluation Total time: 0:02:08 (1.5645 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07930135726928711 uauc: 0.6391583016764959
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030786991119384766 u-nDCG: 0.8483360388046747
rank_0 auc: 0.6539855634659737
2025-11-11 14:59:13,824 [INFO] Averaged stats: loss: 0.651652  acc: 0.591845 ***auc: 0.6595785213904248 ***uauc: 0.6332026230576654 ***u-nDCG: 0.847570320288372
2025-11-11 14:59:13,831 [INFO] Saving checkpoint at epoch 109 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 14:59:14,276 [INFO] Start training
2025-11-11 14:59:14,282 [INFO] Start training epoch 110, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 14:59:39,495 [INFO] Averaged stats: lr: 0.000012  loss: 0.606069
2025-11-11 14:59:39,495 [INFO] Evaluating on valid.
2025-11-11 15:01:48,871 [INFO] Averaged stats: loss: 0.667846  acc: 0.559451 ***auc: 0.6575367138554704 ***uauc: 0.6412684189448178 ***u-nDCG: 0.8495051105789758
2025-11-11 15:01:48,879 [INFO] Start training
2025-11-11 15:01:48,885 [INFO] Start training epoch 111, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:02:14,341 [INFO] Averaged stats: lr: 0.000012  loss: 0.649332
2025-11-11 15:02:14,343 [INFO] Evaluating on valid.
2025-11-11 15:04:28,181 [INFO] Averaged stats: loss: 0.653616  acc: 0.566502 ***auc: 0.6598941990007304 ***uauc: 0.6315020408199117 ***u-nDCG: 0.8481818391048163
2025-11-11 15:04:28,199 [INFO] Saving checkpoint at epoch 111 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 15:04:29,085 [INFO] Start training
2025-11-11 15:04:29,100 [INFO] Start training epoch 112, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:04:58,569 [INFO] Averaged stats: lr: 0.000012  loss: 0.634918
2025-11-11 15:04:58,572 [INFO] Evaluating on valid.
2025-11-11 15:07:22,157 [INFO] Averaged stats: loss: 0.650483  acc: 0.592607 ***auc: 0.6606208068963233 ***uauc: 0.6352867910643414 ***u-nDCG: 0.8471813835622284
2025-11-11 15:07:22,170 [INFO] Saving checkpoint at epoch 112 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 15:07:23,002 [INFO] Start training
2025-11-11 15:07:23,020 [INFO] Start training epoch 113, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:07:50,034 [INFO] Averaged stats: lr: 0.000012  loss: 0.620982
2025-11-11 15:07:50,035 [INFO] Evaluating on valid.
2025-11-11 15:10:00,805 [INFO] Averaged stats: loss: 0.656693  acc: 0.610328 ***auc: 0.6611539397560611 ***uauc: 0.6410695755643397 ***u-nDCG: 0.8488744149532145
2025-11-11 15:10:00,810 [INFO] Saving checkpoint at epoch 113 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 15:10:01,284 [INFO] Start training
2025-11-11 15:10:01,292 [INFO] Start training epoch 114, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:10:26,532 [INFO] Averaged stats: lr: 0.000012  loss: 0.649663
2025-11-11 15:10:26,534 [INFO] Evaluating on valid.
2025-11-11 15:12:51,017 [INFO] Averaged stats: loss: 0.676002  acc: 0.621380 ***auc: 0.6618131357819086 ***uauc: 0.6366131685493719 ***u-nDCG: 0.8485273662335483
2025-11-11 15:12:51,034 [INFO] Saving checkpoint at epoch 114 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 15:12:51,833 [INFO] Start training
2025-11-11 15:12:51,846 [INFO] Start training epoch 115, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:13:22,844 [INFO] Averaged stats: lr: 0.000012  loss: 0.648452
2025-11-11 15:13:22,845 [INFO] Evaluating on valid.
Train: data epoch: [104]  [ 0/50]  eta: 0:00:32  lr: 0.000012  loss: 0.7010  time: 0.6533  data: 0.0000  max mem: 28728
Train: data epoch: [104]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5908  time: 0.5018  data: 0.0000  max mem: 28728
Train: data epoch: [104] Total time: 0:00:26 (0.5332 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6449  acc: 0.5938  time: 0.8965  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:38  loss: 0.7232  acc: 0.5938  time: 1.4976  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.7033  acc: 0.6250  time: 1.5710  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6774  acc: 0.5469  time: 1.5739  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6500  acc: 0.6562  time: 1.6061  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6694  acc: 0.5781  time: 1.5616  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5300  acc: 0.7500  time: 1.5026  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:07 (1.5554 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07983779907226562 uauc: 0.6408460500103669
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030431747436523438 u-nDCG: 0.8484209491745852
rank_0 auc: 0.655260672345795
Train: data epoch: [105]  [ 0/50]  eta: 0:00:24  lr: 0.000012  loss: 0.5692  time: 0.4929  data: 0.0000  max mem: 28728
Train: data epoch: [105]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.6597  time: 0.5002  data: 0.0000  max mem: 28728
Train: data epoch: [105] Total time: 0:00:25 (0.5070 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6618  acc: 0.5781  time: 0.9129  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:38  loss: 0.7221  acc: 0.5000  time: 1.4942  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:17  loss: 0.6823  acc: 0.6094  time: 1.5881  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:53  loss: 0.6613  acc: 0.5781  time: 1.5878  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6438  acc: 0.6406  time: 1.5991  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6687  acc: 0.5938  time: 1.5574  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5360  acc: 0.6250  time: 1.4978  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:07 (1.5578 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07651710510253906 uauc: 0.6314429247977191
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003014802932739258 u-nDCG: 0.8459865891945249
rank_0 auc: 0.6569470084794926
Train: data epoch: [106]  [ 0/50]  eta: 0:00:24  lr: 0.000012  loss: 0.6277  time: 0.4864  data: 0.0000  max mem: 28728
Train: data epoch: [106]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.6147  time: 0.5071  data: 0.0000  max mem: 28728
Train: data epoch: [106] Total time: 0:00:25 (0.5010 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6544  acc: 0.5625  time: 0.9004  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:48  loss: 0.7204  acc: 0.5469  time: 1.6411  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:35  loss: 0.6938  acc: 0.6094  time: 2.1133  data: 0.0033  max mem: 28728
Evaluation  [48/82]  eta: 0:01:02  loss: 0.6666  acc: 0.5312  time: 1.6210  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:31  loss: 0.6415  acc: 0.6562  time: 1.5870  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6667  acc: 0.6094  time: 1.5374  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5247  acc: 0.6875  time: 1.4801  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:19 (1.7061 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07793235778808594 uauc: 0.6292495654462831
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.00459742546081543 u-nDCG: 0.8449794636359466
rank_0 auc: 0.6577533524412822
Train: data epoch: [107]  [ 0/50]  eta: 0:00:25  lr: 0.000012  loss: 0.6305  time: 0.5075  data: 0.0000  max mem: 28728
Train: data epoch: [107]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.6041  time: 0.4963  data: 0.0000  max mem: 28728
Train: data epoch: [107] Total time: 0:00:25 (0.5022 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6581  acc: 0.5781  time: 1.0342  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7128  acc: 0.5000  time: 1.4703  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.6805  acc: 0.6250  time: 1.5564  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6626  acc: 0.5469  time: 1.5502  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6435  acc: 0.6562  time: 1.5717  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6666  acc: 0.6094  time: 1.5717  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5397  acc: 0.6875  time: 1.5136  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:06 (1.5386 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07816076278686523 uauc: 0.6330916887915501
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003057241439819336 u-nDCG: 0.8484611826127956
rank_0 auc: 0.6589049966301489
Train: data epoch: [108]  [ 0/50]  eta: 0:00:27  lr: 0.000012  loss: 0.7149  time: 0.5583  data: 0.0000  max mem: 28728
Train: data epoch: [108]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.6014  time: 0.5010  data: 0.0000  max mem: 28728
Train: data epoch: [108] Total time: 0:00:25 (0.5073 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6579  acc: 0.5781  time: 0.8919  data: 0.0058  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7228  acc: 0.5625  time: 1.4841  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:18  loss: 0.6976  acc: 0.5938  time: 1.6375  data: 0.0034  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6725  acc: 0.5000  time: 1.7504  data: 0.0047  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6439  acc: 0.6406  time: 1.7668  data: 0.0042  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6670  acc: 0.5781  time: 1.5344  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5349  acc: 0.7500  time: 1.4748  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:13 (1.6323 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07871222496032715 uauc: 0.6339094642639029
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003108978271484375 u-nDCG: 0.8488508657986014
rank_0 auc: 0.6592138439629032
Train: data epoch: [109]  [ 0/50]  eta: 0:00:23  lr: 0.000012  loss: 0.4726  time: 0.4755  data: 0.0000  max mem: 28728
Train: data epoch: [109]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5468  time: 0.4953  data: 0.0000  max mem: 28728
Train: data epoch: [109] Total time: 0:00:24 (0.4962 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6547  acc: 0.5469  time: 0.8769  data: 0.0064  max mem: 28728
Evaluation  [16/82]  eta: 0:01:40  loss: 0.7217  acc: 0.5625  time: 1.5279  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:21  loss: 0.7001  acc: 0.6250  time: 1.7427  data: 0.0060  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.6735  acc: 0.5156  time: 1.7327  data: 0.0061  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6437  acc: 0.6719  time: 1.6302  data: 0.0033  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6675  acc: 0.5938  time: 1.5095  data: 0.0025  max mem: 28728
2025-11-11 15:15:38,463 [INFO] Averaged stats: loss: 0.647817  acc: 0.587652 ***auc: 0.6639183461106544 ***uauc: 0.638727580870721 ***u-nDCG: 0.8508943298886292
2025-11-11 15:15:38,479 [INFO] Saving checkpoint at epoch 115 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 15:15:39,253 [INFO] Start training
2025-11-11 15:15:39,268 [INFO] Start training epoch 116, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:16:08,186 [INFO] Averaged stats: lr: 0.000012  loss: 0.629593
2025-11-11 15:16:08,187 [INFO] Evaluating on valid.
2025-11-11 15:18:27,954 [INFO] Averaged stats: loss: 0.649674  acc: 0.601562 ***auc: 0.6638233904042619 ***uauc: 0.6389973365603101 ***u-nDCG: 0.8506692065226705
2025-11-11 15:18:27,968 [INFO] Start training
2025-11-11 15:18:27,982 [INFO] Start training epoch 117, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:18:57,256 [INFO] Averaged stats: lr: 0.000012  loss: 0.638312
2025-11-11 15:18:57,259 [INFO] Evaluating on valid.
2025-11-11 15:21:25,289 [INFO] Averaged stats: loss: 0.652288  acc: 0.613377 ***auc: 0.6654108359977602 ***uauc: 0.6347694533225825 ***u-nDCG: 0.849485464399149
2025-11-11 15:21:25,309 [INFO] Saving checkpoint at epoch 117 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 15:21:26,096 [INFO] Start training
2025-11-11 15:21:26,114 [INFO] Start training epoch 118, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:21:54,915 [INFO] Averaged stats: lr: 0.000012  loss: 0.632876
2025-11-11 15:21:54,918 [INFO] Evaluating on valid.
2025-11-11 15:24:06,469 [INFO] Averaged stats: loss: 0.647678  acc: 0.596227 ***auc: 0.6654552328018437 ***uauc: 0.6403656564994664 ***u-nDCG: 0.8499325217280863
2025-11-11 15:24:06,475 [INFO] Saving checkpoint at epoch 118 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 15:24:06,917 [INFO] Start training
2025-11-11 15:24:06,923 [INFO] Start training epoch 119, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:24:32,004 [INFO] Averaged stats: lr: 0.000012  loss: 0.636774
2025-11-11 15:24:32,006 [INFO] Evaluating on valid.
2025-11-11 15:26:41,109 [INFO] Averaged stats: loss: 0.649205  acc: 0.604802 ***auc: 0.6648629289507104 ***uauc: 0.6485489145728452 ***u-nDCG: 0.8529539888795461
2025-11-11 15:26:41,115 [INFO] Start training
2025-11-11 15:26:41,121 [INFO] Start training epoch 120, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:27:06,374 [INFO] Averaged stats: lr: 0.000012  loss: 0.627703
2025-11-11 15:27:06,375 [INFO] Evaluating on valid.
2025-11-11 15:29:28,923 [INFO] Averaged stats: loss: 0.651216  acc: 0.607851 ***auc: 0.6640208745160712 ***uauc: 0.643368037206985 ***u-nDCG: 0.8506426267961745
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5337  acc: 0.7500  time: 1.4524  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:12 (1.6150 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07618021965026855 uauc: 0.6332026230576654
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003039836883544922 u-nDCG: 0.847570320288372
rank_0 auc: 0.6595785213904248
Train: data epoch: [110]  [ 0/50]  eta: 0:00:24  lr: 0.000012  loss: 0.6878  time: 0.4994  data: 0.0000  max mem: 28728
Train: data epoch: [110]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5858  time: 0.4991  data: 0.0000  max mem: 28728
Train: data epoch: [110] Total time: 0:00:25 (0.5043 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6805  acc: 0.5625  time: 0.9038  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7302  acc: 0.4844  time: 1.5519  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:21  loss: 0.6755  acc: 0.5781  time: 1.7119  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6634  acc: 0.5938  time: 1.5775  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6402  acc: 0.6406  time: 1.5711  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6753  acc: 0.5938  time: 1.5297  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5608  acc: 0.6250  time: 1.4710  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:09 (1.5766 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08108091354370117 uauc: 0.6412684189448178
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0031015872955322266 u-nDCG: 0.8495051105789758
rank_0 auc: 0.6575367138554704
Train: data epoch: [111]  [ 0/50]  eta: 0:00:26  lr: 0.000012  loss: 0.6345  time: 0.5342  data: 0.0000  max mem: 28728
Train: data epoch: [111]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5025  time: 0.5062  data: 0.0000  max mem: 28728
Train: data epoch: [111] Total time: 0:00:25 (0.5091 s / it)
Evaluation  [ 0/82]  eta: 0:01:27  loss: 0.6659  acc: 0.5781  time: 1.0660  data: 0.0056  max mem: 28728
Evaluation  [16/82]  eta: 0:01:38  loss: 0.7077  acc: 0.5000  time: 1.4968  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:17  loss: 0.6725  acc: 0.6094  time: 1.5920  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:53  loss: 0.6618  acc: 0.5781  time: 1.5917  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6434  acc: 0.6562  time: 1.6343  data: 0.0030  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6625  acc: 0.5938  time: 1.8442  data: 0.0048  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5460  acc: 0.6250  time: 1.7826  data: 0.0047  max mem: 28728
Evaluation Total time: 0:02:13 (1.6291 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.21744656562805176 uauc: 0.6315020408199117
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010282278060913086 u-nDCG: 0.8481818391048163
rank_0 auc: 0.6598941990007304
Train: data epoch: [112]  [ 0/50]  eta: 0:00:28  lr: 0.000012  loss: 0.7140  time: 0.5602  data: 0.0000  max mem: 28728
Train: data epoch: [112]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.7047  time: 0.5935  data: 0.0000  max mem: 28728
Train: data epoch: [112] Total time: 0:00:29 (0.5894 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6473  acc: 0.6094  time: 1.0069  data: 0.0127  max mem: 28728
Evaluation  [16/82]  eta: 0:01:50  loss: 0.7108  acc: 0.5938  time: 1.6736  data: 0.0079  max mem: 28728
Evaluation  [32/82]  eta: 0:01:26  loss: 0.6949  acc: 0.6250  time: 1.7557  data: 0.0078  max mem: 28728
Evaluation  [48/82]  eta: 0:00:59  loss: 0.6705  acc: 0.5312  time: 1.7903  data: 0.0086  max mem: 28728
Evaluation  [64/82]  eta: 0:00:32  loss: 0.6451  acc: 0.6406  time: 1.8435  data: 0.0063  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6637  acc: 0.5938  time: 1.7145  data: 0.0073  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5209  acc: 0.7500  time: 1.6492  data: 0.0065  max mem: 28728
Evaluation Total time: 0:02:23 (1.7472 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2794632911682129 uauc: 0.6352867910643414
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009909629821777344 u-nDCG: 0.8471813835622284
rank_0 auc: 0.6606208068963233
Train: data epoch: [113]  [ 0/50]  eta: 0:00:26  lr: 0.000012  loss: 0.5386  time: 0.5267  data: 0.0000  max mem: 28728
Train: data epoch: [113]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.6793  time: 0.5037  data: 0.0000  max mem: 28728
Train: data epoch: [113] Total time: 0:00:27 (0.5403 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6478  acc: 0.6250  time: 0.8944  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:38  loss: 0.7232  acc: 0.6406  time: 1.4879  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:23  loss: 0.7258  acc: 0.5938  time: 1.7935  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6952  acc: 0.5469  time: 1.5620  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6609  acc: 0.6250  time: 1.5724  data: 0.0024  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6656  acc: 0.5781  time: 1.5408  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5174  acc: 0.7500  time: 1.4820  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:10 (1.5936 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07828307151794434 uauc: 0.6410695755643397
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0035588741302490234 u-nDCG: 0.8488744149532145
rank_0 auc: 0.6611539397560611
Train: data epoch: [114]  [ 0/50]  eta: 0:00:24  lr: 0.000012  loss: 0.6182  time: 0.4903  data: 0.0000  max mem: 28728
Train: data epoch: [114]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5989  time: 0.5058  data: 0.0000  max mem: 28728
Train: data epoch: [114] Total time: 0:00:25 (0.5048 s / it)
Evaluation  [ 0/82]  eta: 0:01:25  loss: 0.6722  acc: 0.6094  time: 1.0405  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7455  acc: 0.5781  time: 1.4808  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.7729  acc: 0.5781  time: 1.5703  data: 0.0023  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.7375  acc: 0.5469  time: 1.5731  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6959  acc: 0.6094  time: 1.5818  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6764  acc: 0.6250  time: 2.3717  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5501  acc: 0.8125  time: 2.3726  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:24 (1.7588 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.24043750762939453 uauc: 0.6366131685493719
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009073734283447266 u-nDCG: 0.8485273662335483
rank_0 auc: 0.6618131357819086
Train: data epoch: [115]  [ 0/50]  eta: 0:01:15  lr: 0.000012  loss: 0.6885  time: 1.5060  data: 0.0000  max mem: 28728
Train: data epoch: [115]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5195  time: 0.5731  data: 0.0000  max mem: 28728
Train: data epoch: [115] Total time: 0:00:30 (0.6199 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6519  acc: 0.5781  time: 1.0253  data: 0.0131  max mem: 28728
2025-11-11 15:29:28,939 [INFO] Start training
2025-11-11 15:29:28,954 [INFO] Start training epoch 121, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:29:57,093 [INFO] Averaged stats: lr: 0.000013  loss: 0.641796
2025-11-11 15:29:57,094 [INFO] Evaluating on valid.
2025-11-11 15:32:22,776 [INFO] Averaged stats: loss: 0.650486  acc: 0.565549 ***auc: 0.6634185479750528 ***uauc: 0.6370594957801168 ***u-nDCG: 0.8478712072941826
2025-11-11 15:32:22,791 [INFO] Start training
2025-11-11 15:32:22,810 [INFO] Start training epoch 122, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:32:50,638 [INFO] Averaged stats: lr: 0.000013  loss: 0.631089
2025-11-11 15:32:50,638 [INFO] Evaluating on valid.
2025-11-11 15:35:05,932 [INFO] Averaged stats: loss: 0.647700  acc: 0.588224 ***auc: 0.6645218605260294 ***uauc: 0.6402468745424333 ***u-nDCG: 0.8485891804430234
2025-11-11 15:35:05,940 [INFO] Start training
2025-11-11 15:35:05,946 [INFO] Start training epoch 123, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:35:31,093 [INFO] Averaged stats: lr: 0.000013  loss: 0.623624
2025-11-11 15:35:31,094 [INFO] Evaluating on valid.
2025-11-11 15:37:36,816 [INFO] Averaged stats: loss: 0.654015  acc: 0.609375 ***auc: 0.6639865746440201 ***uauc: 0.647061881172299 ***u-nDCG: 0.8521425974965455
2025-11-11 15:37:36,823 [INFO] Start training
2025-11-11 15:37:36,829 [INFO] Start training epoch 124, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:38:01,954 [INFO] Averaged stats: lr: 0.000013  loss: 0.627620
2025-11-11 15:38:01,957 [INFO] Evaluating on valid.
2025-11-11 15:40:22,804 [INFO] Averaged stats: loss: 0.652144  acc: 0.609566 ***auc: 0.6644181442462558 ***uauc: 0.6467320068021384 ***u-nDCG: 0.8519468631291695
2025-11-11 15:40:22,821 [INFO] Start training
2025-11-11 15:40:22,838 [INFO] Start training epoch 125, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:40:51,449 [INFO] Averaged stats: lr: 0.000013  loss: 0.637739
2025-11-11 15:40:51,451 [INFO] Evaluating on valid.
2025-11-11 15:43:20,446 [INFO] Averaged stats: loss: 0.651048  acc: 0.569741 ***auc: 0.6664023398749079 ***uauc: 0.6383512020328098 ***u-nDCG: 0.8498624969530795
2025-11-11 15:43:20,460 [INFO] Saving checkpoint at epoch 125 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 15:43:21,287 [INFO] Start training
2025-11-11 15:43:21,319 [INFO] Start training epoch 126, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:43:50,573 [INFO] Averaged stats: lr: 0.000013  loss: 0.657514
2025-11-11 15:43:50,576 [INFO] Evaluating on valid.
Evaluation  [16/82]  eta: 0:01:50  loss: 0.6971  acc: 0.5625  time: 1.6817  data: 0.0099  max mem: 28728
Evaluation  [32/82]  eta: 0:01:26  loss: 0.6899  acc: 0.6250  time: 1.7829  data: 0.0076  max mem: 28728
Evaluation  [48/82]  eta: 0:00:58  loss: 0.6750  acc: 0.5938  time: 1.6833  data: 0.0042  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6572  acc: 0.6250  time: 1.5643  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6533  acc: 0.5938  time: 1.5823  data: 0.0031  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5293  acc: 0.7500  time: 1.5279  data: 0.0030  max mem: 28728
Evaluation Total time: 0:02:15 (1.6506 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.23437261581420898 uauc: 0.638727580870721
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.016773223876953125 u-nDCG: 0.8508943298886292
rank_0 auc: 0.6639183461106544
Train: data epoch: [116]  [ 0/50]  eta: 0:00:28  lr: 0.000012  loss: 0.7281  time: 0.5734  data: 0.0000  max mem: 28728
Train: data epoch: [116]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.5508  time: 0.5948  data: 0.0000  max mem: 28728
Train: data epoch: [116] Total time: 0:00:28 (0.5783 s / it)
Evaluation  [ 0/82]  eta: 0:01:30  loss: 0.6475  acc: 0.6406  time: 1.0980  data: 0.0214  max mem: 28728
Evaluation  [16/82]  eta: 0:01:47  loss: 0.7020  acc: 0.5938  time: 1.6285  data: 0.0042  max mem: 28728
Evaluation  [32/82]  eta: 0:01:25  loss: 0.7073  acc: 0.6250  time: 1.8187  data: 0.0067  max mem: 28728
Evaluation  [48/82]  eta: 0:00:57  loss: 0.6830  acc: 0.5469  time: 1.6705  data: 0.0046  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6593  acc: 0.6094  time: 1.7246  data: 0.0047  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6560  acc: 0.5781  time: 1.7932  data: 0.0060  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5078  acc: 0.7500  time: 1.7242  data: 0.0058  max mem: 28728
Evaluation Total time: 0:02:19 (1.7013 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.23616361618041992 uauc: 0.6389973365603101
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007663249969482422 u-nDCG: 0.8506692065226705
rank_0 auc: 0.6638233904042619
Train: data epoch: [117]  [ 0/50]  eta: 0:00:25  lr: 0.000012  loss: 0.6323  time: 0.5167  data: 0.0000  max mem: 28728
Train: data epoch: [117]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.7086  time: 0.5744  data: 0.0000  max mem: 28728
Train: data epoch: [117] Total time: 0:00:29 (0.5855 s / it)
Evaluation  [ 0/82]  eta: 0:01:40  loss: 0.6575  acc: 0.6094  time: 1.2267  data: 0.0092  max mem: 28728
Evaluation  [16/82]  eta: 0:01:53  loss: 0.7083  acc: 0.5938  time: 1.7174  data: 0.0072  max mem: 28728
Evaluation  [32/82]  eta: 0:01:28  loss: 0.7209  acc: 0.6406  time: 1.8199  data: 0.0079  max mem: 28728
Evaluation  [48/82]  eta: 0:01:00  loss: 0.6912  acc: 0.5156  time: 1.7982  data: 0.0054  max mem: 28728
Evaluation  [64/82]  eta: 0:00:32  loss: 0.6693  acc: 0.6094  time: 1.7947  data: 0.0070  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6641  acc: 0.5781  time: 1.8915  data: 0.0058  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5087  acc: 0.7500  time: 1.8264  data: 0.0057  max mem: 28728
Evaluation Total time: 0:02:27 (1.8020 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2250375747680664 uauc: 0.6347694533225825
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.01314854621887207 u-nDCG: 0.849485464399149
rank_0 auc: 0.6654108359977602
Train: data epoch: [118]  [ 0/50]  eta: 0:00:30  lr: 0.000012  loss: 0.5751  time: 0.6170  data: 0.0000  max mem: 28728
Train: data epoch: [118]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.7317  time: 0.5865  data: 0.0000  max mem: 28728
Train: data epoch: [118] Total time: 0:00:28 (0.5760 s / it)
Evaluation  [ 0/82]  eta: 0:01:19  loss: 0.6629  acc: 0.5938  time: 0.9749  data: 0.0153  max mem: 28728
Evaluation  [16/82]  eta: 0:01:47  loss: 0.7030  acc: 0.5938  time: 1.6361  data: 0.0067  max mem: 28728
Evaluation  [32/82]  eta: 0:01:24  loss: 0.6971  acc: 0.5781  time: 1.7301  data: 0.0073  max mem: 28728
Evaluation  [48/82]  eta: 0:00:57  loss: 0.6744  acc: 0.5938  time: 1.6431  data: 0.0042  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6687  acc: 0.6406  time: 1.5547  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6618  acc: 0.5938  time: 1.5075  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5220  acc: 0.7500  time: 1.4505  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:11 (1.6030 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07683086395263672 uauc: 0.6403656564994664
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030355453491210938 u-nDCG: 0.8499325217280863
rank_0 auc: 0.6654552328018437
Train: data epoch: [119]  [ 0/50]  eta: 0:00:24  lr: 0.000012  loss: 0.7572  time: 0.4806  data: 0.0000  max mem: 28728
Train: data epoch: [119]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.6180  time: 0.5016  data: 0.0000  max mem: 28728
Train: data epoch: [119] Total time: 0:00:25 (0.5016 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6598  acc: 0.6094  time: 0.8756  data: 0.0060  max mem: 28728
Evaluation  [16/82]  eta: 0:01:36  loss: 0.7086  acc: 0.6094  time: 1.4673  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.7044  acc: 0.6250  time: 1.5679  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6773  acc: 0.5469  time: 1.5644  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6714  acc: 0.6094  time: 1.6718  data: 0.0048  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6634  acc: 0.5938  time: 1.6492  data: 0.0040  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5254  acc: 0.7500  time: 1.5894  data: 0.0037  max mem: 28728
Evaluation Total time: 0:02:09 (1.5733 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08229255676269531 uauc: 0.6485489145728452
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003148794174194336 u-nDCG: 0.8529539888795461
rank_0 auc: 0.6648629289507104
Train: data epoch: [120]  [ 0/50]  eta: 0:00:26  lr: 0.000012  loss: 0.6057  time: 0.5264  data: 0.0000  max mem: 28728
Train: data epoch: [120]  [49/50]  eta: 0:00:00  lr: 0.000012  loss: 0.6140  time: 0.4954  data: 0.0000  max mem: 28728
Train: data epoch: [120] Total time: 0:00:25 (0.5051 s / it)
Evaluation  [ 0/82]  eta: 0:01:27  loss: 0.6518  acc: 0.5938  time: 1.0637  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:38  loss: 0.7077  acc: 0.6250  time: 1.4862  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:21  loss: 0.7161  acc: 0.6094  time: 1.7258  data: 0.0063  max mem: 28728
Evaluation  [48/82]  eta: 0:00:57  loss: 0.6821  acc: 0.5781  time: 1.7962  data: 0.0065  max mem: 28728
Evaluation  [64/82]  eta: 0:00:31  loss: 0.6653  acc: 0.6406  time: 1.8280  data: 0.0064  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6677  acc: 0.5781  time: 1.8406  data: 0.0067  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5229  acc: 0.7500  time: 1.7779  data: 0.0066  max mem: 28728
Evaluation Total time: 0:02:22 (1.7355 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2005786895751953 uauc: 0.643368037206985
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009234189987182617 u-nDCG: 0.8506426267961745
rank_0 auc: 2025-11-11 15:46:04,053 [INFO] Averaged stats: loss: 0.647058  acc: 0.572409 ***auc: 0.6661346226917559 ***uauc: 0.62880562523144 ***u-nDCG: 0.845914804860341
2025-11-11 15:46:04,071 [INFO] Start training
2025-11-11 15:46:04,087 [INFO] Start training epoch 127, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:46:34,780 [INFO] Averaged stats: lr: 0.000013  loss: 0.631423
2025-11-11 15:46:34,780 [INFO] Evaluating on valid.
2025-11-11 15:48:50,883 [INFO] Averaged stats: loss: 0.647325  acc: 0.575457 ***auc: 0.6664512654499765 ***uauc: 0.6343904823912235 ***u-nDCG: 0.8470937775894891
2025-11-11 15:48:50,897 [INFO] Saving checkpoint at epoch 127 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 15:48:51,674 [INFO] Start training
2025-11-11 15:48:51,691 [INFO] Start training epoch 128, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:49:21,572 [INFO] Averaged stats: lr: 0.000013  loss: 0.644890
2025-11-11 15:49:21,573 [INFO] Evaluating on valid.
2025-11-11 15:51:41,751 [INFO] Averaged stats: loss: 0.649005  acc: 0.569550 ***auc: 0.6654179632439008 ***uauc: 0.6353972514421223 ***u-nDCG: 0.8473135030328439
2025-11-11 15:51:41,777 [INFO] Start training
2025-11-11 15:51:41,804 [INFO] Start training epoch 129, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:52:09,723 [INFO] Averaged stats: lr: 0.000013  loss: 0.637001
2025-11-11 15:52:09,723 [INFO] Evaluating on valid.
2025-11-11 15:54:31,289 [INFO] Averaged stats: loss: 0.648008  acc: 0.597180 ***auc: 0.6648434775081187 ***uauc: 0.6427236139180302 ***u-nDCG: 0.8495191871696233
2025-11-11 15:54:31,306 [INFO] Start training
2025-11-11 15:54:31,336 [INFO] Start training epoch 130, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:54:58,826 [INFO] Averaged stats: lr: 0.000013  loss: 0.631375
2025-11-11 15:54:58,828 [INFO] Evaluating on valid.
2025-11-11 15:57:14,470 [INFO] Averaged stats: loss: 0.647609  acc: 0.598895 ***auc: 0.6658256268747071 ***uauc: 0.6404821381141194 ***u-nDCG: 0.8503384707876215
2025-11-11 15:57:14,486 [INFO] Start training
2025-11-11 15:57:14,498 [INFO] Start training epoch 131, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 15:57:42,116 [INFO] Averaged stats: lr: 0.000013  loss: 0.606092
2025-11-11 15:57:42,118 [INFO] Evaluating on valid.
2025-11-11 15:59:53,287 [INFO] Averaged stats: loss: 0.648899  acc: 0.597561 ***auc: 0.6648960409484048 ***uauc: 0.6389608207633667 ***u-nDCG: 0.848226704167182
2025-11-11 15:59:53,307 [INFO] Start training
2025-11-11 15:59:53,326 [INFO] Start training epoch 132, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:00:20,573 [INFO] Averaged stats: lr: 0.000013  loss: 0.625851
2025-11-11 16:00:20,575 [INFO] Evaluating on valid.
0.6640208745160712
Train: data epoch: [121]  [ 0/50]  eta: 0:00:29  lr: 0.000012  loss: 0.5917  time: 0.5936  data: 0.0000  max mem: 28728
Train: data epoch: [121]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.7177  time: 0.5649  data: 0.0000  max mem: 28728
Train: data epoch: [121] Total time: 0:00:28 (0.5628 s / it)
Evaluation  [ 0/82]  eta: 0:01:21  loss: 0.6696  acc: 0.5156  time: 0.9919  data: 0.0107  max mem: 28728
Evaluation  [16/82]  eta: 0:01:50  loss: 0.6934  acc: 0.5469  time: 1.6803  data: 0.0095  max mem: 28728
Evaluation  [32/82]  eta: 0:01:27  loss: 0.6768  acc: 0.6094  time: 1.7903  data: 0.0066  max mem: 28728
Evaluation  [48/82]  eta: 0:01:00  loss: 0.6613  acc: 0.5625  time: 1.8489  data: 0.0081  max mem: 28728
Evaluation  [64/82]  eta: 0:00:32  loss: 0.6634  acc: 0.5938  time: 1.8227  data: 0.0090  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6634  acc: 0.5781  time: 1.7541  data: 0.0088  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5413  acc: 0.6875  time: 1.6895  data: 0.0074  max mem: 28728
Evaluation Total time: 0:02:25 (1.7719 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.32921266555786133 uauc: 0.6370594957801168
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010596036911010742 u-nDCG: 0.8478712072941826
rank_0 auc: 0.6634185479750528
Train: data epoch: [122]  [ 0/50]  eta: 0:00:28  lr: 0.000013  loss: 0.6580  time: 0.5707  data: 0.0000  max mem: 28728
Train: data epoch: [122]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.7034  time: 0.5527  data: 0.0000  max mem: 28728
Train: data epoch: [122] Total time: 0:00:27 (0.5565 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6506  acc: 0.5625  time: 0.9773  data: 0.0211  max mem: 28728
Evaluation  [16/82]  eta: 0:01:53  loss: 0.6958  acc: 0.6094  time: 1.7208  data: 0.0090  max mem: 28728
Evaluation  [32/82]  eta: 0:01:30  loss: 0.6894  acc: 0.6562  time: 1.8781  data: 0.0077  max mem: 28728
Evaluation  [48/82]  eta: 0:00:58  loss: 0.6655  acc: 0.5625  time: 1.5789  data: 0.0035  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6538  acc: 0.6250  time: 1.5573  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6663  acc: 0.6094  time: 1.5668  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5232  acc: 0.7500  time: 1.5100  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:15 (1.6485 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07817554473876953 uauc: 0.6402468745424333
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030274391174316406 u-nDCG: 0.8485891804430234
rank_0 auc: 0.6645218605260294
Train: data epoch: [123]  [ 0/50]  eta: 0:00:23  lr: 0.000013  loss: 0.6927  time: 0.4739  data: 0.0000  max mem: 28728
Train: data epoch: [123]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.6881  time: 0.5026  data: 0.0000  max mem: 28728
Train: data epoch: [123] Total time: 0:00:25 (0.5029 s / it)
Evaluation  [ 0/82]  eta: 0:01:25  loss: 0.6450  acc: 0.5938  time: 1.0457  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7139  acc: 0.6406  time: 1.4825  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.7293  acc: 0.5938  time: 1.5542  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6898  acc: 0.5625  time: 1.5533  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6654  acc: 0.6406  time: 1.5550  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6704  acc: 0.5781  time: 1.5467  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5220  acc: 0.7500  time: 1.4911  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:05 (1.5320 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08241415023803711 uauc: 0.647061881172299
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030634403228759766 u-nDCG: 0.8521425974965455
rank_0 auc: 0.6639865746440201
Train: data epoch: [124]  [ 0/50]  eta: 0:00:24  lr: 0.000013  loss: 0.5322  time: 0.4985  data: 0.0000  max mem: 28728
Train: data epoch: [124]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.5697  time: 0.5004  data: 0.0000  max mem: 28728
Train: data epoch: [124] Total time: 0:00:25 (0.5025 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6469  acc: 0.6094  time: 0.8996  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7115  acc: 0.6406  time: 1.4799  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:17  loss: 0.7216  acc: 0.6094  time: 1.6129  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.6820  acc: 0.5781  time: 1.8134  data: 0.0048  max mem: 28728
Evaluation  [64/82]  eta: 0:00:31  loss: 0.6598  acc: 0.6562  time: 1.9515  data: 0.0040  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6696  acc: 0.5781  time: 1.6748  data: 0.0056  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5311  acc: 0.7500  time: 1.6202  data: 0.0055  max mem: 28728
Evaluation Total time: 0:02:20 (1.7150 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.19275975227355957 uauc: 0.6467320068021384
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007625102996826172 u-nDCG: 0.8519468631291695
rank_0 auc: 0.6644181442462558
Train: data epoch: [125]  [ 0/50]  eta: 0:00:26  lr: 0.000013  loss: 0.7911  time: 0.5320  data: 0.0000  max mem: 28728
Train: data epoch: [125]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.8099  time: 0.5663  data: 0.0000  max mem: 28728
Train: data epoch: [125] Total time: 0:00:28 (0.5722 s / it)
Evaluation  [ 0/82]  eta: 0:01:19  loss: 0.6615  acc: 0.5469  time: 0.9744  data: 0.0138  max mem: 28728
Evaluation  [16/82]  eta: 0:01:49  loss: 0.6957  acc: 0.5469  time: 1.6649  data: 0.0099  max mem: 28728
Evaluation  [32/82]  eta: 0:01:34  loss: 0.6785  acc: 0.5938  time: 2.0488  data: 0.0062  max mem: 28728
Evaluation  [48/82]  eta: 0:01:03  loss: 0.6584  acc: 0.5938  time: 1.8628  data: 0.0058  max mem: 28728
Evaluation  [64/82]  eta: 0:00:33  loss: 0.6501  acc: 0.6406  time: 1.7853  data: 0.0061  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6674  acc: 0.5625  time: 1.7526  data: 0.0049  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5369  acc: 0.6875  time: 1.6881  data: 0.0048  max mem: 28728
Evaluation Total time: 0:02:28 (1.8137 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.23183798789978027 uauc: 0.6383512020328098
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009242534637451172 u-nDCG: 0.8498624969530795
rank_0 auc: 0.6664023398749079
Train: data epoch: [126]  [ 0/50]  eta: 0:00:27  lr: 0.000013  loss: 0.5233  time: 0.5539  data: 0.0000  max mem: 28728
Train: data epoch: [126]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.6884  time: 0.5868  data: 0.0000  max mem: 28728
Train: data epoch: [126] Total time: 0:00:29 (0.5851 s / it)
Evaluation  [ 0/82]  eta: 0:01:35  loss: 0.6587  acc: 0.5469  time: 1.1624  data: 0.0137  max mem: 28728
Evaluation  [16/82]  eta: 0:01:48  loss: 0.6896  acc: 0.5312  time: 1.6381  data: 0.0082  max mem: 28728
Evaluation  [32/82]  eta: 0:01:23  loss: 0.6847  acc: 0.6094  time: 1.6938  data: 0.0063  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6722  acc: 0.5781  time: 1.5454  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6587  acc: 0.6562  time: 1.5461  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6553  acc: 0.5469  time: 1.7124  data: 0.0057  max mem: 28728
2025-11-11 16:02:31,883 [INFO] Averaged stats: loss: 0.647894  acc: 0.598895 ***auc: 0.6656069095087709 ***uauc: 0.6411321869285979 ***u-nDCG: 0.8494426147072565
2025-11-11 16:02:31,898 [INFO] Start training
2025-11-11 16:02:31,914 [INFO] Start training epoch 133, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:02:59,160 [INFO] Averaged stats: lr: 0.000013  loss: 0.615125
2025-11-11 16:02:59,163 [INFO] Evaluating on valid.
2025-11-11 16:05:10,837 [INFO] Averaged stats: loss: 0.649042  acc: 0.597561 ***auc: 0.6662511828630118 ***uauc: 0.6438344123529094 ***u-nDCG: 0.8521890657398606
2025-11-11 16:05:10,857 [INFO] Start training
2025-11-11 16:05:10,876 [INFO] Start training epoch 134, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:05:38,548 [INFO] Averaged stats: lr: 0.000013  loss: 0.622442
2025-11-11 16:05:38,550 [INFO] Evaluating on valid.
2025-11-11 16:07:55,609 [INFO] Averaged stats: loss: 0.649793  acc: 0.601562 ***auc: 0.665720054541251 ***uauc: 0.6468431334580984 ***u-nDCG: 0.8529656029979532
2025-11-11 16:07:55,626 [INFO] Start training
2025-11-11 16:07:55,640 [INFO] Start training epoch 135, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:08:23,122 [INFO] Averaged stats: lr: 0.000013  loss: 0.626495
2025-11-11 16:08:23,127 [INFO] Evaluating on valid.
2025-11-11 16:10:46,616 [INFO] Averaged stats: loss: 0.650361  acc: 0.584985 ***auc: 0.6656626653613908 ***uauc: 0.6444880437923413 ***u-nDCG: 0.8517336336640474
2025-11-11 16:10:46,631 [INFO] Start training
2025-11-11 16:10:46,646 [INFO] Start training epoch 136, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:11:15,205 [INFO] Averaged stats: lr: 0.000013  loss: 0.621892
2025-11-11 16:11:15,208 [INFO] Evaluating on valid.
2025-11-11 16:13:28,143 [INFO] Averaged stats: loss: 0.686239  acc: 0.621761 ***auc: 0.6638038647195228 ***uauc: 0.6412334460028412 ***u-nDCG: 0.8496262695007013
2025-11-11 16:13:28,158 [INFO] Start training
2025-11-11 16:13:28,173 [INFO] Start training epoch 137, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:13:55,943 [INFO] Averaged stats: lr: 0.000013  loss: 0.634274
2025-11-11 16:13:55,946 [INFO] Evaluating on valid.
2025-11-11 16:16:09,844 [INFO] Averaged stats: loss: 0.649854  acc: 0.584413 ***auc: 0.6659703990619356 ***uauc: 0.6521585930678963 ***u-nDCG: 0.853099365266357
2025-11-11 16:16:09,864 [INFO] Start training
2025-11-11 16:16:09,881 [INFO] Start training epoch 138, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5472  acc: 0.6875  time: 1.6586  data: 0.0057  max mem: 28728
Evaluation Total time: 0:02:13 (1.6244 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.24457693099975586 uauc: 0.62880562523144
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0101318359375 u-nDCG: 0.845914804860341
rank_0 auc: 0.6661346226917559
Train: data epoch: [127]  [ 0/50]  eta: 0:00:28  lr: 0.000013  loss: 0.6482  time: 0.5659  data: 0.0000  max mem: 28728
Train: data epoch: [127]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.7323  time: 0.5703  data: 0.0000  max mem: 28728
Train: data epoch: [127] Total time: 0:00:30 (0.6139 s / it)
Evaluation  [ 0/82]  eta: 0:01:19  loss: 0.6586  acc: 0.5469  time: 0.9642  data: 0.0128  max mem: 28728
Evaluation  [16/82]  eta: 0:01:44  loss: 0.6936  acc: 0.5312  time: 1.5817  data: 0.0051  max mem: 28728
Evaluation  [32/82]  eta: 0:01:18  loss: 0.6845  acc: 0.6094  time: 1.5835  data: 0.0031  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6672  acc: 0.5938  time: 1.6238  data: 0.0035  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6557  acc: 0.6562  time: 1.7869  data: 0.0070  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6565  acc: 0.5469  time: 1.7396  data: 0.0070  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5358  acc: 0.6875  time: 1.6752  data: 0.0069  max mem: 28728
Evaluation Total time: 0:02:15 (1.6568 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.21349644660949707 uauc: 0.6343904823912235
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.008501529693603516 u-nDCG: 0.8470937775894891
rank_0 auc: 0.6664512654499765
Train: data epoch: [128]  [ 0/50]  eta: 0:00:25  lr: 0.000013  loss: 0.7800  time: 0.5044  data: 0.0000  max mem: 28728
Train: data epoch: [128]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.5759  time: 0.5899  data: 0.0000  max mem: 28728
Train: data epoch: [128] Total time: 0:00:29 (0.5976 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6653  acc: 0.5625  time: 1.0266  data: 0.0138  max mem: 28728
Evaluation  [16/82]  eta: 0:01:50  loss: 0.6972  acc: 0.5156  time: 1.6782  data: 0.0062  max mem: 28728
Evaluation  [32/82]  eta: 0:01:26  loss: 0.6759  acc: 0.5938  time: 1.7561  data: 0.0060  max mem: 28728
Evaluation  [48/82]  eta: 0:00:59  loss: 0.6586  acc: 0.6094  time: 1.7155  data: 0.0062  max mem: 28728
Evaluation  [64/82]  eta: 0:00:31  loss: 0.6507  acc: 0.6250  time: 1.7108  data: 0.0052  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6626  acc: 0.5469  time: 1.6905  data: 0.0084  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5509  acc: 0.6250  time: 1.6307  data: 0.0081  max mem: 28728
Evaluation Total time: 0:02:19 (1.7072 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.14630699157714844 uauc: 0.6353972514421223
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.012243986129760742 u-nDCG: 0.8473135030328439
rank_0 auc: 0.6654179632439008
Train: data epoch: [129]  [ 0/50]  eta: 0:00:27  lr: 0.000013  loss: 0.6157  time: 0.5516  data: 0.0000  max mem: 28728
Train: data epoch: [129]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.5264  time: 0.5621  data: 0.0000  max mem: 28728
Train: data epoch: [129] Total time: 0:00:27 (0.5584 s / it)
Evaluation  [ 0/82]  eta: 0:01:40  loss: 0.6464  acc: 0.5938  time: 1.2291  data: 0.0050  max mem: 28728
Evaluation  [16/82]  eta: 0:01:46  loss: 0.7042  acc: 0.5938  time: 1.6207  data: 0.0049  max mem: 28728
Evaluation  [32/82]  eta: 0:01:22  loss: 0.6949  acc: 0.6406  time: 1.6907  data: 0.0057  max mem: 28728
Evaluation  [48/82]  eta: 0:00:57  loss: 0.6685  acc: 0.5781  time: 1.7034  data: 0.0043  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6484  acc: 0.6562  time: 1.7069  data: 0.0057  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6644  acc: 0.6250  time: 1.8971  data: 0.0061  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5350  acc: 0.7500  time: 1.8347  data: 0.0058  max mem: 28728
Evaluation Total time: 0:02:21 (1.7236 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.20970535278320312 uauc: 0.6427236139180302
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.008496999740600586 u-nDCG: 0.8495191871696233
rank_0 auc: 0.6648434775081187
Train: data epoch: [130]  [ 0/50]  eta: 0:00:26  lr: 0.000013  loss: 0.6701  time: 0.5316  data: 0.0000  max mem: 28728
Train: data epoch: [130]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.5707  time: 0.5462  data: 0.0001  max mem: 28728
Train: data epoch: [130] Total time: 0:00:27 (0.5498 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6545  acc: 0.6094  time: 0.9833  data: 0.0261  max mem: 28728
Evaluation  [16/82]  eta: 0:01:45  loss: 0.7054  acc: 0.5781  time: 1.5997  data: 0.0074  max mem: 28728
Evaluation  [32/82]  eta: 0:01:22  loss: 0.7013  acc: 0.6406  time: 1.6971  data: 0.0051  max mem: 28728
Evaluation  [48/82]  eta: 0:00:57  loss: 0.6719  acc: 0.5938  time: 1.7318  data: 0.0045  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6585  acc: 0.6562  time: 1.6877  data: 0.0039  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6639  acc: 0.5781  time: 1.6000  data: 0.0058  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5379  acc: 0.7500  time: 1.5405  data: 0.0056  max mem: 28728
Evaluation Total time: 0:02:15 (1.6518 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.17378473281860352 uauc: 0.6404821381141194
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007659196853637695 u-nDCG: 0.8503384707876215
rank_0 auc: 0.6658256268747071
Train: data epoch: [131]  [ 0/50]  eta: 0:00:25  lr: 0.000013  loss: 0.4527  time: 0.5106  data: 0.0000  max mem: 28728
Train: data epoch: [131]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.5772  time: 0.5547  data: 0.0000  max mem: 28728
Train: data epoch: [131] Total time: 0:00:27 (0.5523 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 0.6452  acc: 0.5781  time: 0.9172  data: 0.0225  max mem: 28728
Evaluation  [16/82]  eta: 0:01:40  loss: 0.7055  acc: 0.6094  time: 1.5252  data: 0.0059  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6961  acc: 0.6250  time: 1.6292  data: 0.0040  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6684  acc: 0.5469  time: 1.6122  data: 0.0050  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6458  acc: 0.6719  time: 1.6162  data: 0.0050  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6598  acc: 0.5938  time: 1.6107  data: 0.0039  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5229  acc: 0.7500  time: 1.5543  data: 0.0035  max mem: 28728
Evaluation Total time: 0:02:10 (1.5967 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2132260799407959 uauc: 0.6389608207633667
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0076749324798583984 u-nDCG: 0.848226704167182
rank_0 auc: 0.6648960409484048
Train: data epoch: [132]  [ 0/50]  eta: 0:00:27  lr: 0.000013  loss: 0.6398  time: 0.5505  data: 0.0000  max mem: 28728
Train: data epoch: [132]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.4703  time: 0.5418  data: 0.0000  max mem: 28728
Train: data epoch: [132] Total time: 0:00:27 (0.5450 s / it)
Evaluation  [ 0/82]  eta: 0:01:32  loss: 0.6419  acc: 0.5781  time: 1.1339  data: 0.0138  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.6998  acc: 0.6094  time: 1.5372  data: 0.0043  max mem: 28728
2025-11-11 16:16:37,570 [INFO] Averaged stats: lr: 0.000013  loss: 0.646710
2025-11-11 16:16:37,574 [INFO] Evaluating on valid.
2025-11-11 16:18:51,799 [INFO] Averaged stats: loss: 0.648752  acc: 0.602134 ***auc: 0.6659385491807452 ***uauc: 0.6487600713589311 ***u-nDCG: 0.8540165060867612
2025-11-11 16:18:51,820 [INFO] Start training
2025-11-11 16:18:51,836 [INFO] Start training epoch 139, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:19:18,805 [INFO] Averaged stats: lr: 0.000013  loss: 0.667088
2025-11-11 16:19:18,806 [INFO] Evaluating on valid.
2025-11-11 16:21:29,427 [INFO] Averaged stats: loss: 0.665191  acc: 0.529916 ***auc: 0.6669002077146797 ***uauc: 0.646044628633292 ***u-nDCG: 0.854350163372996
2025-11-11 16:21:29,442 [INFO] Saving checkpoint at epoch 139 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 16:21:30,174 [INFO] Start training
2025-11-11 16:21:30,194 [INFO] Start training epoch 140, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:21:58,077 [INFO] Averaged stats: lr: 0.000013  loss: 0.645507
2025-11-11 16:21:58,079 [INFO] Evaluating on valid.
2025-11-11 16:24:10,182 [INFO] Averaged stats: loss: 0.656682  acc: 0.616806 ***auc: 0.666133880270283 ***uauc: 0.6467044376434534 ***u-nDCG: 0.8546454673509812
2025-11-11 16:24:10,198 [INFO] Start training
2025-11-11 16:24:10,221 [INFO] Start training epoch 141, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:24:37,750 [INFO] Averaged stats: lr: 0.000013  loss: 0.640954
2025-11-11 16:24:37,751 [INFO] Evaluating on valid.
2025-11-11 16:26:50,436 [INFO] Averaged stats: loss: 0.651972  acc: 0.607279 ***auc: 0.6652408957225981 ***uauc: 0.6477976019058103 ***u-nDCG: 0.8523833463662015
2025-11-11 16:26:50,452 [INFO] Start training
2025-11-11 16:26:50,467 [INFO] Start training epoch 142, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:27:17,792 [INFO] Averaged stats: lr: 0.000013  loss: 0.609854
2025-11-11 16:27:17,793 [INFO] Evaluating on valid.
2025-11-11 16:29:30,364 [INFO] Averaged stats: loss: 0.654322  acc: 0.615091 ***auc: 0.6650810523794682 ***uauc: 0.6508074520091462 ***u-nDCG: 0.8530336875828138
2025-11-11 16:29:30,382 [INFO] Start training
2025-11-11 16:29:30,399 [INFO] Start training epoch 143, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:29:57,799 [INFO] Averaged stats: lr: 0.000013  loss: 0.636653
2025-11-11 16:29:57,802 [INFO] Evaluating on valid.
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6971  acc: 0.6250  time: 1.6263  data: 0.0044  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6682  acc: 0.5469  time: 1.6159  data: 0.0043  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6443  acc: 0.6562  time: 1.6166  data: 0.0050  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6594  acc: 0.5938  time: 1.6222  data: 0.0039  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5306  acc: 0.7500  time: 1.5602  data: 0.0037  max mem: 28728
Evaluation Total time: 0:02:11 (1.5982 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.22699952125549316 uauc: 0.6411321869285979
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007630109786987305 u-nDCG: 0.8494426147072565
rank_0 auc: 0.6656069095087709
Train: data epoch: [133]  [ 0/50]  eta: 0:00:25  lr: 0.000013  loss: 0.6602  time: 0.5129  data: 0.0000  max mem: 28728
Train: data epoch: [133]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.5837  time: 0.5406  data: 0.0000  max mem: 28728
Train: data epoch: [133] Total time: 0:00:27 (0.5449 s / it)
Evaluation  [ 0/82]  eta: 0:01:17  loss: 0.6494  acc: 0.6094  time: 0.9455  data: 0.0137  max mem: 28728
Evaluation  [16/82]  eta: 0:01:40  loss: 0.7016  acc: 0.5938  time: 1.5231  data: 0.0067  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6988  acc: 0.6094  time: 1.6372  data: 0.0059  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6718  acc: 0.5625  time: 1.6422  data: 0.0049  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6508  acc: 0.6719  time: 1.6460  data: 0.0053  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6590  acc: 0.5781  time: 1.5952  data: 0.0040  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5315  acc: 0.7500  time: 1.5395  data: 0.0037  max mem: 28728
Evaluation Total time: 0:02:11 (1.6023 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2434859275817871 uauc: 0.6438344123529094
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.02471470832824707 u-nDCG: 0.8521890657398606
rank_0 auc: 0.6662511828630118
Train: data epoch: [134]  [ 0/50]  eta: 0:00:27  lr: 0.000013  loss: 0.6282  time: 0.5525  data: 0.0000  max mem: 28728
Train: data epoch: [134]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.5476  time: 0.5593  data: 0.0000  max mem: 28728
Train: data epoch: [134] Total time: 0:00:27 (0.5535 s / it)
Evaluation  [ 0/82]  eta: 0:01:17  loss: 0.6424  acc: 0.6562  time: 0.9419  data: 0.0275  max mem: 28728
Evaluation  [16/82]  eta: 0:01:43  loss: 0.6995  acc: 0.6094  time: 1.5617  data: 0.0062  max mem: 28728
Evaluation  [32/82]  eta: 0:01:23  loss: 0.7100  acc: 0.6250  time: 1.7443  data: 0.0067  max mem: 28728
Evaluation  [48/82]  eta: 0:00:58  loss: 0.6810  acc: 0.5625  time: 1.8669  data: 0.0054  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6494  acc: 0.6406  time: 1.6441  data: 0.0047  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6564  acc: 0.6094  time: 1.6109  data: 0.0051  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5240  acc: 0.7500  time: 1.5498  data: 0.0045  max mem: 28728
Evaluation Total time: 0:02:16 (1.6681 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.24854087829589844 uauc: 0.6468431334580984
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.008993387222290039 u-nDCG: 0.8529656029979532
rank_0 auc: 0.665720054541251
Train: data epoch: [135]  [ 0/50]  eta: 0:00:24  lr: 0.000013  loss: 0.6310  time: 0.4873  data: 0.0000  max mem: 28728
Train: data epoch: [135]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.5322  time: 0.5523  data: 0.0000  max mem: 28728
Train: data epoch: [135] Total time: 0:00:27 (0.5497 s / it)
Evaluation  [ 0/82]  eta: 0:01:19  loss: 0.6402  acc: 0.5938  time: 0.9668  data: 0.0169  max mem: 28728
Evaluation  [16/82]  eta: 0:02:08  loss: 0.6943  acc: 0.5469  time: 1.9500  data: 0.0061  max mem: 28728
Evaluation  [32/82]  eta: 0:01:30  loss: 0.6971  acc: 0.5938  time: 1.7480  data: 0.0052  max mem: 28728
Evaluation  [48/82]  eta: 0:01:00  loss: 0.6742  acc: 0.5781  time: 1.6359  data: 0.0046  max mem: 28728
Evaluation  [64/82]  eta: 0:00:31  loss: 0.6438  acc: 0.6406  time: 1.6393  data: 0.0049  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6499  acc: 0.6094  time: 1.8087  data: 0.0040  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5331  acc: 0.6875  time: 1.7538  data: 0.0039  max mem: 28728
Evaluation Total time: 0:02:23 (1.7473 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.16817259788513184 uauc: 0.6444880437923413
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009158849716186523 u-nDCG: 0.8517336336640474
rank_0 auc: 0.6656626653613908
Train: data epoch: [136]  [ 0/50]  eta: 0:00:32  lr: 0.000013  loss: 0.6424  time: 0.6565  data: 0.0000  max mem: 28728
Train: data epoch: [136]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.6058  time: 0.5505  data: 0.0000  max mem: 28728
Train: data epoch: [136] Total time: 0:00:28 (0.5712 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6674  acc: 0.5938  time: 0.9140  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7539  acc: 0.5469  time: 1.5506  data: 0.0046  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.8049  acc: 0.5156  time: 1.6475  data: 0.0061  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.7626  acc: 0.5781  time: 1.6247  data: 0.0053  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.7023  acc: 0.6094  time: 1.6857  data: 0.0045  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6764  acc: 0.6562  time: 1.6141  data: 0.0045  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5670  acc: 0.7500  time: 1.5553  data: 0.0043  max mem: 28728
Evaluation Total time: 0:02:12 (1.6181 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.22539901733398438 uauc: 0.6412334460028412
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.01005244255065918 u-nDCG: 0.8496262695007013
rank_0 auc: 0.6638038647195228
Train: data epoch: [137]  [ 0/50]  eta: 0:00:26  lr: 0.000013  loss: 0.9096  time: 0.5369  data: 0.0000  max mem: 28728
Train: data epoch: [137]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.6488  time: 0.5438  data: 0.0000  max mem: 28728
Train: data epoch: [137] Total time: 0:00:27 (0.5554 s / it)
Evaluation  [ 0/82]  eta: 0:01:17  loss: 0.6459  acc: 0.5781  time: 0.9451  data: 0.0137  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7026  acc: 0.5625  time: 1.5529  data: 0.0050  max mem: 28728
Evaluation  [32/82]  eta: 0:01:21  loss: 0.6866  acc: 0.6094  time: 1.7016  data: 0.0056  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.6662  acc: 0.5625  time: 1.6895  data: 0.0065  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6450  acc: 0.6562  time: 1.6339  data: 0.0043  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6556  acc: 0.5938  time: 1.5948  data: 0.0046  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5380  acc: 0.6875  time: 1.5376  data: 0.0046  max mem: 28728
Evaluation Total time: 0:02:13 (1.6294 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2435309886932373 uauc: 0.6521585930678963
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007673025131225586 u-nDCG: 0.853099365266357
rank_0 auc: 0.6659703990619356
2025-11-11 16:32:11,821 [INFO] Averaged stats: loss: 0.649895  acc: 0.575457 ***auc: 0.6667885475251454 ***uauc: 0.6532065924073942 ***u-nDCG: 0.8540810932605892
2025-11-11 16:32:11,850 [INFO] Start training
2025-11-11 16:32:11,871 [INFO] Start training epoch 144, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:32:39,723 [INFO] Averaged stats: lr: 0.000014  loss: 0.630840
2025-11-11 16:32:39,725 [INFO] Evaluating on valid.
2025-11-11 16:34:56,494 [INFO] Averaged stats: loss: 0.649990  acc: 0.606517 ***auc: 0.6656415063494112 ***uauc: 0.6448217376154797 ***u-nDCG: 0.8522500006694096
2025-11-11 16:34:56,511 [INFO] Start training
2025-11-11 16:34:56,524 [INFO] Start training epoch 145, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:35:24,315 [INFO] Averaged stats: lr: 0.000014  loss: 0.622430
2025-11-11 16:35:24,316 [INFO] Evaluating on valid.
2025-11-11 16:37:39,195 [INFO] Averaged stats: loss: 0.646696  acc: 0.585747 ***auc: 0.6666028679147563 ***uauc: 0.6309513917619851 ***u-nDCG: 0.8476804272170676
2025-11-11 16:37:39,218 [INFO] Start training
2025-11-11 16:37:39,236 [INFO] Start training epoch 146, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:38:06,995 [INFO] Averaged stats: lr: 0.000014  loss: 0.626854
2025-11-11 16:38:06,997 [INFO] Evaluating on valid.
2025-11-11 16:40:22,840 [INFO] Averaged stats: loss: 0.647374  acc: 0.594893 ***auc: 0.6670760131194784 ***uauc: 0.6438649855721101 ***u-nDCG: 0.850277355254802
2025-11-11 16:40:22,854 [INFO] Saving checkpoint at epoch 146 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 16:40:23,573 [INFO] Start training
2025-11-11 16:40:23,580 [INFO] Start training epoch 147, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:40:50,896 [INFO] Averaged stats: lr: 0.000014  loss: 0.649501
2025-11-11 16:40:50,898 [INFO] Evaluating on valid.
2025-11-11 16:43:06,270 [INFO] Averaged stats: loss: 0.645610  acc: 0.589177 ***auc: 0.6667829793640981 ***uauc: 0.6421867111360168 ***u-nDCG: 0.8497179491540322
2025-11-11 16:43:06,297 [INFO] Start training
2025-11-11 16:43:06,317 [INFO] Start training epoch 148, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:43:34,102 [INFO] Averaged stats: lr: 0.000014  loss: 0.619932
2025-11-11 16:43:34,104 [INFO] Evaluating on valid.
2025-11-11 16:45:48,588 [INFO] Averaged stats: loss: 0.647141  acc: 0.607660 ***auc: 0.6673458833249017 ***uauc: 0.6432048111915131 ***u-nDCG: 0.849818011891145
2025-11-11 16:45:48,607 [INFO] Saving checkpoint at epoch 148 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 16:45:49,405 [INFO] Start training
2025-11-11 16:45:49,422 [INFO] Start training epoch 149, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:46:17,216 [INFO] Averaged stats: lr: 0.000014  loss: 0.605859
2025-11-11 16:46:17,218 [INFO] Evaluating on valid.
Train: data epoch: [138]  [ 0/50]  eta: 0:00:25  lr: 0.000013  loss: 0.5704  time: 0.5157  data: 0.0000  max mem: 28728
Train: data epoch: [138]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.6994  time: 0.5549  data: 0.0000  max mem: 28728
Train: data epoch: [138] Total time: 0:00:27 (0.5537 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6424  acc: 0.6406  time: 0.8935  data: 0.0108  max mem: 28728
Evaluation  [16/82]  eta: 0:01:43  loss: 0.7022  acc: 0.6094  time: 1.5690  data: 0.0069  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.7086  acc: 0.6250  time: 1.6163  data: 0.0058  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6835  acc: 0.5625  time: 1.6281  data: 0.0052  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6545  acc: 0.6562  time: 1.6444  data: 0.0053  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6516  acc: 0.5938  time: 1.7149  data: 0.0072  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5273  acc: 0.7500  time: 1.6570  data: 0.0070  max mem: 28728
Evaluation Total time: 0:02:13 (1.6340 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2056429386138916 uauc: 0.6487600713589311
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010765552520751953 u-nDCG: 0.8540165060867612
rank_0 auc: 0.6659385491807452
Train: data epoch: [139]  [ 0/50]  eta: 0:00:26  lr: 0.000013  loss: 0.6667  time: 0.5284  data: 0.0000  max mem: 28728
Train: data epoch: [139]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.7637  time: 0.5381  data: 0.0000  max mem: 28728
Train: data epoch: [139] Total time: 0:00:26 (0.5394 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 0.6707  acc: 0.5000  time: 0.9252  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.7005  acc: 0.5312  time: 1.5361  data: 0.0047  max mem: 28728
Evaluation  [32/82]  eta: 0:01:18  loss: 0.6563  acc: 0.6562  time: 1.6100  data: 0.0050  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6602  acc: 0.5625  time: 1.6063  data: 0.0045  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6559  acc: 0.5625  time: 1.6378  data: 0.0054  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6727  acc: 0.5469  time: 1.5942  data: 0.0061  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5648  acc: 0.5625  time: 1.5359  data: 0.0059  max mem: 28728
Evaluation Total time: 0:02:10 (1.5900 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.22136354446411133 uauc: 0.646044628633292
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007645845413208008 u-nDCG: 0.854350163372996
rank_0 auc: 0.6669002077146797
Train: data epoch: [140]  [ 0/50]  eta: 0:00:26  lr: 0.000013  loss: 0.7135  time: 0.5239  data: 0.0000  max mem: 28728
Train: data epoch: [140]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.5606  time: 0.5660  data: 0.0000  max mem: 28728
Train: data epoch: [140] Total time: 0:00:27 (0.5577 s / it)
Evaluation  [ 0/82]  eta: 0:01:17  loss: 0.6439  acc: 0.6562  time: 0.9479  data: 0.0198  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7137  acc: 0.6406  time: 1.5541  data: 0.0062  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.7297  acc: 0.5469  time: 1.6471  data: 0.0053  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.7012  acc: 0.5469  time: 1.6486  data: 0.0045  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6714  acc: 0.6406  time: 1.6166  data: 0.0044  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6613  acc: 0.5938  time: 1.6128  data: 0.0055  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5522  acc: 0.7500  time: 1.5523  data: 0.0054  max mem: 28728
Evaluation Total time: 0:02:11 (1.6082 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.20519351959228516 uauc: 0.6467044376434534
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007354021072387695 u-nDCG: 0.8546454673509812
rank_0 auc: 0.666133880270283
Train: data epoch: [141]  [ 0/50]  eta: 0:00:27  lr: 0.000013  loss: 0.7568  time: 0.5415  data: 0.0000  max mem: 28728
Train: data epoch: [141]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.6515  time: 0.5423  data: 0.0000  max mem: 28728
Train: data epoch: [141] Total time: 0:00:27 (0.5506 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6397  acc: 0.6406  time: 0.8863  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:44  loss: 0.7040  acc: 0.6094  time: 1.5849  data: 0.0035  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.7162  acc: 0.5938  time: 1.6208  data: 0.0051  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6917  acc: 0.6094  time: 1.6450  data: 0.0049  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6593  acc: 0.6250  time: 1.6418  data: 0.0051  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6562  acc: 0.5938  time: 1.6172  data: 0.0046  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5402  acc: 0.7500  time: 1.5605  data: 0.0044  max mem: 28728
Evaluation Total time: 0:02:12 (1.6152 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.20902705192565918 uauc: 0.6477976019058103
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009160280227661133 u-nDCG: 0.8523833463662015
rank_0 auc: 0.6652408957225981
Train: data epoch: [142]  [ 0/50]  eta: 0:00:27  lr: 0.000013  loss: 0.5646  time: 0.5439  data: 0.0000  max mem: 28728
Train: data epoch: [142]  [49/50]  eta: 0:00:00  lr: 0.000013  loss: 0.6084  time: 0.5384  data: 0.0000  max mem: 28728
Train: data epoch: [142] Total time: 0:00:27 (0.5465 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6402  acc: 0.6562  time: 0.9122  data: 0.0105  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7163  acc: 0.6094  time: 1.5498  data: 0.0041  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.7249  acc: 0.5781  time: 1.6420  data: 0.0044  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6947  acc: 0.5781  time: 1.6443  data: 0.0038  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6588  acc: 0.6250  time: 1.6339  data: 0.0045  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6594  acc: 0.6094  time: 1.6272  data: 0.0040  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5240  acc: 0.7500  time: 1.5681  data: 0.0039  max mem: 28728
Evaluation Total time: 0:02:12 (1.6135 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2262248992919922 uauc: 0.6508074520091462
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009291648864746094 u-nDCG: 0.8530336875828138
rank_0 auc: 0.6650810523794682
Train: data epoch: [143]  [ 0/50]  eta: 0:00:27  lr: 0.000013  loss: 0.8022  time: 0.5490  data: 0.0000  max mem: 28728
Train: data epoch: [143]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.7008  time: 0.5510  data: 0.0000  max mem: 28728
Train: data epoch: [143] Total time: 0:00:27 (0.5480 s / it)
Evaluation  [ 0/82]  eta: 0:01:17  loss: 0.6502  acc: 0.5781  time: 0.9461  data: 0.0138  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.6932  acc: 0.5625  time: 1.5519  data: 0.0062  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6797  acc: 0.6094  time: 1.6642  data: 0.0060  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.6657  acc: 0.5938  time: 1.7066  data: 0.0054  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6448  acc: 0.6562  time: 1.6400  data: 0.0049  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6573  acc: 0.6094  time: 1.6129  data: 0.0063  max mem: 28728
2025-11-11 16:48:33,753 [INFO] Averaged stats: loss: 0.670686  acc: 0.624238 ***auc: 0.6678110846198632 ***uauc: 0.6466286520098962 ***u-nDCG: 0.852396253905458
2025-11-11 16:48:33,798 [INFO] Saving checkpoint at epoch 149 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 16:48:34,488 [INFO] Start training
2025-11-11 16:48:34,511 [INFO] Start training epoch 150, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:49:02,373 [INFO] Averaged stats: lr: 0.000014  loss: 0.632406
2025-11-11 16:49:02,374 [INFO] Evaluating on valid.
2025-11-11 16:51:17,303 [INFO] Averaged stats: loss: 0.656178  acc: 0.565168 ***auc: 0.6681091668412593 ***uauc: 0.6460340077159714 ***u-nDCG: 0.8528920611816843
2025-11-11 16:51:17,316 [INFO] Saving checkpoint at epoch 150 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 16:51:18,069 [INFO] Start training
2025-11-11 16:51:18,076 [INFO] Start training epoch 151, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:51:45,821 [INFO] Averaged stats: lr: 0.000014  loss: 0.638098
2025-11-11 16:51:45,823 [INFO] Evaluating on valid.
2025-11-11 16:53:59,948 [INFO] Averaged stats: loss: 0.646149  acc: 0.586128 ***auc: 0.6673706059599518 ***uauc: 0.6412112968731344 ***u-nDCG: 0.8522282142131995
2025-11-11 16:53:59,964 [INFO] Start training
2025-11-11 16:53:59,989 [INFO] Start training epoch 152, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:54:27,726 [INFO] Averaged stats: lr: 0.000014  loss: 0.605178
2025-11-11 16:54:27,727 [INFO] Evaluating on valid.
2025-11-11 16:56:45,936 [INFO] Averaged stats: loss: 0.648967  acc: 0.604611 ***auc: 0.6673996346395447 ***uauc: 0.6380740381353045 ***u-nDCG: 0.8504243359869811
2025-11-11 16:56:45,951 [INFO] Start training
2025-11-11 16:56:45,970 [INFO] Start training epoch 153, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:57:13,523 [INFO] Averaged stats: lr: 0.000014  loss: 0.619079
2025-11-11 16:57:13,525 [INFO] Evaluating on valid.
2025-11-11 16:59:25,633 [INFO] Averaged stats: loss: 0.652398  acc: 0.591082 ***auc: 0.6637613982112691 ***uauc: 0.6396609874339717 ***u-nDCG: 0.848919320532216
2025-11-11 16:59:25,650 [INFO] Start training
2025-11-11 16:59:25,665 [INFO] Start training epoch 154, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 16:59:53,362 [INFO] Averaged stats: lr: 0.000014  loss: 0.629198
2025-11-11 16:59:53,362 [INFO] Evaluating on valid.
2025-11-11 17:02:05,578 [INFO] Averaged stats: loss: 0.667849  acc: 0.556974 ***auc: 0.6640444092767642 ***uauc: 0.6396647381528611 ***u-nDCG: 0.8482854428776687
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5196  acc: 0.6250  time: 1.5579  data: 0.0057  max mem: 28728
Evaluation Total time: 0:02:13 (1.6311 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.22021007537841797 uauc: 0.6532065924073942
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.013903141021728516 u-nDCG: 0.8540810932605892
rank_0 auc: 0.6667885475251454
Train: data epoch: [144]  [ 0/50]  eta: 0:00:27  lr: 0.000014  loss: 0.6057  time: 0.5560  data: 0.0000  max mem: 28728
Train: data epoch: [144]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.6457  time: 0.5585  data: 0.0000  max mem: 28728
Train: data epoch: [144] Total time: 0:00:27 (0.5570 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6472  acc: 0.6406  time: 0.8945  data: 0.0107  max mem: 28728
Evaluation  [16/82]  eta: 0:01:59  loss: 0.7012  acc: 0.6250  time: 1.8125  data: 0.0044  max mem: 28728
Evaluation  [32/82]  eta: 0:01:26  loss: 0.7107  acc: 0.5938  time: 1.7531  data: 0.0051  max mem: 28728
Evaluation  [48/82]  eta: 0:00:58  loss: 0.6890  acc: 0.5625  time: 1.6251  data: 0.0045  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6585  acc: 0.6250  time: 1.6508  data: 0.0043  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6537  acc: 0.5938  time: 1.6210  data: 0.0041  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5265  acc: 0.7500  time: 1.5634  data: 0.0040  max mem: 28728
Evaluation Total time: 0:02:16 (1.6656 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.16295623779296875 uauc: 0.6448217376154797
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009262323379516602 u-nDCG: 0.8522500006694096
rank_0 auc: 0.6656415063494112
Train: data epoch: [145]  [ 0/50]  eta: 0:00:28  lr: 0.000014  loss: 0.5535  time: 0.5720  data: 0.0000  max mem: 28728
Train: data epoch: [145]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.7116  time: 0.5517  data: 0.0000  max mem: 28728
Train: data epoch: [145] Total time: 0:00:27 (0.5558 s / it)
Evaluation  [ 0/82]  eta: 0:01:17  loss: 0.6573  acc: 0.5781  time: 0.9500  data: 0.0152  max mem: 28728
Evaluation  [16/82]  eta: 0:01:43  loss: 0.6896  acc: 0.5938  time: 1.5616  data: 0.0039  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6845  acc: 0.6250  time: 1.6587  data: 0.0043  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6735  acc: 0.5625  time: 1.6411  data: 0.0051  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6493  acc: 0.6562  time: 1.7113  data: 0.0045  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6535  acc: 0.5938  time: 1.6617  data: 0.0057  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5240  acc: 0.7500  time: 1.6037  data: 0.0051  max mem: 28728
Evaluation Total time: 0:02:14 (1.6416 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2240293025970459 uauc: 0.6309513917619851
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009062767028808594 u-nDCG: 0.8476804272170676
rank_0 auc: 0.6666028679147563
Train: data epoch: [146]  [ 0/50]  eta: 0:00:26  lr: 0.000014  loss: 0.5416  time: 0.5288  data: 0.0000  max mem: 28728
Train: data epoch: [146]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.7059  time: 0.5654  data: 0.0000  max mem: 28728
Train: data epoch: [146] Total time: 0:00:27 (0.5552 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 0.6503  acc: 0.5938  time: 0.9204  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.6986  acc: 0.6094  time: 1.5319  data: 0.0052  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6914  acc: 0.6406  time: 1.6559  data: 0.0049  max mem: 28728
Evaluation  [48/82]  eta: 0:00:57  loss: 0.6730  acc: 0.5469  time: 1.8118  data: 0.0046  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6501  acc: 0.6250  time: 1.6482  data: 0.0055  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6544  acc: 0.5938  time: 1.6163  data: 0.0049  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5084  acc: 0.7500  time: 1.5585  data: 0.0047  max mem: 28728
Evaluation Total time: 0:02:15 (1.6534 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.22476601600646973 uauc: 0.6438649855721101
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009322643280029297 u-nDCG: 0.850277355254802
rank_0 auc: 0.6670760131194784
Train: data epoch: [147]  [ 0/50]  eta: 0:00:27  lr: 0.000014  loss: 0.6408  time: 0.5577  data: 0.0000  max mem: 28728
Train: data epoch: [147]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.6160  time: 0.5438  data: 0.0000  max mem: 28728
Train: data epoch: [147] Total time: 0:00:27 (0.5463 s / it)
Evaluation  [ 0/82]  eta: 0:01:16  loss: 0.6470  acc: 0.5781  time: 0.9342  data: 0.0255  max mem: 28728
Evaluation  [16/82]  eta: 0:01:44  loss: 0.6918  acc: 0.5938  time: 1.5900  data: 0.0067  max mem: 28728
Evaluation  [32/82]  eta: 0:01:21  loss: 0.6832  acc: 0.6562  time: 1.6787  data: 0.0065  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.6678  acc: 0.5625  time: 1.6576  data: 0.0056  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6499  acc: 0.6250  time: 1.6615  data: 0.0060  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6565  acc: 0.5938  time: 1.6682  data: 0.0054  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5232  acc: 0.7500  time: 1.6120  data: 0.0045  max mem: 28728
Evaluation Total time: 0:02:15 (1.6478 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.21455860137939453 uauc: 0.6421867111360168
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009238481521606445 u-nDCG: 0.8497179491540322
rank_0 auc: 0.6667829793640981
Train: data epoch: [148]  [ 0/50]  eta: 0:00:26  lr: 0.000014  loss: 0.7445  time: 0.5298  data: 0.0000  max mem: 28728
Train: data epoch: [148]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.6484  time: 0.5501  data: 0.0000  max mem: 28728
Train: data epoch: [148] Total time: 0:00:27 (0.5557 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 0.6564  acc: 0.5938  time: 0.9232  data: 0.0137  max mem: 28728
Evaluation  [16/82]  eta: 0:01:43  loss: 0.7043  acc: 0.6250  time: 1.5667  data: 0.0069  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6975  acc: 0.6250  time: 1.6326  data: 0.0050  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6747  acc: 0.5625  time: 1.6467  data: 0.0045  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6587  acc: 0.6406  time: 1.7087  data: 0.0038  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6606  acc: 0.5625  time: 1.6568  data: 0.0035  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5194  acc: 0.7500  time: 1.5949  data: 0.0033  max mem: 28728
Evaluation Total time: 0:02:14 (1.6362 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.27855849266052246 uauc: 0.6432048111915131
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.011890172958374023 u-nDCG: 0.849818011891145
rank_0 auc: 0.6673458833249017
Train: data epoch: [149]  [ 0/50]  eta: 0:00:25  lr: 0.000014  loss: 0.7354  time: 0.5010  data: 0.0000  max mem: 28728
Train: data epoch: [149]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.5649  time: 0.5632  data: 0.0000  max mem: 28728
Train: data epoch: [149] Total time: 0:00:27 (0.5559 s / it)
Evaluation  [ 0/82]  eta: 0:01:19  loss: 0.6832  acc: 0.5938  time: 0.9669  data: 0.0336  max mem: 28728
2025-11-11 17:02:05,593 [INFO] Start training
2025-11-11 17:02:05,609 [INFO] Start training epoch 155, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:02:33,054 [INFO] Averaged stats: lr: 0.000014  loss: 0.636900
2025-11-11 17:02:33,055 [INFO] Evaluating on valid.
2025-11-11 17:04:45,543 [INFO] Averaged stats: loss: 0.649743  acc: 0.588224 ***auc: 0.663452105425631 ***uauc: 0.6479865311533116 ***u-nDCG: 0.8506722904193662
2025-11-11 17:04:45,558 [INFO] Start training
2025-11-11 17:04:45,572 [INFO] Start training epoch 156, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:05:13,247 [INFO] Averaged stats: lr: 0.000014  loss: 0.625868
2025-11-11 17:05:13,248 [INFO] Evaluating on valid.
2025-11-11 17:07:24,543 [INFO] Averaged stats: loss: 0.650468  acc: 0.580221 ***auc: 0.663064264448153 ***uauc: 0.6451421999728084 ***u-nDCG: 0.8493346772522078
2025-11-11 17:07:24,562 [INFO] Start training
2025-11-11 17:07:24,576 [INFO] Start training epoch 157, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:07:51,955 [INFO] Averaged stats: lr: 0.000014  loss: 0.625790
2025-11-11 17:07:51,961 [INFO] Evaluating on valid.
2025-11-11 17:10:04,104 [INFO] Averaged stats: loss: 0.665784  acc: 0.623095 ***auc: 0.6641853951144806 ***uauc: 0.6496852788288834 ***u-nDCG: 0.8527126214955493
2025-11-11 17:10:04,119 [INFO] Start training
2025-11-11 17:10:04,133 [INFO] Start training epoch 158, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:10:31,674 [INFO] Averaged stats: lr: 0.000014  loss: 0.644498
2025-11-11 17:10:31,676 [INFO] Evaluating on valid.
2025-11-11 17:12:44,238 [INFO] Averaged stats: loss: 0.655293  acc: 0.610709 ***auc: 0.6639423263242311 ***uauc: 0.6444201822170926 ***u-nDCG: 0.8498769269666611
2025-11-11 17:12:44,253 [INFO] Start training
2025-11-11 17:12:44,274 [INFO] Start training epoch 159, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:13:11,655 [INFO] Averaged stats: lr: 0.000014  loss: 0.644567
2025-11-11 17:13:11,656 [INFO] Evaluating on valid.
2025-11-11 17:15:23,466 [INFO] Averaged stats: loss: 0.650337  acc: 0.610709 ***auc: 0.6663026326710885 ***uauc: 0.6597653170929859 ***u-nDCG: 0.8579759454655993
2025-11-11 17:15:23,484 [INFO] Start training
2025-11-11 17:15:23,500 [INFO] Start training epoch 160, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:15:51,146 [INFO] Averaged stats: lr: 0.000014  loss: 0.630646
2025-11-11 17:15:51,148 [INFO] Evaluating on valid.
Evaluation  [16/82]  eta: 0:01:43  loss: 0.7467  acc: 0.5938  time: 1.5635  data: 0.0068  max mem: 28728
Evaluation  [32/82]  eta: 0:01:22  loss: 0.7679  acc: 0.5156  time: 1.7012  data: 0.0048  max mem: 28728
Evaluation  [48/82]  eta: 0:00:57  loss: 0.7291  acc: 0.5938  time: 1.7494  data: 0.0070  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.7010  acc: 0.5938  time: 1.6883  data: 0.0069  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6880  acc: 0.5781  time: 1.6462  data: 0.0060  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5284  acc: 0.6875  time: 1.5879  data: 0.0051  max mem: 28728
Evaluation Total time: 0:02:16 (1.6617 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.22729277610778809 uauc: 0.6466286520098962
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009144306182861328 u-nDCG: 0.852396253905458
rank_0 auc: 0.6678110846198632
Train: data epoch: [150]  [ 0/50]  eta: 0:00:26  lr: 0.000014  loss: 0.6484  time: 0.5332  data: 0.0000  max mem: 28728
Train: data epoch: [150]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.7099  time: 0.5603  data: 0.0000  max mem: 28728
Train: data epoch: [150] Total time: 0:00:27 (0.5572 s / it)
Evaluation  [ 0/82]  eta: 0:01:17  loss: 0.6793  acc: 0.5312  time: 0.9426  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:44  loss: 0.7059  acc: 0.5781  time: 1.5792  data: 0.0065  max mem: 28728
Evaluation  [32/82]  eta: 0:01:22  loss: 0.6696  acc: 0.5938  time: 1.6777  data: 0.0047  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.6654  acc: 0.5938  time: 1.6587  data: 0.0046  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6518  acc: 0.6406  time: 1.6667  data: 0.0080  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6710  acc: 0.5781  time: 1.6516  data: 0.0055  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5278  acc: 0.6875  time: 1.5932  data: 0.0045  max mem: 28728
Evaluation Total time: 0:02:14 (1.6425 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2101891040802002 uauc: 0.6460340077159714
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0075876712799072266 u-nDCG: 0.8528920611816843
rank_0 auc: 0.6681091668412593
Train: data epoch: [151]  [ 0/50]  eta: 0:00:30  lr: 0.000014  loss: 0.6001  time: 0.6171  data: 0.0000  max mem: 28728
Train: data epoch: [151]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.5624  time: 0.5494  data: 0.0000  max mem: 28728
Train: data epoch: [151] Total time: 0:00:27 (0.5549 s / it)
Evaluation  [ 0/82]  eta: 0:01:16  loss: 0.6599  acc: 0.5781  time: 0.9328  data: 0.0123  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7005  acc: 0.5938  time: 1.5527  data: 0.0049  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6821  acc: 0.6562  time: 1.6705  data: 0.0048  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6676  acc: 0.5625  time: 1.6622  data: 0.0049  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6458  acc: 0.6406  time: 1.7023  data: 0.0065  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6606  acc: 0.5938  time: 1.5978  data: 0.0046  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5273  acc: 0.7500  time: 1.5391  data: 0.0044  max mem: 28728
Evaluation Total time: 0:02:13 (1.6320 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2769756317138672 uauc: 0.6412112968731344
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009307384490966797 u-nDCG: 0.8522282142131995
rank_0 auc: 0.6673706059599518
Train: data epoch: [152]  [ 0/50]  eta: 0:00:26  lr: 0.000014  loss: 0.6725  time: 0.5371  data: 0.0000  max mem: 28728
Train: data epoch: [152]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.5251  time: 0.5560  data: 0.0000  max mem: 28728
Train: data epoch: [152] Total time: 0:00:27 (0.5547 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6674  acc: 0.6250  time: 0.8945  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:40  loss: 0.7094  acc: 0.6250  time: 1.5280  data: 0.0050  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.7056  acc: 0.6406  time: 1.6740  data: 0.0064  max mem: 28728
Evaluation  [48/82]  eta: 0:00:59  loss: 0.6817  acc: 0.5469  time: 1.9868  data: 0.0056  max mem: 28728
Evaluation  [64/82]  eta: 0:00:31  loss: 0.6557  acc: 0.6406  time: 1.6295  data: 0.0051  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6648  acc: 0.5781  time: 1.6080  data: 0.0038  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5167  acc: 0.7500  time: 1.5506  data: 0.0037  max mem: 28728
Evaluation Total time: 0:02:17 (1.6823 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.23264622688293457 uauc: 0.6380740381353045
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007569074630737305 u-nDCG: 0.8504243359869811
rank_0 auc: 0.6673996346395447
Train: data epoch: [153]  [ 0/50]  eta: 0:00:27  lr: 0.000014  loss: 0.6260  time: 0.5582  data: 0.0000  max mem: 28728
Train: data epoch: [153]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.6637  time: 0.5604  data: 0.0000  max mem: 28728
Train: data epoch: [153] Total time: 0:00:27 (0.5511 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 0.6732  acc: 0.5938  time: 0.9157  data: 0.0121  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7154  acc: 0.5781  time: 1.5490  data: 0.0056  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6887  acc: 0.6094  time: 1.6351  data: 0.0043  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6640  acc: 0.5781  time: 1.6147  data: 0.0052  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6530  acc: 0.6562  time: 1.6276  data: 0.0048  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6636  acc: 0.5781  time: 1.6167  data: 0.0058  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5316  acc: 0.7500  time: 1.5563  data: 0.0056  max mem: 28728
Evaluation Total time: 0:02:11 (1.6084 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.19479107856750488 uauc: 0.6396609874339717
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009388208389282227 u-nDCG: 0.848919320532216
rank_0 auc: 0.6637613982112691
Train: data epoch: [154]  [ 0/50]  eta: 0:00:25  lr: 0.000014  loss: 0.6239  time: 0.5013  data: 0.0000  max mem: 28728
Train: data epoch: [154]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.5426  time: 0.5457  data: 0.0000  max mem: 28728
Train: data epoch: [154] Total time: 0:00:27 (0.5539 s / it)
Evaluation  [ 0/82]  eta: 0:01:16  loss: 0.6928  acc: 0.5312  time: 0.9273  data: 0.0133  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.7132  acc: 0.5000  time: 1.5423  data: 0.0058  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6613  acc: 0.6094  time: 1.6249  data: 0.0048  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6547  acc: 0.5938  time: 1.6072  data: 0.0044  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6491  acc: 0.6406  time: 1.6863  data: 0.0055  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6831  acc: 0.5625  time: 1.6068  data: 0.0042  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5591  acc: 0.6250  time: 1.5500  data: 0.0041  max mem: 28728
Evaluation Total time: 0:02:11 (1.6095 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.20844554901123047 uauc: 0.6396647381528611
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007626771926879883 u-nDCG: 0.8482854428776687
rank_0 auc: 2025-11-11 17:18:04,947 [INFO] Averaged stats: loss: 0.646284  acc: 0.588034 ***auc: 0.6666755509769599 ***uauc: 0.6529059606702352 ***u-nDCG: 0.8553006016924907
2025-11-11 17:18:04,969 [INFO] Start training
2025-11-11 17:18:04,995 [INFO] Start training epoch 161, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:18:32,773 [INFO] Averaged stats: lr: 0.000014  loss: 0.614310
2025-11-11 17:18:32,776 [INFO] Evaluating on valid.
2025-11-11 17:20:45,620 [INFO] Averaged stats: loss: 0.646320  acc: 0.586700 ***auc: 0.6666910675857448 ***uauc: 0.6394855183550188 ***u-nDCG: 0.8485650980805294
2025-11-11 17:20:45,649 [INFO] Start training
2025-11-11 17:20:45,668 [INFO] Start training epoch 162, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:21:13,175 [INFO] Averaged stats: lr: 0.000014  loss: 0.635686
2025-11-11 17:21:13,178 [INFO] Evaluating on valid.
2025-11-11 17:23:24,933 [INFO] Averaged stats: loss: 0.645435  acc: 0.585366 ***auc: 0.6687792022206123 ***uauc: 0.6438165726976244 ***u-nDCG: 0.8518782105523248
2025-11-11 17:23:24,948 [INFO] Saving checkpoint at epoch 162 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251111101\checkpoint_best.pth.
2025-11-11 17:23:25,737 [INFO] Start training
2025-11-11 17:23:25,758 [INFO] Start training epoch 163, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:23:52,764 [INFO] Averaged stats: lr: 0.000015  loss: 0.624904
2025-11-11 17:23:52,765 [INFO] Evaluating on valid.
2025-11-11 17:26:05,342 [INFO] Averaged stats: loss: 0.646333  acc: 0.599466 ***auc: 0.6675944460340513 ***uauc: 0.6373779488837263 ***u-nDCG: 0.8489139451523157
2025-11-11 17:26:05,362 [INFO] Start training
2025-11-11 17:26:05,378 [INFO] Start training epoch 164, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:26:32,865 [INFO] Averaged stats: lr: 0.000015  loss: 0.619803
2025-11-11 17:26:32,867 [INFO] Evaluating on valid.
2025-11-11 17:28:47,435 [INFO] Averaged stats: loss: 0.646457  acc: 0.600610 ***auc: 0.6683015282449053 ***uauc: 0.6380078277403075 ***u-nDCG: 0.8484573174673238
2025-11-11 17:28:47,460 [INFO] Start training
2025-11-11 17:28:47,483 [INFO] Start training epoch 165, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:29:15,445 [INFO] Averaged stats: lr: 0.000015  loss: 0.618862
2025-11-11 17:29:15,446 [INFO] Evaluating on valid.
2025-11-11 17:31:27,627 [INFO] Averaged stats: loss: 0.645929  acc: 0.593178 ***auc: 0.6687619780424394 ***uauc: 0.6465603406839842 ***u-nDCG: 0.8537979345511296
2025-11-11 17:31:27,649 [INFO] Start training
2025-11-11 17:31:27,665 [INFO] Start training epoch 166, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:31:55,098 [INFO] Averaged stats: lr: 0.000015  loss: 0.635379
2025-11-11 17:31:55,100 [INFO] Evaluating on valid.
0.6640444092767642
Train: data epoch: [155]  [ 0/50]  eta: 0:00:24  lr: 0.000014  loss: 0.6692  time: 0.4956  data: 0.0000  max mem: 28728
Train: data epoch: [155]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.6389  time: 0.5531  data: 0.0000  max mem: 28728
Train: data epoch: [155] Total time: 0:00:27 (0.5489 s / it)
Evaluation  [ 0/82]  eta: 0:01:16  loss: 0.6538  acc: 0.5781  time: 0.9326  data: 0.0164  max mem: 28728
Evaluation  [16/82]  eta: 0:01:40  loss: 0.7153  acc: 0.5469  time: 1.5300  data: 0.0067  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6763  acc: 0.6406  time: 1.6391  data: 0.0063  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6460  acc: 0.5781  time: 1.6502  data: 0.0042  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6446  acc: 0.6875  time: 1.6455  data: 0.0067  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6670  acc: 0.6094  time: 1.6204  data: 0.0062  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5390  acc: 0.7500  time: 1.5616  data: 0.0056  max mem: 28728
Evaluation Total time: 0:02:12 (1.6120 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2667975425720215 uauc: 0.6479865311533116
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.013525247573852539 u-nDCG: 0.8506722904193662
rank_0 auc: 0.663452105425631
Train: data epoch: [156]  [ 0/50]  eta: 0:00:26  lr: 0.000014  loss: 0.6679  time: 0.5343  data: 0.0000  max mem: 28728
Train: data epoch: [156]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.5943  time: 0.5571  data: 0.0000  max mem: 28728
Train: data epoch: [156] Total time: 0:00:27 (0.5535 s / it)
Evaluation  [ 0/82]  eta: 0:01:19  loss: 0.6498  acc: 0.5781  time: 0.9673  data: 0.0380  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7103  acc: 0.5781  time: 1.5469  data: 0.0062  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6768  acc: 0.6094  time: 1.6265  data: 0.0074  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6501  acc: 0.5938  time: 1.6298  data: 0.0060  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6457  acc: 0.6719  time: 1.6273  data: 0.0080  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6583  acc: 0.5781  time: 1.5996  data: 0.0046  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5412  acc: 0.6250  time: 1.5455  data: 0.0044  max mem: 28728
Evaluation Total time: 0:02:11 (1.5990 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.153733491897583 uauc: 0.6451421999728084
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009227275848388672 u-nDCG: 0.8493346772522078
rank_0 auc: 0.663064264448153
Train: data epoch: [157]  [ 0/50]  eta: 0:00:27  lr: 0.000014  loss: 0.5136  time: 0.5401  data: 0.0000  max mem: 28728
Train: data epoch: [157]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.6833  time: 0.5479  data: 0.0000  max mem: 28728
Train: data epoch: [157] Total time: 0:00:27 (0.5476 s / it)
Evaluation  [ 0/82]  eta: 0:01:37  loss: 0.6533  acc: 0.6250  time: 1.1932  data: 0.0153  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.7485  acc: 0.5781  time: 1.5428  data: 0.0058  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.7519  acc: 0.5469  time: 1.6192  data: 0.0049  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.7030  acc: 0.5781  time: 1.6231  data: 0.0059  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6844  acc: 0.6094  time: 1.6332  data: 0.0049  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6748  acc: 0.6406  time: 1.6292  data: 0.0040  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5420  acc: 0.7500  time: 1.5705  data: 0.0036  max mem: 28728
Evaluation Total time: 0:02:11 (1.6082 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.23363447189331055 uauc: 0.6496852788288834
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.00765228271484375 u-nDCG: 0.8527126214955493
rank_0 auc: 0.6641853951144806
Train: data epoch: [158]  [ 0/50]  eta: 0:00:27  lr: 0.000014  loss: 0.7583  time: 0.5580  data: 0.0000  max mem: 28728
Train: data epoch: [158]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.6423  time: 0.5496  data: 0.0000  max mem: 28728
Train: data epoch: [158] Total time: 0:00:27 (0.5508 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6470  acc: 0.6562  time: 0.8786  data: 0.0067  max mem: 28728
Evaluation  [16/82]  eta: 0:01:40  loss: 0.7236  acc: 0.5938  time: 1.5299  data: 0.0065  max mem: 28728
Evaluation  [32/82]  eta: 0:01:18  loss: 0.7281  acc: 0.5625  time: 1.6172  data: 0.0053  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6908  acc: 0.5781  time: 1.6250  data: 0.0053  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6694  acc: 0.5781  time: 1.6920  data: 0.0061  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6617  acc: 0.5938  time: 1.6313  data: 0.0059  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5460  acc: 0.7500  time: 1.5695  data: 0.0053  max mem: 28728
Evaluation Total time: 0:02:12 (1.6139 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.20064377784729004 uauc: 0.6444201822170926
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009360074996948242 u-nDCG: 0.8498769269666611
rank_0 auc: 0.6639423263242311
Train: data epoch: [159]  [ 0/50]  eta: 0:00:30  lr: 0.000014  loss: 0.5097  time: 0.6107  data: 0.0000  max mem: 28728
Train: data epoch: [159]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.7966  time: 0.5437  data: 0.0000  max mem: 28728
Train: data epoch: [159] Total time: 0:00:27 (0.5475 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6432  acc: 0.5938  time: 0.8746  data: 0.0123  max mem: 28728
Evaluation  [16/82]  eta: 0:01:40  loss: 0.7139  acc: 0.5938  time: 1.5198  data: 0.0043  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.7086  acc: 0.6406  time: 1.6309  data: 0.0049  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6810  acc: 0.5938  time: 1.6765  data: 0.0047  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6627  acc: 0.6562  time: 1.6355  data: 0.0054  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6582  acc: 0.5625  time: 1.5981  data: 0.0053  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5479  acc: 0.7500  time: 1.5415  data: 0.0049  max mem: 28728
Evaluation Total time: 0:02:11 (1.6044 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.21180987358093262 uauc: 0.6597653170929859
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010783195495605469 u-nDCG: 0.8579759454655993
rank_0 auc: 0.6663026326710885
Train: data epoch: [160]  [ 0/50]  eta: 0:00:27  lr: 0.000014  loss: 0.5237  time: 0.5412  data: 0.0000  max mem: 28728
Train: data epoch: [160]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.6451  time: 0.5519  data: 0.0000  max mem: 28728
Train: data epoch: [160] Total time: 0:00:27 (0.5529 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 0.6507  acc: 0.6250  time: 0.9174  data: 0.0138  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7034  acc: 0.5625  time: 1.5515  data: 0.0073  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6837  acc: 0.5938  time: 1.6342  data: 0.0057  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6612  acc: 0.6094  time: 1.6478  data: 0.0057  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6481  acc: 0.6562  time: 1.6827  data: 0.0048  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6513  acc: 0.5469  time: 1.6520  data: 0.0034  max mem: 28728
2025-11-11 17:34:08,081 [INFO] Averaged stats: loss: 0.646000  acc: 0.601944 ***auc: 0.6686813510704752 ***uauc: 0.6458285553257838 ***u-nDCG: 0.8542620187863424
2025-11-11 17:34:08,099 [INFO] Start training
2025-11-11 17:34:08,113 [INFO] Start training epoch 167, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:34:35,786 [INFO] Averaged stats: lr: 0.000015  loss: 0.625292
2025-11-11 17:34:35,788 [INFO] Evaluating on valid.
2025-11-11 17:36:48,681 [INFO] Averaged stats: loss: 0.648992  acc: 0.577172 ***auc: 0.6682671541307068 ***uauc: 0.6432811751945301 ***u-nDCG: 0.8540968861403341
2025-11-11 17:36:48,702 [INFO] Start training
2025-11-11 17:36:48,718 [INFO] Start training epoch 168, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:37:16,278 [INFO] Averaged stats: lr: 0.000015  loss: 0.635411
2025-11-11 17:37:16,280 [INFO] Evaluating on valid.
2025-11-11 17:39:28,716 [INFO] Averaged stats: loss: 0.648155  acc: 0.600419 ***auc: 0.6654201905083197 ***uauc: 0.6479814486894105 ***u-nDCG: 0.8546370139823564
2025-11-11 17:39:28,733 [INFO] Start training
2025-11-11 17:39:28,749 [INFO] Start training epoch 169, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:39:58,644 [INFO] Averaged stats: lr: 0.000015  loss: 0.614713
2025-11-11 17:39:58,646 [INFO] Evaluating on valid.
2025-11-11 17:42:09,357 [INFO] Averaged stats: loss: 0.656329  acc: 0.615282 ***auc: 0.6655222734608527 ***uauc: 0.637659054315001 ***u-nDCG: 0.8510206312337767
2025-11-11 17:42:09,373 [INFO] Start training
2025-11-11 17:42:09,394 [INFO] Start training epoch 170, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:42:36,621 [INFO] Averaged stats: lr: 0.000015  loss: 0.626321
2025-11-11 17:42:36,623 [INFO] Evaluating on valid.
2025-11-11 17:44:48,948 [INFO] Averaged stats: loss: 0.646879  acc: 0.594893 ***auc: 0.6669234455067835 ***uauc: 0.6379039090584425 ***u-nDCG: 0.8491010875513578
2025-11-11 17:44:48,963 [INFO] Start training
2025-11-11 17:44:48,978 [INFO] Start training epoch 171, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:45:16,026 [INFO] Averaged stats: lr: 0.000015  loss: 0.619480
2025-11-11 17:45:16,028 [INFO] Evaluating on valid.
2025-11-11 17:47:26,900 [INFO] Averaged stats: loss: 0.651704  acc: 0.612043 ***auc: 0.6674544253442497 ***uauc: 0.6447466668866304 ***u-nDCG: 0.8535519097899239
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5374  acc: 0.6875  time: 1.5939  data: 0.0032  max mem: 28728
Evaluation Total time: 0:02:13 (1.6290 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.19254541397094727 uauc: 0.6529059606702352
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010724782943725586 u-nDCG: 0.8553006016924907
rank_0 auc: 0.6666755509769599
Train: data epoch: [161]  [ 0/50]  eta: 0:00:27  lr: 0.000014  loss: 0.5941  time: 0.5590  data: 0.0000  max mem: 28728
Train: data epoch: [161]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.6791  time: 0.5510  data: 0.0000  max mem: 28728
Train: data epoch: [161] Total time: 0:00:27 (0.5556 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6508  acc: 0.5938  time: 0.9036  data: 0.0041  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.7072  acc: 0.5625  time: 1.5449  data: 0.0051  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6777  acc: 0.6406  time: 1.6494  data: 0.0042  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6577  acc: 0.5938  time: 1.6382  data: 0.0046  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6443  acc: 0.6719  time: 1.6740  data: 0.0065  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6525  acc: 0.5781  time: 1.6225  data: 0.0035  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5313  acc: 0.6875  time: 1.5674  data: 0.0034  max mem: 28728
Evaluation Total time: 0:02:12 (1.6178 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.15670037269592285 uauc: 0.6394855183550188
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010755538940429688 u-nDCG: 0.8485650980805294
rank_0 auc: 0.6666910675857448
Train: data epoch: [162]  [ 0/50]  eta: 0:00:25  lr: 0.000014  loss: 0.7559  time: 0.5127  data: 0.0000  max mem: 28728
Train: data epoch: [162]  [49/50]  eta: 0:00:00  lr: 0.000014  loss: 0.5842  time: 0.5522  data: 0.0000  max mem: 28728
Train: data epoch: [162] Total time: 0:00:27 (0.5501 s / it)
Evaluation  [ 0/82]  eta: 0:01:16  loss: 0.6542  acc: 0.5938  time: 0.9275  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.7009  acc: 0.5469  time: 1.5355  data: 0.0063  max mem: 28728
Evaluation  [32/82]  eta: 0:01:18  loss: 0.6774  acc: 0.5938  time: 1.6151  data: 0.0038  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6621  acc: 0.6094  time: 1.6577  data: 0.0041  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6432  acc: 0.6719  time: 1.6164  data: 0.0038  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6547  acc: 0.5625  time: 1.6092  data: 0.0045  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5387  acc: 0.6250  time: 1.5547  data: 0.0044  max mem: 28728
Evaluation Total time: 0:02:11 (1.6039 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.20575976371765137 uauc: 0.6438165726976244
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.013831853866577148 u-nDCG: 0.8518782105523248
rank_0 auc: 0.6687792022206123
Train: data epoch: [163]  [ 0/50]  eta: 0:00:24  lr: 0.000014  loss: 0.5836  time: 0.4989  data: 0.0000  max mem: 28728
Train: data epoch: [163]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.6530  time: 0.5435  data: 0.0000  max mem: 28728
Train: data epoch: [163] Total time: 0:00:27 (0.5401 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6489  acc: 0.6250  time: 0.8796  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7067  acc: 0.5938  time: 1.5459  data: 0.0038  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6888  acc: 0.6250  time: 1.6184  data: 0.0059  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6736  acc: 0.5781  time: 1.6345  data: 0.0070  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6414  acc: 0.6875  time: 1.6633  data: 0.0056  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6505  acc: 0.5781  time: 1.6357  data: 0.0055  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5351  acc: 0.7500  time: 1.5796  data: 0.0055  max mem: 28728
Evaluation Total time: 0:02:12 (1.6136 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.22236037254333496 uauc: 0.6373779488837263
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009247303009033203 u-nDCG: 0.8489139451523157
rank_0 auc: 0.6675944460340513
Train: data epoch: [164]  [ 0/50]  eta: 0:00:26  lr: 0.000015  loss: 0.9220  time: 0.5274  data: 0.0000  max mem: 28728
Train: data epoch: [164]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.6488  time: 0.5617  data: 0.0000  max mem: 28728
Train: data epoch: [164] Total time: 0:00:27 (0.5498 s / it)
Evaluation  [ 0/82]  eta: 0:01:35  loss: 0.6592  acc: 0.5938  time: 1.1686  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:44  loss: 0.7064  acc: 0.6094  time: 1.5793  data: 0.0058  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6914  acc: 0.6406  time: 1.6529  data: 0.0043  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6796  acc: 0.5781  time: 1.6602  data: 0.0060  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6414  acc: 0.6875  time: 1.6658  data: 0.0062  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6532  acc: 0.5938  time: 1.6757  data: 0.0050  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5344  acc: 0.7500  time: 1.6183  data: 0.0048  max mem: 28728
Evaluation Total time: 0:02:14 (1.6383 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.21055221557617188 uauc: 0.6380078277403075
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.00762629508972168 u-nDCG: 0.8484573174673238
rank_0 auc: 0.6683015282449053
Train: data epoch: [165]  [ 0/50]  eta: 0:00:25  lr: 0.000015  loss: 0.6292  time: 0.5025  data: 0.0000  max mem: 28728
Train: data epoch: [165]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.5968  time: 0.5558  data: 0.0000  max mem: 28728
Train: data epoch: [165] Total time: 0:00:27 (0.5592 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6657  acc: 0.5938  time: 0.8840  data: 0.0076  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.7024  acc: 0.5625  time: 1.5320  data: 0.0054  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6858  acc: 0.6094  time: 1.6380  data: 0.0062  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6739  acc: 0.6094  time: 1.6361  data: 0.0054  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6457  acc: 0.6875  time: 1.6731  data: 0.0044  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6572  acc: 0.5625  time: 1.5931  data: 0.0054  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5486  acc: 0.6250  time: 1.5356  data: 0.0053  max mem: 28728
Evaluation Total time: 0:02:11 (1.6091 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.21352124214172363 uauc: 0.6465603406839842
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010151386260986328 u-nDCG: 0.8537979345511296
rank_0 auc: 0.6687619780424394
Train: data epoch: [166]  [ 0/50]  eta: 0:00:28  lr: 0.000015  loss: 0.6435  time: 0.5634  data: 0.0000  max mem: 28728
Train: data epoch: [166]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.5741  time: 0.5469  data: 0.0000  max mem: 28728
Train: data epoch: [166] Total time: 0:00:27 (0.5487 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 0.6530  acc: 0.6094  time: 0.9224  data: 0.0138  max mem: 28728
2025-11-11 17:47:26,918 [INFO] Start training
2025-11-11 17:47:26,935 [INFO] Start training epoch 172, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:47:54,255 [INFO] Averaged stats: lr: 0.000015  loss: 0.632651
2025-11-11 17:47:54,257 [INFO] Evaluating on valid.
2025-11-11 17:50:12,242 [INFO] Averaged stats: loss: 0.659773  acc: 0.622523 ***auc: 0.6670810615854944 ***uauc: 0.6440982839859082 ***u-nDCG: 0.8537519578708843
2025-11-11 17:50:12,267 [INFO] Start training
2025-11-11 17:50:12,285 [INFO] Start training epoch 173, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:50:39,809 [INFO] Averaged stats: lr: 0.000015  loss: 0.628468
2025-11-11 17:50:39,810 [INFO] Evaluating on valid.
2025-11-11 17:52:58,420 [INFO] Averaged stats: loss: 0.647114  acc: 0.607660 ***auc: 0.6684363519843961 ***uauc: 0.6414402921627947 ***u-nDCG: 0.8510408133190965
2025-11-11 17:52:58,440 [INFO] Start training
2025-11-11 17:52:58,456 [INFO] Start training epoch 174, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:53:25,654 [INFO] Averaged stats: lr: 0.000015  loss: 0.639074
2025-11-11 17:53:25,656 [INFO] Evaluating on valid.
2025-11-11 17:55:37,762 [INFO] Averaged stats: loss: 0.645274  acc: 0.588796 ***auc: 0.6680174035472007 ***uauc: 0.6396773811906639 ***u-nDCG: 0.8504355731582329
2025-11-11 17:55:37,777 [INFO] Start training
2025-11-11 17:55:37,794 [INFO] Start training epoch 175, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:56:04,811 [INFO] Averaged stats: lr: 0.000015  loss: 0.628882
2025-11-11 17:56:04,814 [INFO] Evaluating on valid.
2025-11-11 17:58:17,328 [INFO] Averaged stats: loss: 0.646582  acc: 0.587652 ***auc: 0.6671443901371387 ***uauc: 0.6423382363793683 ***u-nDCG: 0.8493415470187153
2025-11-11 17:58:17,347 [INFO] Start training
2025-11-11 17:58:17,370 [INFO] Start training epoch 176, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 17:58:45,199 [INFO] Averaged stats: lr: 0.000015  loss: 0.610592
2025-11-11 17:58:45,200 [INFO] Evaluating on valid.
2025-11-11 18:00:58,479 [INFO] Averaged stats: loss: 0.647454  acc: 0.598323 ***auc: 0.6674753616297874 ***uauc: 0.6464876503763816 ***u-nDCG: 0.8545799997109564
2025-11-11 18:00:58,495 [INFO] Start training
2025-11-11 18:00:58,512 [INFO] Start training epoch 177, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 18:01:25,779 [INFO] Averaged stats: lr: 0.000015  loss: 0.614067
2025-11-11 18:01:25,780 [INFO] Evaluating on valid.
Evaluation  [16/82]  eta: 0:01:43  loss: 0.6991  acc: 0.6094  time: 1.5613  data: 0.0060  max mem: 28728
Evaluation  [32/82]  eta: 0:01:21  loss: 0.7002  acc: 0.6406  time: 1.6629  data: 0.0065  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6800  acc: 0.6250  time: 1.6534  data: 0.0060  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6455  acc: 0.6719  time: 1.6265  data: 0.0046  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6623  acc: 0.5781  time: 1.6136  data: 0.0047  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5429  acc: 0.7500  time: 1.5604  data: 0.0046  max mem: 28728
Evaluation Total time: 0:02:12 (1.6185 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.22934961318969727 uauc: 0.6458285553257838
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010311365127563477 u-nDCG: 0.8542620187863424
rank_0 auc: 0.6686813510704752
Train: data epoch: [167]  [ 0/50]  eta: 0:00:25  lr: 0.000015  loss: 0.8092  time: 0.5172  data: 0.0000  max mem: 28728
Train: data epoch: [167]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.6031  time: 0.5534  data: 0.0000  max mem: 28728
Train: data epoch: [167] Total time: 0:00:27 (0.5535 s / it)
Evaluation  [ 0/82]  eta: 0:01:14  loss: 0.6596  acc: 0.5625  time: 0.9116  data: 0.0124  max mem: 28728
Evaluation  [16/82]  eta: 0:01:46  loss: 0.6929  acc: 0.5781  time: 1.6205  data: 0.0059  max mem: 28728
Evaluation  [32/82]  eta: 0:01:21  loss: 0.6768  acc: 0.6094  time: 1.6360  data: 0.0052  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6674  acc: 0.6094  time: 1.6150  data: 0.0055  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6399  acc: 0.6406  time: 1.6236  data: 0.0049  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6610  acc: 0.5938  time: 1.6253  data: 0.0051  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5412  acc: 0.6250  time: 1.5657  data: 0.0050  max mem: 28728
Evaluation Total time: 0:02:12 (1.6174 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2246084213256836 uauc: 0.6432811751945301
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009180545806884766 u-nDCG: 0.8540968861403341
rank_0 auc: 0.6682671541307068
Train: data epoch: [168]  [ 0/50]  eta: 0:00:27  lr: 0.000015  loss: 0.5662  time: 0.5543  data: 0.0000  max mem: 28728
Train: data epoch: [168]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.5428  time: 0.5465  data: 0.0000  max mem: 28728
Train: data epoch: [168] Total time: 0:00:27 (0.5512 s / it)
Evaluation  [ 0/82]  eta: 0:01:16  loss: 0.6526  acc: 0.5938  time: 0.9336  data: 0.0256  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.6983  acc: 0.6250  time: 1.5409  data: 0.0075  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.7030  acc: 0.6250  time: 1.6481  data: 0.0046  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6813  acc: 0.6094  time: 1.6427  data: 0.0050  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6473  acc: 0.6406  time: 1.6711  data: 0.0054  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6578  acc: 0.5781  time: 1.5884  data: 0.0048  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5272  acc: 0.7500  time: 1.5309  data: 0.0047  max mem: 28728
Evaluation Total time: 0:02:12 (1.6118 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.24130535125732422 uauc: 0.6479814486894105
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007771015167236328 u-nDCG: 0.8546370139823564
rank_0 auc: 0.6654201905083197
Train: data epoch: [169]  [ 0/50]  eta: 0:00:25  lr: 0.000015  loss: 0.8291  time: 0.5186  data: 0.0000  max mem: 28728
Train: data epoch: [169]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.6099  time: 0.5536  data: 0.0000  max mem: 28728
Train: data epoch: [169] Total time: 0:00:29 (0.5979 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6564  acc: 0.6406  time: 0.8805  data: 0.0201  max mem: 28728
Evaluation  [16/82]  eta: 0:01:38  loss: 0.7195  acc: 0.6250  time: 1.4935  data: 0.0054  max mem: 28728
Evaluation  [32/82]  eta: 0:01:17  loss: 0.7358  acc: 0.5781  time: 1.6160  data: 0.0040  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.7022  acc: 0.5312  time: 1.6683  data: 0.0050  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6655  acc: 0.6406  time: 1.6074  data: 0.0044  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6644  acc: 0.5781  time: 1.5946  data: 0.0039  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5256  acc: 0.6875  time: 1.5399  data: 0.0037  max mem: 28728
Evaluation Total time: 0:02:10 (1.5907 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.23717379570007324 uauc: 0.637659054315001
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.014307498931884766 u-nDCG: 0.8510206312337767
rank_0 auc: 0.6655222734608527
Train: data epoch: [170]  [ 0/50]  eta: 0:00:26  lr: 0.000015  loss: 0.5898  time: 0.5234  data: 0.0000  max mem: 28728
Train: data epoch: [170]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.5345  time: 0.5487  data: 0.0000  max mem: 28728
Train: data epoch: [170] Total time: 0:00:27 (0.5445 s / it)
Evaluation  [ 0/82]  eta: 0:01:11  loss: 0.6612  acc: 0.6250  time: 0.8707  data: 0.0138  max mem: 28728
Evaluation  [16/82]  eta: 0:01:43  loss: 0.7004  acc: 0.6094  time: 1.5666  data: 0.0049  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6879  acc: 0.6250  time: 1.6369  data: 0.0044  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6675  acc: 0.5781  time: 1.6393  data: 0.0041  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6368  acc: 0.6875  time: 1.6315  data: 0.0042  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6560  acc: 0.5781  time: 1.6048  data: 0.0046  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5348  acc: 0.7500  time: 1.5456  data: 0.0045  max mem: 28728
Evaluation Total time: 0:02:12 (1.6106 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.2245621681213379 uauc: 0.6379039090584425
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007603883743286133 u-nDCG: 0.8491010875513578
rank_0 auc: 0.6669234455067835
Train: data epoch: [171]  [ 0/50]  eta: 0:00:29  lr: 0.000015  loss: 0.7660  time: 0.5862  data: 0.0000  max mem: 28728
Train: data epoch: [171]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.5967  time: 0.5416  data: 0.0000  max mem: 28728
Train: data epoch: [171] Total time: 0:00:27 (0.5410 s / it)
Evaluation  [ 0/82]  eta: 0:01:29  loss: 0.6684  acc: 0.5625  time: 1.0872  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.7190  acc: 0.6094  time: 1.5364  data: 0.0041  max mem: 28728
Evaluation  [32/82]  eta: 0:01:18  loss: 0.7207  acc: 0.6250  time: 1.6073  data: 0.0043  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6836  acc: 0.6094  time: 1.6096  data: 0.0044  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6537  acc: 0.6719  time: 1.6077  data: 0.0055  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6583  acc: 0.5625  time: 1.6223  data: 0.0049  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5336  acc: 0.6875  time: 1.5674  data: 0.0047  max mem: 28728
Evaluation Total time: 0:02:10 (1.5938 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.16100692749023438 uauc: 0.6447466668866304
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007684469223022461 u-nDCG: 0.8535519097899239
rank_0 auc: 2025-11-11 18:03:38,208 [INFO] Averaged stats: loss: 0.653134  acc: 0.580221 ***auc: 0.6650317555936631 ***uauc: 0.6433542020411745 ***u-nDCG: 0.8515525412332636
2025-11-11 18:03:38,226 [INFO] Start training
2025-11-11 18:03:38,241 [INFO] Start training epoch 178, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 18:04:05,760 [INFO] Averaged stats: lr: 0.000015  loss: 0.630159
2025-11-11 18:04:05,761 [INFO] Evaluating on valid.
2025-11-11 18:06:17,474 [INFO] Averaged stats: loss: 0.652889  acc: 0.612805 ***auc: 0.6642179131749966 ***uauc: 0.6510991876795762 ***u-nDCG: 0.8533357378898413
2025-11-11 18:06:17,490 [INFO] Start training
2025-11-11 18:06:17,521 [INFO] Start training epoch 179, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 18:06:45,180 [INFO] Averaged stats: lr: 0.000015  loss: 0.620967
2025-11-11 18:06:45,183 [INFO] Evaluating on valid.
2025-11-11 18:08:58,033 [INFO] Averaged stats: loss: 0.649249  acc: 0.604802 ***auc: 0.6647866080232895 ***uauc: 0.6398728440416991 ***u-nDCG: 0.8496531103151221
2025-11-11 18:08:58,050 [INFO] Start training
2025-11-11 18:08:58,066 [INFO] Start training epoch 180, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 18:09:25,172 [INFO] Averaged stats: lr: 0.000015  loss: 0.615815
2025-11-11 18:09:25,174 [INFO] Evaluating on valid.
2025-11-11 18:11:35,161 [INFO] Averaged stats: loss: 0.646831  acc: 0.594512 ***auc: 0.6658187223550085 ***uauc: 0.642088286180443 ***u-nDCG: 0.8515673366341626
2025-11-11 18:11:35,181 [INFO] Start training
2025-11-11 18:11:35,196 [INFO] Start training epoch 181, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 18:12:02,346 [INFO] Averaged stats: lr: 0.000016  loss: 0.629113
2025-11-11 18:12:02,347 [INFO] Evaluating on valid.
2025-11-11 18:14:25,675 [INFO] Averaged stats: loss: 0.677368  acc: 0.532965 ***auc: 0.6652436426820482 ***uauc: 0.6354451310388153 ***u-nDCG: 0.8497794586668477
2025-11-11 18:14:25,681 [INFO] Start training
2025-11-11 18:14:25,688 [INFO] Start training epoch 182, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-11 18:14:50,971 [INFO] Averaged stats: lr: 0.000016  loss: 0.641328
2025-11-11 18:14:50,973 [INFO] Evaluating on valid.
2025-11-11 18:16:59,308 [INFO] Averaged stats: loss: 0.649433  acc: 0.571075 ***auc: 0.6672046747607436 ***uauc: 0.6394637076951905 ***u-nDCG: 0.853039437580422
2025-11-11 18:16:59,312 [INFO] Early stop. The results has not changed up to 20 epochs.
2025-11-11 18:16:59,312 [INFO] Training time 7:57:53
0.6674544253442497
Train: data epoch: [172]  [ 0/50]  eta: 0:00:26  lr: 0.000015  loss: 0.6501  time: 0.5256  data: 0.0000  max mem: 28728
Train: data epoch: [172]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.7178  time: 0.5427  data: 0.0000  max mem: 28728
Train: data epoch: [172] Total time: 0:00:27 (0.5464 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6726  acc: 0.6406  time: 0.8990  data: 0.0056  max mem: 28728
Evaluation  [16/82]  eta: 0:01:39  loss: 0.7270  acc: 0.6094  time: 1.5135  data: 0.0046  max mem: 28728
Evaluation  [32/82]  eta: 0:01:18  loss: 0.7468  acc: 0.5625  time: 1.6168  data: 0.0042  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.7038  acc: 0.5938  time: 1.6588  data: 0.0042  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6752  acc: 0.6250  time: 1.9594  data: 0.0057  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6716  acc: 0.6250  time: 1.6669  data: 0.0049  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5531  acc: 0.6875  time: 1.5855  data: 0.0046  max mem: 28728
Evaluation Total time: 0:02:17 (1.6792 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.24485015869140625 uauc: 0.6440982839859082
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010777950286865234 u-nDCG: 0.8537519578708843
rank_0 auc: 0.6670810615854944
Train: data epoch: [173]  [ 0/50]  eta: 0:00:27  lr: 0.000015  loss: 0.6074  time: 0.5570  data: 0.0000  max mem: 28728
Train: data epoch: [173]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.5202  time: 0.5419  data: 0.0000  max mem: 28728
Train: data epoch: [173] Total time: 0:00:27 (0.5505 s / it)
Evaluation  [ 0/82]  eta: 0:01:17  loss: 0.6653  acc: 0.5938  time: 0.9396  data: 0.0259  max mem: 28728
Evaluation  [16/82]  eta: 0:01:39  loss: 0.7069  acc: 0.6094  time: 1.5126  data: 0.0054  max mem: 28728
Evaluation  [32/82]  eta: 0:01:24  loss: 0.7008  acc: 0.6250  time: 1.8218  data: 0.0052  max mem: 28728
Evaluation  [48/82]  eta: 0:00:59  loss: 0.6749  acc: 0.5938  time: 1.9698  data: 0.0035  max mem: 28728
Evaluation  [64/82]  eta: 0:00:31  loss: 0.6490  acc: 0.6875  time: 1.6419  data: 0.0055  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6607  acc: 0.5781  time: 1.5929  data: 0.0044  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5434  acc: 0.7500  time: 1.5355  data: 0.0042  max mem: 28728
Evaluation Total time: 0:02:18 (1.6878 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.18300676345825195 uauc: 0.6414402921627947
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009227752685546875 u-nDCG: 0.8510408133190965
rank_0 auc: 0.6684363519843961
Train: data epoch: [174]  [ 0/50]  eta: 0:00:26  lr: 0.000015  loss: 0.7376  time: 0.5332  data: 0.0000  max mem: 28728
Train: data epoch: [174]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.6332  time: 0.5413  data: 0.0000  max mem: 28728
Train: data epoch: [174] Total time: 0:00:27 (0.5440 s / it)
Evaluation  [ 0/82]  eta: 0:01:28  loss: 0.6685  acc: 0.5938  time: 1.0844  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:40  loss: 0.6991  acc: 0.5938  time: 1.5297  data: 0.0053  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6812  acc: 0.5938  time: 1.6299  data: 0.0066  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6625  acc: 0.5938  time: 1.6486  data: 0.0055  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6457  acc: 0.6719  time: 1.6568  data: 0.0076  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6598  acc: 0.5625  time: 1.6160  data: 0.0031  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5490  acc: 0.6250  time: 1.5578  data: 0.0030  max mem: 28728
Evaluation Total time: 0:02:11 (1.6085 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.1847517490386963 uauc: 0.6396773811906639
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007598876953125 u-nDCG: 0.8504355731582329
rank_0 auc: 0.6680174035472007
Train: data epoch: [175]  [ 0/50]  eta: 0:00:26  lr: 0.000015  loss: 0.6179  time: 0.5365  data: 0.0000  max mem: 28728
Train: data epoch: [175]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.4915  time: 0.5416  data: 0.0000  max mem: 28728
Train: data epoch: [175] Total time: 0:00:27 (0.5403 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6718  acc: 0.5781  time: 0.8896  data: 0.0237  max mem: 28728
Evaluation  [16/82]  eta: 0:01:40  loss: 0.7030  acc: 0.5781  time: 1.5294  data: 0.0075  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.6770  acc: 0.5938  time: 1.6332  data: 0.0058  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6589  acc: 0.6250  time: 1.6412  data: 0.0045  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6455  acc: 0.6875  time: 1.6736  data: 0.0040  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6629  acc: 0.5625  time: 1.6228  data: 0.0040  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5436  acc: 0.6875  time: 1.5561  data: 0.0037  max mem: 28728
Evaluation Total time: 0:02:12 (1.6126 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.24659967422485352 uauc: 0.6423382363793683
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.010731935501098633 u-nDCG: 0.8493415470187153
rank_0 auc: 0.6671443901371387
Train: data epoch: [176]  [ 0/50]  eta: 0:00:27  lr: 0.000015  loss: 0.6383  time: 0.5499  data: 0.0000  max mem: 28728
Train: data epoch: [176]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.6319  time: 0.5575  data: 0.0000  max mem: 28728
Train: data epoch: [176] Total time: 0:00:27 (0.5566 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6594  acc: 0.6094  time: 1.0175  data: 0.0167  max mem: 28728
Evaluation  [16/82]  eta: 0:01:42  loss: 0.7015  acc: 0.6094  time: 1.5457  data: 0.0052  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6922  acc: 0.6250  time: 1.6670  data: 0.0057  max mem: 28728
Evaluation  [48/82]  eta: 0:00:56  loss: 0.6760  acc: 0.6094  time: 1.7125  data: 0.0054  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6502  acc: 0.6406  time: 1.6310  data: 0.0063  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6589  acc: 0.5781  time: 1.6045  data: 0.0054  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5196  acc: 0.7500  time: 1.5474  data: 0.0054  max mem: 28728
Evaluation Total time: 0:02:13 (1.6227 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.1871049404144287 uauc: 0.6464876503763816
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009243011474609375 u-nDCG: 0.8545799997109564
rank_0 auc: 0.6674753616297874
Train: data epoch: [177]  [ 0/50]  eta: 0:00:25  lr: 0.000015  loss: 0.6451  time: 0.5088  data: 0.0000  max mem: 28728
Train: data epoch: [177]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.8257  time: 0.5499  data: 0.0000  max mem: 28728
Train: data epoch: [177] Total time: 0:00:27 (0.5453 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.6657  acc: 0.5781  time: 0.8880  data: 0.0145  max mem: 28728
Evaluation  [16/82]  eta: 0:01:45  loss: 0.7008  acc: 0.5312  time: 1.5930  data: 0.0045  max mem: 28728
Evaluation  [32/82]  eta: 0:01:21  loss: 0.6830  acc: 0.5781  time: 1.6559  data: 0.0045  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6707  acc: 0.6250  time: 1.6246  data: 0.0063  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6458  acc: 0.6719  time: 1.6103  data: 0.0068  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6534  acc: 0.5938  time: 1.6157  data: 0.0053  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5256  acc: 0.7500  time: 1.5614  data: 0.0051  max mem: 28728
Evaluation Total time: 0:02:12 (1.6128 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.13724565505981445 uauc: 0.6433542020411745
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009290456771850586 u-nDCG: 0.8515525412332636
rank_0 auc: 0.6650317555936631
Train: data epoch: [178]  [ 0/50]  eta: 0:00:26  lr: 0.000015  loss: 0.6629  time: 0.5366  data: 0.0000  max mem: 28728
Train: data epoch: [178]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.7260  time: 0.5448  data: 0.0000  max mem: 28728
Train: data epoch: [178] Total time: 0:00:27 (0.5504 s / it)
Evaluation  [ 0/82]  eta: 0:01:16  loss: 0.6474  acc: 0.6562  time: 0.9376  data: 0.0153  max mem: 28728
Evaluation  [16/82]  eta: 0:01:40  loss: 0.7170  acc: 0.6094  time: 1.5303  data: 0.0057  max mem: 28728
Evaluation  [32/82]  eta: 0:01:18  loss: 0.7188  acc: 0.6094  time: 1.6138  data: 0.0050  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.6897  acc: 0.5469  time: 1.6294  data: 0.0058  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6625  acc: 0.6719  time: 1.6495  data: 0.0060  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6600  acc: 0.5781  time: 1.6228  data: 0.0054  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5182  acc: 0.6875  time: 1.5598  data: 0.0049  max mem: 28728
Evaluation Total time: 0:02:11 (1.6034 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.19857192039489746 uauc: 0.6510991876795762
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.007172584533691406 u-nDCG: 0.8533357378898413
rank_0 auc: 0.6642179131749966
Train: data epoch: [179]  [ 0/50]  eta: 0:00:25  lr: 0.000015  loss: 0.6814  time: 0.5183  data: 0.0000  max mem: 28728
Train: data epoch: [179]  [49/50]  eta: 0:00:00  lr: 0.000015  loss: 0.6435  time: 0.5548  data: 0.0000  max mem: 28728
Train: data epoch: [179] Total time: 0:00:27 (0.5532 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 0.6475  acc: 0.6406  time: 0.9235  data: 0.0117  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.7061  acc: 0.5938  time: 1.5448  data: 0.0040  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.7058  acc: 0.5938  time: 1.6368  data: 0.0047  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6798  acc: 0.5781  time: 1.6540  data: 0.0044  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6625  acc: 0.6562  time: 1.6465  data: 0.0058  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6549  acc: 0.5938  time: 1.6302  data: 0.0051  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5236  acc: 0.7500  time: 1.5719  data: 0.0050  max mem: 28728
Evaluation Total time: 0:02:12 (1.6173 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.19565987586975098 uauc: 0.6398728440416991
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.009186267852783203 u-nDCG: 0.8496531103151221
rank_0 auc: 0.6647866080232895
Train: data epoch: [180]  [ 0/50]  eta: 0:00:26  lr: 0.000015  loss: 0.5753  time: 0.5204  data: 0.0000  max mem: 28728
Train: data epoch: [180]  [49/50]  eta: 0:00:00  lr: 0.000016  loss: 0.5699  time: 0.5481  data: 0.0000  max mem: 28728
Train: data epoch: [180] Total time: 0:00:27 (0.5421 s / it)
Evaluation  [ 0/82]  eta: 0:01:15  loss: 0.6520  acc: 0.6094  time: 0.9218  data: 0.0077  max mem: 28728
Evaluation  [16/82]  eta: 0:01:44  loss: 0.6903  acc: 0.5938  time: 1.5778  data: 0.0048  max mem: 28728
Evaluation  [32/82]  eta: 0:01:20  loss: 0.6915  acc: 0.6250  time: 1.6418  data: 0.0051  max mem: 28728
Evaluation  [48/82]  eta: 0:00:55  loss: 0.6723  acc: 0.6250  time: 1.6210  data: 0.0039  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.6541  acc: 0.6250  time: 1.5850  data: 0.0035  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6507  acc: 0.5781  time: 1.5188  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5257  acc: 0.7500  time: 1.4657  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:09 (1.5824 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.21183013916015625 uauc: 0.642088286180443
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0076427459716796875 u-nDCG: 0.8515673366341626
rank_0 auc: 0.6658187223550085
Train: data epoch: [181]  [ 0/50]  eta: 0:00:27  lr: 0.000016  loss: 0.6232  time: 0.5579  data: 0.0000  max mem: 28728
Train: data epoch: [181]  [49/50]  eta: 0:00:00  lr: 0.000016  loss: 0.6369  time: 0.5114  data: 0.0000  max mem: 28728
Train: data epoch: [181] Total time: 0:00:27 (0.5430 s / it)
Evaluation  [ 0/82]  eta: 0:01:25  loss: 0.6945  acc: 0.5000  time: 1.0487  data: 0.0060  max mem: 28728
Evaluation  [16/82]  eta: 0:01:46  loss: 0.7071  acc: 0.5469  time: 1.6158  data: 0.0057  max mem: 28728
Evaluation  [32/82]  eta: 0:01:24  loss: 0.6583  acc: 0.6719  time: 1.7630  data: 0.0044  max mem: 28728
Evaluation  [48/82]  eta: 0:00:59  loss: 0.6638  acc: 0.5938  time: 1.7921  data: 0.0073  max mem: 28728
Evaluation  [64/82]  eta: 0:00:30  loss: 0.6587  acc: 0.5938  time: 1.6448  data: 0.0037  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6758  acc: 0.5625  time: 1.9121  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5791  acc: 0.6250  time: 1.8558  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:23 (1.7467 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08250164985656738 uauc: 0.6354451310388153
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0020148754119873047 u-nDCG: 0.8497794586668477
rank_0 auc: 0.6652436426820482
Train: data epoch: [182]  [ 0/50]  eta: 0:00:24  lr: 0.000016  loss: 0.7834  time: 0.4868  data: 0.0000  max mem: 28728
Train: data epoch: [182]  [49/50]  eta: 0:00:00  lr: 0.000016  loss: 0.6754  time: 0.5068  data: 0.0000  max mem: 28728
Train: data epoch: [182] Total time: 0:00:25 (0.5057 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6523  acc: 0.5625  time: 0.8930  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.6961  acc: 0.5469  time: 1.4815  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.6684  acc: 0.6250  time: 1.5703  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6643  acc: 0.6094  time: 1.5706  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6478  acc: 0.6406  time: 1.6564  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6513  acc: 0.5938  time: 1.5643  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5403  acc: 0.6250  time: 1.5072  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:08 (1.5639 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08021092414855957 uauc: 0.6394637076951905
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030701160430908203 u-nDCG: 0.853039437580422
rank_0 auc: 0.6672046747607436
