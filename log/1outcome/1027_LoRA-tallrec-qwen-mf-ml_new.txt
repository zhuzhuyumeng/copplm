W1112 21:23:51.537508 2308 site-packages\torch\distributed\elastic\multiprocessing\redirects.py:29] NOTE: Redirects are currently not supported in Windows or MacOs.
2025-11-12 21:23:51,605 [INFO] Building datasets...
2025-11-12 21:23:51,805 [INFO] Movie OOD datasets, max history length:10
2025-11-12 21:23:51,847 [INFO] Movie OOD datasets, max history length:10
2025-11-12 21:23:52,013 [INFO] Movie OOD datasets, max history length:10
2025-11-12 21:23:52,175 [INFO] 
=====  Running Parameters    =====
2025-11-12 21:23:52,175 [INFO] {
    "amp": true,
    "batch_size_eval": 64,
    "batch_size_train": 16,
    "device": "cuda",
    "dist_url": "env://",
    "distributed": false,
    "evaluate": false,
    "init_lr": 0.0001,
    "iters_per_epoch": 50,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 1000,
    "min_lr": 8e-05,
    "mode": "v2",
    "num_workers": 0,
    "output_dir": "Qwen/Qwen2.5-1.5rec_log/collm",
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "rec_pretrain",
    "test_splits": [
        "test",
        "valid"
    ],
    "train_splits": [
        "train"
    ],
    "valid_splits": [
        "valid"
    ],
    "warmup_lr": 1e-05,
    "warmup_steps": 200,
    "weight_decay": 0.001,
    "world_size": 1
}
2025-11-12 21:23:52,183 [INFO] 
======  Dataset Attributes  ======
2025-11-12 21:23:52,183 [INFO] 
======== amazon_ood =======
2025-11-12 21:23:52,183 [INFO] {
    "build_info": {
        "storage": "D:\\Pycoding\\CoLLM-main\\CoLLM-main\\collm-datasets\\ml-1m\\ml-1m\\"
    },
    "data_type": "default",
    "path": "D:\\Pycoding\\CoLLM-main\\CoLLM-main\\collm-datasets\\ml-1m\\ml-1m\\"
}
2025-11-12 21:23:52,183 [INFO] 
======  Model Attributes  ======
2025-11-12 21:23:52,183 [INFO] {
    "ans_type": "v2",
    "arch": "mini_gpt4rec_v2",
    "end_sym": "###",
    "freeze_lora": false,
    "freeze_proj": true,
    "freeze_rec": true,
    "item_num": -100,
    "llama_model": "Qwen/Qwen2-1.5B",
    "lora_config": {
        "alpha": 16,
        "dropout": 0.05,
        "r": 8,
        "target_modules": [
            "q_proj",
            "v_proj"
        ],
        "use_lora": true
    },
    "max_txt_len": 1024,
    "model_type": "pretrain_vicuna",
    "proj_drop": 0,
    "proj_mid_times": 10,
    "proj_token_num": 1,
    "prompt_path": "prompts/tallrec_movie.txt",
    "prompt_template": "{}",
    "rec_config": {
        "embedding_size": 256,
        "item_num": 3256,
        "pretrained_path": "collm-trained-models/my-collm-trained-models/mf_0912_ml1m_oodv2_best_model_d256lr-0.001wd0.0001.pth",
        "user_num": 839
    },
    "user_num": -100
}
2025-11-12 21:23:52,212 [INFO] freeze rec encoder
`torch_dtype` is deprecated! Use `dtype` instead!
2025-11-12 21:23:52,854 [INFO] !!!! freeze llama_proj...
2025-11-12 21:23:53,912 [INFO] Start training
2025-11-12 21:23:53,919 [INFO] dataset_ratios not specified, datasets will be concatenated (map-style datasets) or chained (webdataset.DataPipeline).
2025-11-12 21:23:53,919 [INFO] Loaded 33891 records for train split from the dataset.
2025-11-12 21:23:53,920 [INFO] Loaded 5200 records for valid split from the dataset.
2025-11-12 21:23:53,920 [INFO] Loaded 7331 records for test split from the dataset.
2025-11-12 21:23:53,925 [INFO] number of trainable parameters: 1089536
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\runners\runner_base.py:153: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.
  self._scaler = torch.cuda.amp.GradScaler()
2025-11-12 21:23:53,938 [INFO] Start training epoch 0, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:24:19,962 [INFO] Averaged stats: lr: 0.000021  loss: 4.842425
2025-11-12 21:24:19,963 [INFO] Evaluating on valid.
2025-11-12 21:26:36,053 [INFO] Averaged stats: loss: 2.354553  acc: 0.530297 ***auc: 0.4869187563727603 ***uauc: 0.5022753719295867 ***u-nDCG: 0.7986931700788974
2025-11-12 21:26:36,059 [INFO] Saving checkpoint at epoch 0 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:26:36,495 [INFO] Start training
2025-11-12 21:26:36,502 [INFO] Start training epoch 1, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:27:01,468 [INFO] Averaged stats: lr: 0.000021  loss: 1.153828
2025-11-12 21:27:01,470 [INFO] Evaluating on valid.

===================================BUG REPORT===================================
Welcome to bitsandbytes. For bug reports, please submit your error trace to: https://github.com/TimDettmers/bitsandbytes/issues
================================================================================
binary_path: D:\Anaconda3\envs\minigpt4\lib\site-packages\bitsandbytes\cuda_setup\libbitsandbytes_cuda116.dll
CUDA SETUP: Loading binary D:\Anaconda3\envs\minigpt4\lib\site-packages\bitsandbytes\cuda_setup\libbitsandbytes_cuda116.dll...
Not using distributed mode
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\train data size: (33891, 7)
Movie OOD datasets, max history length: 10
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\valid_small data size: (5200, 7)
Movie OOD datasets, max history length: 10
data path: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\test data size: (7331, 7)
Movie OOD datasets, max history length: 10
data dir: D:\Pycoding\CoLLM-main\CoLLM-main\collm-datasets\ml-1m\ml-1m\
正在计算全局流行度以进行偏见评估...
已计算 3087 个物品的流行度。总物品数为 3256。
正在将流行度数据注入评估任务...
runing MiniGPT4Rec_v2 ...... 
Loading Rec_model
### rec_encoder: MF
creat MF model, user num: 839 item num: 3256
successfully load the pretrained model......
freeze rec encoder
Loading Rec_model Done
Loading LLama model: Qwen/Qwen2-1.5B
Loading LLAMA Done
Setting Lora
Setting Lora Done
type: <class 'int'> 10
Load 4 training prompts
Prompt List: 
['#Question: A user has given high ratings to the following movies: <ItemTitleList>. Leverage the information to predict whether the user would enjoy the movie titled <TargetItemTitle>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Leverage the information to predict whether the user would enjoy the movie titled <TargetItemTitle>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Leverage the information to predict whether the user would enjoy the movie titled <TargetItemTitle>? Answer with "Yes" or "No". \\n#Answer:', '#Question: A user has given high ratings to the following movies: <ItemTitleList>. Leverage the information to predict whether the user would enjoy the movie titled <TargetItemTitle>? Answer with "Yes" or "No". \\n#Answer:']
answer token ids: pos: 9454 neg ids: 2753
Prompt Pos Example 
#Question: A user has given high ratings to the following movies: <ItemTitleList>. Leverage the information to predict whether the user would enjoy the movie titled <TargetItemTitle>? Answer with "Yes" or "No". \n#Answer: Yes or No
llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.0.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.0.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.1.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.1.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.2.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.2.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.3.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.3.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.4.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.4.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.5.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.5.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.6.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.6.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.7.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.7.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.8.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.8.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.9.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.9.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.10.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.10.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.11.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.11.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.12.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.12.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.13.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.13.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.14.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.14.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.15.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.15.self_attn.v_proj.lora_B.default.weight
2025-11-12 21:29:14,625 [INFO] Averaged stats: loss: 0.761641  acc: 0.520008 ***auc: 0.5041018043959963 ***uauc: 0.4773826930239864 ***u-nDCG: 0.7869735573068956
2025-11-12 21:29:14,630 [INFO] Saving checkpoint at epoch 1 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:29:15,136 [INFO] Start training
2025-11-12 21:29:15,145 [INFO] Start training epoch 2, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:29:40,062 [INFO] Averaged stats: lr: 0.000021  loss: 0.719463
2025-11-12 21:29:40,063 [INFO] Evaluating on valid.
2025-11-12 21:31:47,936 [INFO] Averaged stats: loss: 0.699261  acc: 0.484566 ***auc: 0.513527438932493 ***uauc: 0.49275867776384313 ***u-nDCG: 0.79679935516573
2025-11-12 21:31:47,943 [INFO] Saving checkpoint at epoch 2 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:31:48,445 [INFO] Start training
2025-11-12 21:31:48,452 [INFO] Start training epoch 3, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:32:13,549 [INFO] Averaged stats: lr: 0.000021  loss: 0.697451
2025-11-12 21:32:13,550 [INFO] Evaluating on valid.
2025-11-12 21:34:19,661 [INFO] Averaged stats: loss: 0.706849  acc: 0.469893 ***auc: 0.5193179552109004 ***uauc: 0.49411112450975375 ***u-nDCG: 0.7989875760928004
2025-11-12 21:34:19,667 [INFO] Saving checkpoint at epoch 3 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:34:20,153 [INFO] Start training
2025-11-12 21:34:20,160 [INFO] Start training epoch 4, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:34:45,120 [INFO] Averaged stats: lr: 0.000100  loss: 0.706464
2025-11-12 21:34:45,121 [INFO] Evaluating on valid.
2025-11-12 21:36:51,568 [INFO] Averaged stats: loss: 0.697177  acc: 0.475610 ***auc: 0.5207237302699638 ***uauc: 0.5167545938473529 ***u-nDCG: 0.8087177306054378
2025-11-12 21:36:51,574 [INFO] Saving checkpoint at epoch 4 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:36:52,101 [INFO] Start training
2025-11-12 21:36:52,107 [INFO] Start training epoch 5, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:37:17,356 [INFO] Averaged stats: lr: 0.000100  loss: 0.701522
2025-11-12 21:37:17,357 [INFO] Evaluating on valid.
2025-11-12 21:39:21,988 [INFO] Averaged stats: loss: 0.692651  acc: 0.473514 ***auc: 0.5333842436484729 ***uauc: 0.5209247554518941 ***u-nDCG: 0.808799413773193
2025-11-12 21:39:21,992 [INFO] Saving checkpoint at epoch 5 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:39:22,489 [INFO] Start training
2025-11-12 21:39:22,496 [INFO] Start training epoch 6, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:39:47,573 [INFO] Averaged stats: lr: 0.000100  loss: 0.700431
2025-11-12 21:39:47,574 [INFO] Evaluating on valid.
2025-11-12 21:41:47,464 [INFO] Averaged stats: loss: 0.690428  acc: 0.484566 ***auc: 0.5364709351644812 ***uauc: 0.5119054892156806 ***u-nDCG: 0.8025947563017242
2025-11-12 21:41:47,470 [INFO] Saving checkpoint at epoch 6 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:41:47,935 [INFO] Start training
2025-11-12 21:41:47,941 [INFO] Start training epoch 7, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:42:12,837 [INFO] Averaged stats: lr: 0.000100  loss: 0.702375
2025-11-12 21:42:12,840 [INFO] Evaluating on valid.
llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.16.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.16.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.17.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.17.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.18.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.18.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.19.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.19.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.20.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.20.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.21.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.21.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.22.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.22.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.23.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.23.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.24.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.24.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.25.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.25.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.26.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.26.self_attn.v_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.27.self_attn.q_proj.lora_B.default.weight
llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_A.default.weight
llama_model.base_model.model.model.layers.27.self_attn.v_proj.lora_B.default.weight
prompt example: <s>#Question: A user has given high ratings to the following movies: "Best in Show (2000)", "High Fidelity (2000)", "Bring It On (2000)", "28 Days (2000)", "Perfect Storm, The (2000)", "Return to Me (2000)", "Thomas Crown Affair, The (1999)". Leverage the information to predict whether the user would enjoy the movie titled "My Dog Skip (1999)"? Answer with "Yes" or "No". \n#Answer:
#######prmpt decoded example:  <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <|endoftext|> <s ># Question :  A  user  has  given  high  ratings  to  the  following  movies :  " Dave  ( 1 9 9 3 )",  " Add ams  Family ,  The  ( 1 9 9 1 )",  " Ham let  ( 1 9 9 0 )",  " Cour age  Under  Fire  ( 1 9 9 6 )",  " P ump  Up  the  Volume  ( 1 9 9 0 )",  " B ul worth  ( 1 9 9 8 )",  " M ight y  Aph rod ite  ( 1 9 9 5 )",  " Four  Wed dings  and  a  Funeral  ( 1 9 9 4 )",  " In  the  Name  of  the  Father  ( 1 9 9 3 )",  " S cream  ( 1 9 9 6 )".  Le verage  the  information  to  predict  whether  the  user  would  enjoy  the  movie  titled  " Last  Sup per ,  The  ( 1 9 9 5 )" ?  Answer  with  " Yes "  or  " No ".  \ n # Answer :
Train: data epoch: [0]  [ 0/50]  eta: 0:00:41  lr: 0.000010  loss: 6.5522  time: 0.8354  data: 0.0000  max mem: 17609
Train: data epoch: [0]  [49/50]  eta: 0:00:00  lr: 0.000032  loss: 3.0339  time: 0.5132  data: 0.0001  max mem: 20337
Train: data epoch: [0] Total time: 0:00:26 (0.5205 s / it)
Evaluation  [ 0/82]  eta: 0:01:40  loss: 2.1459  acc: 0.5625  time: 1.2289  data: 0.0046  max mem: 22304
Evaluation  [16/82]  eta: 0:01:45  loss: 2.5474  acc: 0.5000  time: 1.6044  data: 0.0026  max mem: 26592
Evaluation  [32/82]  eta: 0:01:21  loss: 3.1269  acc: 0.3750  time: 1.6639  data: 0.0025  max mem: 27639
Evaluation  [48/82]  eta: 0:00:56  loss: 2.7368  acc: 0.4531  time: 1.6558  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 2.5659  acc: 0.4844  time: 1.6552  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 2.1679  acc: 0.5625  time: 1.7335  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 2.5137  acc: 0.5000  time: 1.6705  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:15 (1.6585 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07755732536315918 uauc: 0.5022753719295867
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015244483947753906 u-nDCG: 0.7986931700788974
rank_0 auc: 0.4869187563727603
Train: data epoch: [1]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 3.2948  time: 0.4667  data: 0.0000  max mem: 28728
Train: data epoch: [1]  [49/50]  eta: 0:00:00  lr: 0.000032  loss: 0.7637  time: 0.4933  data: 0.0000  max mem: 28728
Train: data epoch: [1] Total time: 0:00:24 (0.4993 s / it)
Evaluation  [ 0/82]  eta: 0:01:18  loss: 0.7189  acc: 0.5469  time: 0.9603  data: 0.0043  max mem: 28728
Evaluation  [16/82]  eta: 0:01:41  loss: 0.7926  acc: 0.5312  time: 1.5348  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:19  loss: 0.8632  acc: 0.4375  time: 1.6383  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:54  loss: 0.8254  acc: 0.5000  time: 1.6441  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:29  loss: 0.7773  acc: 0.5469  time: 1.7370  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7500  acc: 0.5781  time: 1.5877  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7826  acc: 0.5625  time: 1.5252  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:13 (1.6227 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07699131965637207 uauc: 0.4773826930239864
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
2025-11-12 21:44:12,755 [INFO] Averaged stats: loss: 0.694744  acc: 0.518483 ***auc: 0.5450609743331534 ***uauc: 0.5294649876857795 ***u-nDCG: 0.8137018560979303
2025-11-12 21:44:12,761 [INFO] Saving checkpoint at epoch 7 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:44:13,240 [INFO] Start training
2025-11-12 21:44:13,247 [INFO] Start training epoch 8, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:44:38,469 [INFO] Averaged stats: lr: 0.000100  loss: 0.695517
2025-11-12 21:44:38,470 [INFO] Evaluating on valid.
2025-11-12 21:46:38,082 [INFO] Averaged stats: loss: 0.691797  acc: 0.470274 ***auc: 0.5608896971054026 ***uauc: 0.5352046580733797 ***u-nDCG: 0.8156610369645112
2025-11-12 21:46:38,088 [INFO] Saving checkpoint at epoch 8 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:46:38,576 [INFO] Start training
2025-11-12 21:46:38,582 [INFO] Start training epoch 9, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:47:03,584 [INFO] Averaged stats: lr: 0.000100  loss: 0.710889
2025-11-12 21:47:03,586 [INFO] Evaluating on valid.
2025-11-12 21:49:03,794 [INFO] Averaged stats: loss: 0.692609  acc: 0.530488 ***auc: 0.5637635363851112 ***uauc: 0.5211141053646949 ***u-nDCG: 0.809944315146581
2025-11-12 21:49:03,800 [INFO] Saving checkpoint at epoch 9 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:49:04,266 [INFO] Start training
2025-11-12 21:49:04,272 [INFO] Start training epoch 10, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:49:29,150 [INFO] Averaged stats: lr: 0.000100  loss: 0.688134
2025-11-12 21:49:29,151 [INFO] Evaluating on valid.
2025-11-12 21:51:29,090 [INFO] Averaged stats: loss: 0.689218  acc: 0.535061 ***auc: 0.5741396931334477 ***uauc: 0.5445847904532083 ***u-nDCG: 0.8198179563750148
2025-11-12 21:51:29,097 [INFO] Saving checkpoint at epoch 10 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:51:29,576 [INFO] Start training
2025-11-12 21:51:29,582 [INFO] Start training epoch 11, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:51:54,742 [INFO] Averaged stats: lr: 0.000100  loss: 0.702247
2025-11-12 21:51:54,744 [INFO] Evaluating on valid.
2025-11-12 21:53:54,421 [INFO] Averaged stats: loss: 0.679965  acc: 0.482851 ***auc: 0.5922587119076534 ***uauc: 0.5732967175577083 ***u-nDCG: 0.8296177258743271
2025-11-12 21:53:54,427 [INFO] Saving checkpoint at epoch 11 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:53:54,893 [INFO] Start training
2025-11-12 21:53:54,900 [INFO] Start training epoch 12, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:54:20,027 [INFO] Averaged stats: lr: 0.000100  loss: 0.664005
2025-11-12 21:54:20,028 [INFO] Evaluating on valid.
2025-11-12 21:56:19,540 [INFO] Averaged stats: loss: 0.674960  acc: 0.534489 ***auc: 0.5990400638838829 ***uauc: 0.5818276316891633 ***u-nDCG: 0.8343742365242713
2025-11-12 21:56:19,547 [INFO] Saving checkpoint at epoch 12 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:56:20,062 [INFO] Start training
2025-11-12 21:56:20,068 [INFO] Start training epoch 13, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:56:44,796 [INFO] Averaged stats: lr: 0.000100  loss: 0.689076
2025-11-12 21:56:44,797 [INFO] Evaluating on valid.
u-nDCG for validation Cost: 0.0030775070190429688 u-nDCG: 0.7869735573068956
rank_0 auc: 0.5041018043959963
Train: data epoch: [2]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.8970  time: 0.4666  data: 0.0000  max mem: 28728
Train: data epoch: [2]  [49/50]  eta: 0:00:00  lr: 0.000032  loss: 0.7887  time: 0.4964  data: 0.0000  max mem: 28728
Train: data epoch: [2] Total time: 0:00:24 (0.4983 s / it)
Evaluation  [ 0/82]  eta: 0:01:16  loss: 0.6879  acc: 0.4219  time: 0.9295  data: 0.0051  max mem: 28728
Evaluation  [16/82]  eta: 0:01:39  loss: 0.7059  acc: 0.5156  time: 1.5073  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:18  loss: 0.6999  acc: 0.5938  time: 1.6246  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:53  loss: 0.7126  acc: 0.5469  time: 1.6089  data: 0.0030  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6966  acc: 0.5625  time: 1.5611  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7035  acc: 0.4375  time: 1.5405  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7044  acc: 0.4375  time: 1.4808  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:07 (1.5583 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07860016822814941 uauc: 0.49275867776384313
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015249252319335938 u-nDCG: 0.79679935516573
rank_0 auc: 0.513527438932493
Train: data epoch: [3]  [ 0/50]  eta: 0:00:23  lr: 0.000010  loss: 0.6365  time: 0.4750  data: 0.0000  max mem: 28728
Train: data epoch: [3]  [49/50]  eta: 0:00:00  lr: 0.000032  loss: 0.7272  time: 0.5048  data: 0.0000  max mem: 28728
Train: data epoch: [3] Total time: 0:00:25 (0.5019 s / it)
Evaluation  [ 0/82]  eta: 0:01:12  loss: 0.7141  acc: 0.4375  time: 0.8887  data: 0.0051  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.6977  acc: 0.5156  time: 1.4827  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.6578  acc: 0.6406  time: 1.5653  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6931  acc: 0.5312  time: 1.5591  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6967  acc: 0.5156  time: 1.5687  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7234  acc: 0.4531  time: 1.5388  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.7024  acc: 0.5000  time: 1.4811  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:06 (1.5368 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08071041107177734 uauc: 0.49411112450975375
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.004087209701538086 u-nDCG: 0.7989875760928004
rank_0 auc: 0.5193179552109004
Train: data epoch: [4]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7802  time: 0.4688  data: 0.0000  max mem: 28728
Train: data epoch: [4]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6567  time: 0.5061  data: 0.0000  max mem: 28728
Train: data epoch: [4] Total time: 0:00:24 (0.4992 s / it)
Evaluation  [ 0/82]  eta: 0:01:27  loss: 0.6964  acc: 0.4219  time: 1.0624  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:37  loss: 0.7122  acc: 0.5000  time: 1.4819  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:16  loss: 0.6663  acc: 0.6562  time: 1.5584  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6855  acc: 0.5625  time: 1.5812  data: 0.0030  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6922  acc: 0.5156  time: 1.5908  data: 0.0030  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7093  acc: 0.4219  time: 1.5387  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6959  acc: 0.5000  time: 1.4810  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:06 (1.5410 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07515120506286621 uauc: 0.5167545938473529
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030303001403808594 u-nDCG: 0.8087177306054378
rank_0 auc: 0.5207237302699638
Train: data epoch: [5]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.7108  time: 0.5182  data: 0.0000  max mem: 28728
Train: data epoch: [5]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6863  time: 0.4991  data: 0.0000  max mem: 28728
Train: data epoch: [5] Total time: 0:00:25 (0.5050 s / it)
Evaluation  [ 0/82]  eta: 0:01:13  loss: 0.6854  acc: 0.4375  time: 0.8957  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:36  loss: 0.7034  acc: 0.5156  time: 1.4645  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:15  loss: 0.6667  acc: 0.6250  time: 1.5669  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:52  loss: 0.6841  acc: 0.5469  time: 1.5589  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:28  loss: 0.6928  acc: 0.5469  time: 1.5774  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.7027  acc: 0.4375  time: 1.4744  data: 0.0029  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6819  acc: 0.5000  time: 1.4169  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:04 (1.5188 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0769495964050293 uauc: 0.5209247554518941
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003069162368774414 u-nDCG: 0.808799413773193
rank_0 auc: 0.5333842436484729
Train: data epoch: [6]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.6743  time: 0.4952  data: 0.0000  max mem: 28728
Train: data epoch: [6]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.8008  time: 0.4968  data: 0.0000  max mem: 28728
Train: data epoch: [6] Total time: 0:00:25 (0.5015 s / it)
Evaluation  [ 0/82]  eta: 0:01:08  loss: 0.6790  acc: 0.4844  time: 0.8306  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:31  loss: 0.7059  acc: 0.5625  time: 1.3933  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6889  acc: 0.6406  time: 1.4897  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6967  acc: 0.5781  time: 1.4930  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6925  acc: 0.5469  time: 1.5138  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6968  acc: 0.4688  time: 1.4503  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6784  acc: 0.5000  time: 1.3957  data: 0.0026  max mem: 28728
Evaluation Total time: 0:01:59 (1.4609 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07712626457214355 uauc: 0.5119054892156806
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.005378007888793945 u-nDCG: 0.8025947563017242
rank_0 auc: 0.5364709351644812
Train: data epoch: [7]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.7155  time: 0.4833  data: 0.0000  max mem: 28728
Train: data epoch: [7]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6608  time: 0.4980  data: 0.0000  max mem: 28728
Train: data epoch: [7] Total time: 0:00:24 (0.4979 s / it)
Evaluation  [ 0/82]  eta: 0:01:09  loss: 0.6757  acc: 0.5469  time: 0.8481  data: 0.0058  max mem: 28728
Evaluation  [16/82]  eta: 0:01:31  loss: 0.7236  acc: 0.5000  time: 1.3859  data: 0.0031  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.7161  acc: 0.7188  time: 1.5018  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7077  acc: 0.6250  time: 1.5056  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.7070  acc: 0.5156  time: 1.4847  data: 0.0029  max mem: 28728
2025-11-12 21:58:44,928 [INFO] Averaged stats: loss: 0.689356  acc: 0.578887 ***auc: 0.6086593961826767 ***uauc: 0.6076300140875321 ***u-nDCG: 0.8433361359208514
2025-11-12 21:58:44,935 [INFO] Saving checkpoint at epoch 13 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 21:58:45,421 [INFO] Start training
2025-11-12 21:58:45,427 [INFO] Start training epoch 14, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 21:59:10,491 [INFO] Averaged stats: lr: 0.000100  loss: 0.660475
2025-11-12 21:59:10,493 [INFO] Evaluating on valid.
2025-11-12 22:01:10,139 [INFO] Averaged stats: loss: 0.724538  acc: 0.582889 ***auc: 0.6160178323698435 ***uauc: 0.6239884572866452 ***u-nDCG: 0.847559898727203
2025-11-12 22:01:10,145 [INFO] Saving checkpoint at epoch 14 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:01:10,615 [INFO] Start training
2025-11-12 22:01:10,623 [INFO] Start training epoch 15, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:01:35,810 [INFO] Averaged stats: lr: 0.000100  loss: 0.646861
2025-11-12 22:01:35,812 [INFO] Evaluating on valid.
2025-11-12 22:03:35,700 [INFO] Averaged stats: loss: 0.664679  acc: 0.582317 ***auc: 0.634254896158251 ***uauc: 0.6417592206830743 ***u-nDCG: 0.8563277071027393
2025-11-12 22:03:35,706 [INFO] Saving checkpoint at epoch 15 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:03:36,167 [INFO] Start training
2025-11-12 22:03:36,174 [INFO] Start training epoch 16, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:04:01,165 [INFO] Averaged stats: lr: 0.000100  loss: 0.659928
2025-11-12 22:04:01,167 [INFO] Evaluating on valid.
2025-11-12 22:06:01,035 [INFO] Averaged stats: loss: 0.677156  acc: 0.510290 ***auc: 0.6450831875836245 ***uauc: 0.634142055363074 ***u-nDCG: 0.8513810591529389
2025-11-12 22:06:01,041 [INFO] Saving checkpoint at epoch 16 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:06:01,509 [INFO] Start training
2025-11-12 22:06:01,515 [INFO] Start training epoch 17, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:06:26,453 [INFO] Averaged stats: lr: 0.000100  loss: 0.659708
2025-11-12 22:06:26,454 [INFO] Evaluating on valid.
2025-11-12 22:08:26,548 [INFO] Averaged stats: loss: 0.657508  acc: 0.581364 ***auc: 0.6468102826561881 ***uauc: 0.6317615142882776 ***u-nDCG: 0.849917334728241
2025-11-12 22:08:26,554 [INFO] Saving checkpoint at epoch 17 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:08:27,021 [INFO] Start training
2025-11-12 22:08:27,027 [INFO] Start training epoch 18, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:08:52,013 [INFO] Averaged stats: lr: 0.000100  loss: 0.653891
2025-11-12 22:08:52,015 [INFO] Evaluating on valid.
2025-11-12 22:10:52,766 [INFO] Averaged stats: loss: 0.687563  acc: 0.614901 ***auc: 0.6509353990864355 ***uauc: 0.6368813418600323 ***u-nDCG: 0.8505118017308375
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6921  acc: 0.4062  time: 1.4560  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6886  acc: 0.6250  time: 1.4038  data: 0.0024  max mem: 28728
Evaluation Total time: 0:01:59 (1.4613 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07849359512329102 uauc: 0.5294649876857795
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003210306167602539 u-nDCG: 0.8137018560979303
rank_0 auc: 0.5450609743331534
Train: data epoch: [8]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7599  time: 0.4642  data: 0.0000  max mem: 28728
Train: data epoch: [8]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7090  time: 0.5061  data: 0.0000  max mem: 28728
Train: data epoch: [8] Total time: 0:00:25 (0.5044 s / it)
Evaluation  [ 0/82]  eta: 0:01:08  loss: 0.6873  acc: 0.4375  time: 0.8382  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:32  loss: 0.6990  acc: 0.5156  time: 1.4050  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6535  acc: 0.6250  time: 1.5046  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6788  acc: 0.5469  time: 1.4813  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6860  acc: 0.5156  time: 1.4867  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.7056  acc: 0.4375  time: 1.4550  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6636  acc: 0.5000  time: 1.3997  data: 0.0025  max mem: 28728
Evaluation Total time: 0:01:59 (1.4575 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07793784141540527 uauc: 0.5352046580733797
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003072500228881836 u-nDCG: 0.8156610369645112
rank_0 auc: 0.5608896971054026
Train: data epoch: [9]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.6978  time: 0.5171  data: 0.0000  max mem: 28728
Train: data epoch: [9]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.8994  time: 0.4950  data: 0.0000  max mem: 28728
Train: data epoch: [9] Total time: 0:00:25 (0.5000 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6672  acc: 0.6094  time: 1.0017  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:32  loss: 0.7135  acc: 0.4844  time: 1.4031  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.7313  acc: 0.7031  time: 1.4942  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7230  acc: 0.5469  time: 1.4848  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.7016  acc: 0.5312  time: 1.4982  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6930  acc: 0.4688  time: 1.4750  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6679  acc: 0.5625  time: 1.4189  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:00 (1.4648 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08112096786499023 uauc: 0.5211141053646949
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0025207996368408203 u-nDCG: 0.809944315146581
rank_0 auc: 0.5637635363851112
Train: data epoch: [10]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.6577  time: 0.4764  data: 0.0000  max mem: 28728
Train: data epoch: [10]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6694  time: 0.5023  data: 0.0000  max mem: 28728
Train: data epoch: [10] Total time: 0:00:24 (0.4976 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6636  acc: 0.6094  time: 1.0088  data: 0.0055  max mem: 28728
Evaluation  [16/82]  eta: 0:01:32  loss: 0.7176  acc: 0.5156  time: 1.3987  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.7204  acc: 0.7188  time: 1.4825  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7135  acc: 0.5781  time: 1.4935  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6925  acc: 0.5781  time: 1.5047  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6850  acc: 0.5156  time: 1.4599  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6634  acc: 0.6250  time: 1.4060  data: 0.0025  max mem: 28728
Evaluation Total time: 0:01:59 (1.4615 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07686185836791992 uauc: 0.5445847904532083
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030517578125 u-nDCG: 0.8198179563750148
rank_0 auc: 0.5741396931334477
Train: data epoch: [11]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.6398  time: 0.4896  data: 0.0000  max mem: 28728
Train: data epoch: [11]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7526  time: 0.5046  data: 0.0000  max mem: 28728
Train: data epoch: [11] Total time: 0:00:25 (0.5032 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6594  acc: 0.4844  time: 1.0014  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.6972  acc: 0.5312  time: 1.4131  data: 0.0031  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6696  acc: 0.6406  time: 1.4890  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6818  acc: 0.5781  time: 1.4727  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6737  acc: 0.5312  time: 1.4758  data: 0.0024  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6796  acc: 0.4375  time: 1.4596  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6329  acc: 0.5000  time: 1.4065  data: 0.0026  max mem: 28728
Evaluation Total time: 0:01:59 (1.4583 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07985973358154297 uauc: 0.5732967175577083
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030837059020996094 u-nDCG: 0.8296177258743271
rank_0 auc: 0.5922587119076534
Train: data epoch: [12]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.6858  time: 0.4898  data: 0.0005  max mem: 28728
Train: data epoch: [12]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6598  time: 0.5041  data: 0.0000  max mem: 28728
Train: data epoch: [12] Total time: 0:00:25 (0.5025 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6473  acc: 0.5781  time: 1.0012  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7012  acc: 0.5469  time: 1.4180  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6830  acc: 0.6875  time: 1.4859  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6964  acc: 0.5938  time: 1.4804  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6531  acc: 0.6094  time: 1.4877  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6640  acc: 0.5156  time: 1.4469  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6019  acc: 0.5625  time: 1.3918  data: 0.0026  max mem: 28728
Evaluation Total time: 0:01:59 (1.4564 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0770118236541748 uauc: 0.5818276316891633
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003103971481323242 u-nDCG: 0.8343742365242713
rank_0 auc: 0.5990400638838829
Train: data epoch: [13]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7841  time: 0.4761  data: 0.0000  max mem: 28728
Train: data epoch: [13]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7223  time: 0.4947  data: 0.0000  max mem: 28728
Train: data epoch: [13] Total time: 0:00:24 (0.4946 s / it)
Evaluation  [ 0/82]  eta: 0:01:20  loss: 0.6472  acc: 0.6406  time: 0.9875  data: 0.0046  max mem: 28728
2025-11-12 22:10:52,772 [INFO] Saving checkpoint at epoch 18 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:10:53,249 [INFO] Start training
2025-11-12 22:10:53,255 [INFO] Start training epoch 19, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:11:18,050 [INFO] Averaged stats: lr: 0.000100  loss: 0.650398
2025-11-12 22:11:18,052 [INFO] Evaluating on valid.
2025-11-12 22:13:20,135 [INFO] Averaged stats: loss: 0.657330  acc: 0.598323 ***auc: 0.6531472211386993 ***uauc: 0.6358344560336971 ***u-nDCG: 0.849915052813088
2025-11-12 22:13:20,141 [INFO] Saving checkpoint at epoch 19 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:13:20,613 [INFO] Start training
2025-11-12 22:13:20,619 [INFO] Start training epoch 20, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:13:45,624 [INFO] Averaged stats: lr: 0.000100  loss: 0.647453
2025-11-12 22:13:45,625 [INFO] Evaluating on valid.
2025-11-12 22:15:47,453 [INFO] Averaged stats: loss: 0.685940  acc: 0.510861 ***auc: 0.6614339811356643 ***uauc: 0.6352219829160185 ***u-nDCG: 0.8483049268057644
2025-11-12 22:15:47,459 [INFO] Saving checkpoint at epoch 20 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:15:47,911 [INFO] Start training
2025-11-12 22:15:47,918 [INFO] Start training epoch 21, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:16:12,986 [INFO] Averaged stats: lr: 0.000100  loss: 0.634636
2025-11-12 22:16:12,987 [INFO] Evaluating on valid.
2025-11-12 22:18:14,209 [INFO] Averaged stats: loss: 0.653182  acc: 0.573552 ***auc: 0.6608670680989066 ***uauc: 0.6463738346101708 ***u-nDCG: 0.8507765862707164
2025-11-12 22:18:14,216 [INFO] Start training
2025-11-12 22:18:14,222 [INFO] Start training epoch 22, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:18:39,371 [INFO] Averaged stats: lr: 0.000100  loss: 0.653113
2025-11-12 22:18:39,372 [INFO] Evaluating on valid.
2025-11-12 22:20:41,186 [INFO] Averaged stats: loss: 0.653984  acc: 0.551448 ***auc: 0.6658807145480012 ***uauc: 0.6402003080005121 ***u-nDCG: 0.8460781440314298
2025-11-12 22:20:41,192 [INFO] Saving checkpoint at epoch 22 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:20:41,675 [INFO] Start training
2025-11-12 22:20:41,683 [INFO] Start training epoch 23, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:21:06,886 [INFO] Averaged stats: lr: 0.000100  loss: 0.613684
2025-11-12 22:21:06,888 [INFO] Evaluating on valid.
2025-11-12 22:23:08,218 [INFO] Averaged stats: loss: 0.652269  acc: 0.597180 ***auc: 0.6670027361200965 ***uauc: 0.6429897866250281 ***u-nDCG: 0.8457544453192503
2025-11-12 22:23:08,224 [INFO] Saving checkpoint at epoch 23 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:23:08,679 [INFO] Start training
2025-11-12 22:23:08,685 [INFO] Start training epoch 24, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:23:33,701 [INFO] Averaged stats: lr: 0.000100  loss: 0.631297
2025-11-12 22:23:33,703 [INFO] Evaluating on valid.
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7363  acc: 0.5312  time: 1.4131  data: 0.0031  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.7519  acc: 0.6250  time: 1.4901  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7213  acc: 0.5781  time: 1.4795  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.7022  acc: 0.6250  time: 1.4963  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6654  acc: 0.6094  time: 1.4730  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6373  acc: 0.8750  time: 1.4177  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:00 (1.4638 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08034825325012207 uauc: 0.6076300140875321
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030171871185302734 u-nDCG: 0.8433361359208514
rank_0 auc: 0.6086593961826767
Train: data epoch: [14]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.6601  time: 0.4873  data: 0.0000  max mem: 28728
Train: data epoch: [14]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6632  time: 0.4988  data: 0.0000  max mem: 28728
Train: data epoch: [14] Total time: 0:00:25 (0.5013 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6674  acc: 0.5781  time: 1.0007  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.8019  acc: 0.5000  time: 1.4128  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.8252  acc: 0.5156  time: 1.4865  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7993  acc: 0.5000  time: 1.4767  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.7123  acc: 0.6094  time: 1.4954  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6729  acc: 0.5625  time: 1.4497  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.6202  acc: 0.8750  time: 1.3962  data: 0.0024  max mem: 28728
Evaluation Total time: 0:01:59 (1.4580 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07756733894348145 uauc: 0.6239884572866452
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0015552043914794922 u-nDCG: 0.847559898727203
rank_0 auc: 0.6160178323698435
Train: data epoch: [15]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7193  time: 0.4630  data: 0.0000  max mem: 28728
Train: data epoch: [15]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6380  time: 0.5031  data: 0.0000  max mem: 28728
Train: data epoch: [15] Total time: 0:00:25 (0.5037 s / it)
Evaluation  [ 0/82]  eta: 0:01:21  loss: 0.6247  acc: 0.6562  time: 0.9996  data: 0.0060  max mem: 28728
Evaluation  [16/82]  eta: 0:01:32  loss: 0.7126  acc: 0.5781  time: 1.4071  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6921  acc: 0.6250  time: 1.4881  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6932  acc: 0.5938  time: 1.4884  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6451  acc: 0.6250  time: 1.4818  data: 0.0021  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6276  acc: 0.6562  time: 1.4712  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5546  acc: 0.6875  time: 1.4159  data: 0.0024  max mem: 28728
Evaluation Total time: 0:01:59 (1.4609 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07871317863464355 uauc: 0.6417592206830743
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.004610776901245117 u-nDCG: 0.8563277071027393
rank_0 auc: 0.634254896158251
Train: data epoch: [16]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.7282  time: 0.4913  data: 0.0000  max mem: 28728
Train: data epoch: [16]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7194  time: 0.4958  data: 0.0000  max mem: 28728
Train: data epoch: [16] Total time: 0:00:24 (0.4998 s / it)
Evaluation  [ 0/82]  eta: 0:01:21  loss: 0.6593  acc: 0.4844  time: 0.9973  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7096  acc: 0.5156  time: 1.4175  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6411  acc: 0.6719  time: 1.4991  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6652  acc: 0.5469  time: 1.4867  data: 0.0022  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6516  acc: 0.5625  time: 1.4787  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6698  acc: 0.5156  time: 1.4639  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5976  acc: 0.5625  time: 1.4090  data: 0.0027  max mem: 28728
Evaluation Total time: 0:01:59 (1.4607 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07753562927246094 uauc: 0.634142055363074
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.001524209976196289 u-nDCG: 0.8513810591529389
rank_0 auc: 0.6450831875836245
Train: data epoch: [17]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7507  time: 0.4741  data: 0.0000  max mem: 28728
Train: data epoch: [17]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6398  time: 0.4948  data: 0.0000  max mem: 28728
Train: data epoch: [17] Total time: 0:00:24 (0.4988 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6196  acc: 0.6094  time: 1.0007  data: 0.0038  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7101  acc: 0.5781  time: 1.4094  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6831  acc: 0.6250  time: 1.4945  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6720  acc: 0.5938  time: 1.4883  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6386  acc: 0.6875  time: 1.4872  data: 0.0024  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6317  acc: 0.6250  time: 1.4665  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5459  acc: 0.6875  time: 1.4109  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:00 (1.4634 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07726502418518066 uauc: 0.6317615142882776
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030782222747802734 u-nDCG: 0.849917334728241
rank_0 auc: 0.6468102826561881
Train: data epoch: [18]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5492  time: 0.4832  data: 0.0000  max mem: 28728
Train: data epoch: [18]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.8254  time: 0.4985  data: 0.0000  max mem: 28728
Train: data epoch: [18] Total time: 0:00:24 (0.4997 s / it)
Evaluation  [ 0/82]  eta: 0:01:21  loss: 0.6412  acc: 0.6562  time: 0.9992  data: 0.0042  max mem: 28728
Evaluation  [16/82]  eta: 0:01:31  loss: 0.7415  acc: 0.5312  time: 1.3920  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.7820  acc: 0.5000  time: 1.4975  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7450  acc: 0.5625  time: 1.5071  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.7069  acc: 0.6094  time: 1.5097  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6652  acc: 0.6250  time: 1.4783  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5835  acc: 0.8125  time: 1.4220  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:00 (1.4715 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07892060279846191 uauc: 0.6368813418600323
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030319690704345703 u-nDCG: 0.8505118017308375
rank_0 auc: 2025-11-12 22:25:35,507 [INFO] Averaged stats: loss: 0.650021  acc: 0.583460 ***auc: 0.6669930846409479 ***uauc: 0.6357057366888128 ***u-nDCG: 0.846451719894923
2025-11-12 22:25:35,513 [INFO] Start training
2025-11-12 22:25:35,519 [INFO] Start training epoch 25, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:26:00,552 [INFO] Averaged stats: lr: 0.000100  loss: 0.644738
2025-11-12 22:26:00,554 [INFO] Evaluating on valid.
2025-11-12 22:28:02,362 [INFO] Averaged stats: loss: 0.648779  acc: 0.602706 ***auc: 0.669541520589055 ***uauc: 0.6389103419954685 ***u-nDCG: 0.8444601828088862
2025-11-12 22:28:02,368 [INFO] Saving checkpoint at epoch 25 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:28:02,857 [INFO] Start training
2025-11-12 22:28:02,863 [INFO] Start training epoch 26, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:28:27,959 [INFO] Averaged stats: lr: 0.000100  loss: 0.646035
2025-11-12 22:28:27,961 [INFO] Evaluating on valid.
2025-11-12 22:30:29,735 [INFO] Averaged stats: loss: 0.661146  acc: 0.539825 ***auc: 0.6700067218840162 ***uauc: 0.6323676022573184 ***u-nDCG: 0.843253029223703
2025-11-12 22:30:29,743 [INFO] Saving checkpoint at epoch 26 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:30:30,218 [INFO] Start training
2025-11-12 22:30:30,225 [INFO] Start training epoch 27, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:30:55,272 [INFO] Averaged stats: lr: 0.000100  loss: 0.650676
2025-11-12 22:30:55,274 [INFO] Evaluating on valid.
2025-11-12 22:32:56,941 [INFO] Averaged stats: loss: 0.645240  acc: 0.592035 ***auc: 0.6715483600726325 ***uauc: 0.6411339596953032 ***u-nDCG: 0.8459525329164138
2025-11-12 22:32:56,949 [INFO] Saving checkpoint at epoch 27 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:32:57,404 [INFO] Start training
2025-11-12 22:32:57,412 [INFO] Start training epoch 28, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:33:22,742 [INFO] Averaged stats: lr: 0.000100  loss: 0.672525
2025-11-12 22:33:22,744 [INFO] Evaluating on valid.
2025-11-12 22:35:24,955 [INFO] Averaged stats: loss: 0.648079  acc: 0.598133 ***auc: 0.6722697710179147 ***uauc: 0.6421713074428147 ***u-nDCG: 0.8470075492869117
2025-11-12 22:35:24,961 [INFO] Saving checkpoint at epoch 28 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:35:25,433 [INFO] Start training
2025-11-12 22:35:25,439 [INFO] Start training epoch 29, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:35:50,495 [INFO] Averaged stats: lr: 0.000100  loss: 0.646411
2025-11-12 22:35:50,496 [INFO] Evaluating on valid.
2025-11-12 22:37:52,107 [INFO] Averaged stats: loss: 0.644556  acc: 0.584413 ***auc: 0.6723918251080705 ***uauc: 0.6439091853537928 ***u-nDCG: 0.8464563025521354
2025-11-12 22:37:52,112 [INFO] Saving checkpoint at epoch 29 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:37:52,578 [INFO] Start training
2025-11-12 22:37:52,584 [INFO] Start training epoch 30, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:38:17,381 [INFO] Averaged stats: lr: 0.000100  loss: 0.630416
2025-11-12 22:38:17,383 [INFO] Evaluating on valid.
0.6509353990864355
Train: data epoch: [19]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.7046  time: 0.4977  data: 0.0000  max mem: 28728
Train: data epoch: [19]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6411  time: 0.4962  data: 0.0000  max mem: 28728
Train: data epoch: [19] Total time: 0:00:24 (0.4959 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6125  acc: 0.6406  time: 1.0182  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7188  acc: 0.5625  time: 1.4331  data: 0.0025  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7033  acc: 0.6094  time: 1.5237  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6880  acc: 0.6250  time: 1.5153  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6371  acc: 0.6250  time: 1.5134  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6330  acc: 0.6250  time: 1.4902  data: 0.0023  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5327  acc: 0.7500  time: 1.4357  data: 0.0021  max mem: 28728
Evaluation Total time: 0:02:01 (1.4877 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07735013961791992 uauc: 0.6358344560336971
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030126571655273438 u-nDCG: 0.849915052813088
rank_0 auc: 0.6531472211386993
Train: data epoch: [20]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7031  time: 0.4711  data: 0.0000  max mem: 28728
Train: data epoch: [20]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6871  time: 0.4968  data: 0.0000  max mem: 28728
Train: data epoch: [20] Total time: 0:00:25 (0.5001 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6717  acc: 0.5000  time: 1.0311  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7178  acc: 0.5156  time: 1.4486  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6406  acc: 0.6719  time: 1.5252  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6622  acc: 0.5312  time: 1.5064  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6525  acc: 0.5625  time: 1.5151  data: 0.0024  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6765  acc: 0.5000  time: 1.4725  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5902  acc: 0.5625  time: 1.4161  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4846 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07501339912414551 uauc: 0.6352219829160185
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003047943115234375 u-nDCG: 0.8483049268057644
rank_0 auc: 0.6614339811356643
Train: data epoch: [21]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.8810  time: 0.4986  data: 0.0000  max mem: 28728
Train: data epoch: [21]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7453  time: 0.4996  data: 0.0000  max mem: 28728
Train: data epoch: [21] Total time: 0:00:25 (0.5014 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6189  acc: 0.5781  time: 1.0255  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7049  acc: 0.5938  time: 1.4285  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6641  acc: 0.5938  time: 1.5136  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6593  acc: 0.6094  time: 1.5187  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6316  acc: 0.6719  time: 1.5018  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6347  acc: 0.5938  time: 1.4600  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5470  acc: 0.6875  time: 1.4063  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4772 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07831645011901855 uauc: 0.6463738346101708
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003045320510864258 u-nDCG: 0.8507765862707164
rank_0 auc: 0.6608670680989066
Train: data epoch: [22]  [ 0/50]  eta: 0:00:22  lr: 0.000100  loss: 0.5545  time: 0.4595  data: 0.0000  max mem: 28728
Train: data epoch: [22]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7540  time: 0.5081  data: 0.0000  max mem: 28728
Train: data epoch: [22] Total time: 0:00:25 (0.5030 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6367  acc: 0.5469  time: 1.0189  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.6920  acc: 0.5156  time: 1.4211  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6508  acc: 0.6406  time: 1.5125  data: 0.0031  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6559  acc: 0.6094  time: 1.5148  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6343  acc: 0.6250  time: 1.5162  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6473  acc: 0.5781  time: 1.4847  data: 0.0029  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5567  acc: 0.6250  time: 1.4276  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4844 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07806777954101562 uauc: 0.6402003080005121
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003037691116333008 u-nDCG: 0.8460781440314298
rank_0 auc: 0.6658807145480012
Train: data epoch: [23]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.6544  time: 0.5141  data: 0.0000  max mem: 28728
Train: data epoch: [23]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5947  time: 0.5029  data: 0.0000  max mem: 28728
Train: data epoch: [23] Total time: 0:00:25 (0.5041 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6257  acc: 0.5938  time: 1.0346  data: 0.0047  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7187  acc: 0.5938  time: 1.4404  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6834  acc: 0.6094  time: 1.5143  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6746  acc: 0.6094  time: 1.5008  data: 0.0031  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6277  acc: 0.6562  time: 1.4976  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6323  acc: 0.6094  time: 1.4780  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5035  acc: 0.7500  time: 1.4220  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4785 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07498645782470703 uauc: 0.6429897866250281
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030465126037597656 u-nDCG: 0.8457544453192503
rank_0 auc: 0.6670027361200965
Train: data epoch: [24]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7604  time: 0.4670  data: 0.0000  max mem: 28728
Train: data epoch: [24]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.4998  time: 0.4998  data: 0.0000  max mem: 28728
Train: data epoch: [24] Total time: 0:00:25 (0.5003 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6260  acc: 0.5781  time: 1.0210  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7031  acc: 0.5938  time: 1.4277  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6701  acc: 0.5938  time: 1.5157  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6677  acc: 0.5938  time: 1.5142  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6216  acc: 0.6562  time: 1.5178  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6348  acc: 0.5938  time: 1.4754  data: 0.0032  max mem: 28728
2025-11-12 22:40:18,589 [INFO] Averaged stats: loss: 0.654359  acc: 0.559832 ***auc: 0.6735418359696967 ***uauc: 0.6495603805604896 ***u-nDCG: 0.8482720328896226
2025-11-12 22:40:18,595 [INFO] Saving checkpoint at epoch 30 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:40:19,082 [INFO] Start training
2025-11-12 22:40:19,088 [INFO] Start training epoch 31, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:40:44,254 [INFO] Averaged stats: lr: 0.000100  loss: 0.640427
2025-11-12 22:40:44,255 [INFO] Evaluating on valid.
2025-11-12 22:42:45,095 [INFO] Averaged stats: loss: 0.644212  acc: 0.608422 ***auc: 0.6747389905948563 ***uauc: 0.6511500970343284 ***u-nDCG: 0.8491526457136206
2025-11-12 22:42:45,101 [INFO] Saving checkpoint at epoch 31 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:42:45,575 [INFO] Start training
2025-11-12 22:42:45,581 [INFO] Start training epoch 32, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:43:10,403 [INFO] Averaged stats: lr: 0.000100  loss: 0.647221
2025-11-12 22:43:10,405 [INFO] Evaluating on valid.
2025-11-12 22:45:12,129 [INFO] Averaged stats: loss: 0.643483  acc: 0.597370 ***auc: 0.6722942709265226 ***uauc: 0.6570588338281215 ***u-nDCG: 0.8526614646808663
2025-11-12 22:45:12,137 [INFO] Start training
2025-11-12 22:45:12,143 [INFO] Start training epoch 33, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:45:37,187 [INFO] Averaged stats: lr: 0.000100  loss: 0.628000
2025-11-12 22:45:37,188 [INFO] Evaluating on valid.
2025-11-12 22:47:38,960 [INFO] Averaged stats: loss: 0.643161  acc: 0.594131 ***auc: 0.6745633336743522 ***uauc: 0.6640793203821613 ***u-nDCG: 0.8550621337589667
2025-11-12 22:47:38,966 [INFO] Start training
2025-11-12 22:47:38,972 [INFO] Start training epoch 34, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:48:04,113 [INFO] Averaged stats: lr: 0.000100  loss: 0.630759
2025-11-12 22:48:04,114 [INFO] Evaluating on valid.
2025-11-12 22:50:05,855 [INFO] Averaged stats: loss: 0.657289  acc: 0.550686 ***auc: 0.6737282580015588 ***uauc: 0.6634195164770904 ***u-nDCG: 0.8550626960864764
2025-11-12 22:50:05,861 [INFO] Start training
2025-11-12 22:50:05,869 [INFO] Start training epoch 35, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:50:30,820 [INFO] Averaged stats: lr: 0.000100  loss: 0.632730
2025-11-12 22:50:30,822 [INFO] Evaluating on valid.
2025-11-12 22:52:32,594 [INFO] Averaged stats: loss: 0.647856  acc: 0.614329 ***auc: 0.6707796568795223 ***uauc: 0.6515640343962879 ***u-nDCG: 0.8514961395095106
2025-11-12 22:52:32,600 [INFO] Start training
2025-11-12 22:52:32,606 [INFO] Start training epoch 36, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5107  acc: 0.7500  time: 1.4219  data: 0.0030  max mem: 28728
Evaluation Total time: 0:02:01 (1.4843 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07850265502929688 uauc: 0.6357057366888128
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030629634857177734 u-nDCG: 0.846451719894923
rank_0 auc: 0.6669930846409479
Train: data epoch: [25]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.6257  time: 0.5003  data: 0.0000  max mem: 28728
Train: data epoch: [25]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5743  time: 0.5041  data: 0.0000  max mem: 28728
Train: data epoch: [25] Total time: 0:00:25 (0.5007 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6265  acc: 0.6250  time: 1.0362  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7109  acc: 0.5938  time: 1.4280  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6965  acc: 0.6094  time: 1.5098  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6766  acc: 0.6094  time: 1.5154  data: 0.0031  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6196  acc: 0.6719  time: 1.5157  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6319  acc: 0.6406  time: 1.4891  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5453  acc: 0.7500  time: 1.4321  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4844 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07898592948913574 uauc: 0.6389103419954685
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030167102813720703 u-nDCG: 0.8444601828088862
rank_0 auc: 0.669541520589055
Train: data epoch: [26]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.6683  time: 0.4827  data: 0.0000  max mem: 28728
Train: data epoch: [26]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6061  time: 0.5006  data: 0.0000  max mem: 28728
Train: data epoch: [26] Total time: 0:00:25 (0.5019 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6502  acc: 0.5469  time: 1.0213  data: 0.0043  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6942  acc: 0.5469  time: 1.4314  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6460  acc: 0.6406  time: 1.5129  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6547  acc: 0.6250  time: 1.5117  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6220  acc: 0.6406  time: 1.5137  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6521  acc: 0.5469  time: 1.4850  data: 0.0029  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5699  acc: 0.5625  time: 1.4302  data: 0.0028  max mem: 28728
Evaluation Total time: 0:02:01 (1.4840 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0764760971069336 uauc: 0.6323676022573184
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030739307403564453 u-nDCG: 0.843253029223703
rank_0 auc: 0.6700067218840162
Train: data epoch: [27]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.5230  time: 0.5055  data: 0.0000  max mem: 28728
Train: data epoch: [27]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6996  time: 0.5022  data: 0.0000  max mem: 28728
Train: data epoch: [27] Total time: 0:00:25 (0.5009 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6270  acc: 0.5938  time: 1.0205  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.6927  acc: 0.5938  time: 1.4416  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6825  acc: 0.6094  time: 1.5065  data: 0.0032  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6710  acc: 0.6094  time: 1.5119  data: 0.0031  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6193  acc: 0.6562  time: 1.5076  data: 0.0024  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6342  acc: 0.5781  time: 1.4899  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5436  acc: 0.7500  time: 1.4331  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4826 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07846522331237793 uauc: 0.6411339596953032
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030570030212402344 u-nDCG: 0.8459525329164138
rank_0 auc: 0.6715483600726325
Train: data epoch: [28]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.6379  time: 0.4776  data: 0.0000  max mem: 28728
Train: data epoch: [28]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5684  time: 0.5055  data: 0.0000  max mem: 28728
Train: data epoch: [28] Total time: 0:00:25 (0.5066 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6327  acc: 0.6094  time: 1.0365  data: 0.0042  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6983  acc: 0.5938  time: 1.4368  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6929  acc: 0.6094  time: 1.5188  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6713  acc: 0.5938  time: 1.5183  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6311  acc: 0.6719  time: 1.5261  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6395  acc: 0.5938  time: 1.4870  data: 0.0029  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5765  acc: 0.7500  time: 1.4311  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:02 (1.4893 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07745981216430664 uauc: 0.6421713074428147
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003047943115234375 u-nDCG: 0.8470075492869117
rank_0 auc: 0.6722697710179147
Train: data epoch: [29]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.6187  time: 0.4639  data: 0.0000  max mem: 28728
Train: data epoch: [29]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7035  time: 0.5018  data: 0.0000  max mem: 28728
Train: data epoch: [29] Total time: 0:00:25 (0.5011 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6279  acc: 0.5781  time: 1.0327  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6908  acc: 0.6094  time: 1.4389  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6690  acc: 0.6406  time: 1.5190  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6544  acc: 0.5781  time: 1.4941  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6201  acc: 0.6562  time: 1.5109  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6387  acc: 0.5625  time: 1.4902  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5584  acc: 0.6875  time: 1.4322  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:01 (1.4819 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07635092735290527 uauc: 0.6439091853537928
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030736923217773438 u-nDCG: 0.8464563025521354
rank_0 auc: 0.6723918251080705
Train: data epoch: [30]  [ 0/50]  eta: 0:00:22  lr: 0.000100  loss: 0.6096  time: 0.4573  data: 0.0000  max mem: 28728
Train: data epoch: [30]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5590  time: 0.4934  data: 0.0000  max mem: 28728
Train: data epoch: [30] Total time: 0:00:24 (0.4959 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6448  acc: 0.5625  time: 1.0271  data: 0.0043  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6918  acc: 0.5625  time: 1.4253  data: 0.0026  max mem: 28728
2025-11-12 22:52:57,755 [INFO] Averaged stats: lr: 0.000100  loss: 0.636940
2025-11-12 22:52:57,757 [INFO] Evaluating on valid.
2025-11-12 22:54:59,636 [INFO] Averaged stats: loss: 0.645569  acc: 0.614710 ***auc: 0.674115876252595 ***uauc: 0.6634939256966752 ***u-nDCG: 0.8579252421268614
2025-11-12 22:54:59,642 [INFO] Start training
2025-11-12 22:54:59,649 [INFO] Start training epoch 37, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:55:24,752 [INFO] Averaged stats: lr: 0.000100  loss: 0.627161
2025-11-12 22:55:24,754 [INFO] Evaluating on valid.
2025-11-12 22:57:26,226 [INFO] Averaged stats: loss: 0.647533  acc: 0.578125 ***auc: 0.6752731628446562 ***uauc: 0.6558826096763501 ***u-nDCG: 0.8533889663089715
2025-11-12 22:57:26,234 [INFO] Saving checkpoint at epoch 37 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:57:26,712 [INFO] Start training
2025-11-12 22:57:26,718 [INFO] Start training epoch 38, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 22:57:51,640 [INFO] Averaged stats: lr: 0.000100  loss: 0.629774
2025-11-12 22:57:51,641 [INFO] Evaluating on valid.
2025-11-12 22:59:53,785 [INFO] Averaged stats: loss: 0.640810  acc: 0.584604 ***auc: 0.6775526937352546 ***uauc: 0.6503063128340721 ***u-nDCG: 0.8502859131495042
2025-11-12 22:59:53,792 [INFO] Saving checkpoint at epoch 38 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 22:59:54,238 [INFO] Start training
2025-11-12 22:59:54,244 [INFO] Start training epoch 39, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:00:19,371 [INFO] Averaged stats: lr: 0.000100  loss: 0.627631
2025-11-12 23:00:19,373 [INFO] Evaluating on valid.
2025-11-12 23:02:19,848 [INFO] Averaged stats: loss: 0.659395  acc: 0.633384 ***auc: 0.6734848922427201 ***uauc: 0.6451289664881387 ***u-nDCG: 0.8498947798734204
2025-11-12 23:02:19,856 [INFO] Start training
2025-11-12 23:02:19,862 [INFO] Start training epoch 40, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:02:44,977 [INFO] Averaged stats: lr: 0.000100  loss: 0.638968
2025-11-12 23:02:44,978 [INFO] Evaluating on valid.
2025-11-12 23:04:46,227 [INFO] Averaged stats: loss: 0.642137  acc: 0.604802 ***auc: 0.6760068237442425 ***uauc: 0.6553642414699711 ***u-nDCG: 0.8511659184463625
2025-11-12 23:04:46,233 [INFO] Start training
2025-11-12 23:04:46,239 [INFO] Start training epoch 41, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:05:11,206 [INFO] Averaged stats: lr: 0.000100  loss: 0.629963
2025-11-12 23:05:11,207 [INFO] Evaluating on valid.
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6500  acc: 0.6250  time: 1.5045  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6421  acc: 0.6250  time: 1.5080  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6173  acc: 0.6406  time: 1.4982  data: 0.0024  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6504  acc: 0.5781  time: 1.4782  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5597  acc: 0.6250  time: 1.4250  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:01 (1.4771 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07191252708435059 uauc: 0.6495603805604896
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0031766891479492188 u-nDCG: 0.8482720328896226
rank_0 auc: 0.6735418359696967
Train: data epoch: [31]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.6530  time: 0.4676  data: 0.0000  max mem: 28728
Train: data epoch: [31]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6777  time: 0.5013  data: 0.0000  max mem: 28728
Train: data epoch: [31] Total time: 0:00:25 (0.5033 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6232  acc: 0.6094  time: 1.0249  data: 0.0047  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7076  acc: 0.6094  time: 1.4317  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6900  acc: 0.6094  time: 1.5106  data: 0.0031  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6621  acc: 0.6094  time: 1.4869  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6227  acc: 0.6562  time: 1.4907  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6370  acc: 0.6562  time: 1.4750  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5290  acc: 0.7500  time: 1.4216  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:00 (1.4726 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0758669376373291 uauc: 0.6511500970343284
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030570030212402344 u-nDCG: 0.8491526457136206
rank_0 auc: 0.6747389905948563
Train: data epoch: [32]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5896  time: 0.4907  data: 0.0000  max mem: 28728
Train: data epoch: [32]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7094  time: 0.4968  data: 0.0000  max mem: 28728
Train: data epoch: [32] Total time: 0:00:24 (0.4964 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6183  acc: 0.5781  time: 1.0193  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6954  acc: 0.6250  time: 1.4332  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6812  acc: 0.6406  time: 1.5109  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6582  acc: 0.5781  time: 1.5054  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6213  acc: 0.6719  time: 1.5236  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6328  acc: 0.6250  time: 1.4838  data: 0.0029  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5397  acc: 0.7500  time: 1.4293  data: 0.0028  max mem: 28728
Evaluation Total time: 0:02:01 (1.4833 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07870292663574219 uauc: 0.6570588338281215
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030128955841064453 u-nDCG: 0.8526614646808663
rank_0 auc: 0.6722942709265226
Train: data epoch: [33]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.6137  time: 0.4717  data: 0.0000  max mem: 28728
Train: data epoch: [33]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6201  time: 0.5005  data: 0.0000  max mem: 28728
Train: data epoch: [33] Total time: 0:00:25 (0.5009 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6255  acc: 0.5625  time: 1.0179  data: 0.0048  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.6946  acc: 0.6094  time: 1.4217  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6747  acc: 0.6719  time: 1.5099  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6460  acc: 0.6250  time: 1.5129  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6108  acc: 0.6719  time: 1.5173  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6316  acc: 0.6250  time: 1.4922  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5369  acc: 0.6875  time: 1.4344  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4839 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08003425598144531 uauc: 0.6640793203821613
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003043651580810547 u-nDCG: 0.8550621337589667
rank_0 auc: 0.6745633336743522
Train: data epoch: [34]  [ 0/50]  eta: 0:00:27  lr: 0.000100  loss: 0.7417  time: 0.5543  data: 0.0000  max mem: 28728
Train: data epoch: [34]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5818  time: 0.5021  data: 0.0000  max mem: 28728
Train: data epoch: [34] Total time: 0:00:25 (0.5028 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6444  acc: 0.5469  time: 1.0344  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6948  acc: 0.5625  time: 1.4347  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6458  acc: 0.6406  time: 1.5178  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6331  acc: 0.5938  time: 1.5262  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6198  acc: 0.6562  time: 1.5222  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6547  acc: 0.5625  time: 1.4697  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5589  acc: 0.6250  time: 1.4141  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4835 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07678055763244629 uauc: 0.6634195164770904
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030608177185058594 u-nDCG: 0.8550626960864764
rank_0 auc: 0.6737282580015588
Train: data epoch: [35]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7095  time: 0.4629  data: 0.0000  max mem: 28728
Train: data epoch: [35]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7576  time: 0.4927  data: 0.0000  max mem: 28728
Train: data epoch: [35] Total time: 0:00:24 (0.4990 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6169  acc: 0.6406  time: 1.0213  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7087  acc: 0.5781  time: 1.4394  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6965  acc: 0.6250  time: 1.5153  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6729  acc: 0.6406  time: 1.5093  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6314  acc: 0.6406  time: 1.5107  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6300  acc: 0.6719  time: 1.4853  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5106  acc: 0.6875  time: 1.4288  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4839 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07788491249084473 uauc: 0.6515640343962879
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030417442321777344 u-nDCG: 0.8514961395095106
rank_0 auc: 0.6707796568795223
2025-11-12 23:07:13,220 [INFO] Averaged stats: loss: 0.644203  acc: 0.615854 ***auc: 0.6767199195690272 ***uauc: 0.6586267650985782 ***u-nDCG: 0.8539138778109377
2025-11-12 23:07:13,226 [INFO] Start training
2025-11-12 23:07:13,232 [INFO] Start training epoch 42, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:07:40,562 [INFO] Averaged stats: lr: 0.000100  loss: 0.628811
2025-11-12 23:07:40,562 [INFO] Evaluating on valid.
2025-11-12 23:09:42,340 [INFO] Averaged stats: loss: 0.639629  acc: 0.601562 ***auc: 0.6793322037638095 ***uauc: 0.6583690747581802 ***u-nDCG: 0.8522225066399101
2025-11-12 23:09:42,346 [INFO] Saving checkpoint at epoch 42 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 23:09:42,820 [INFO] Start training
2025-11-12 23:09:42,826 [INFO] Start training epoch 43, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:10:07,724 [INFO] Averaged stats: lr: 0.000100  loss: 0.610646
2025-11-12 23:10:07,725 [INFO] Evaluating on valid.
2025-11-12 23:12:08,724 [INFO] Averaged stats: loss: 0.648927  acc: 0.585747 ***auc: 0.6782300048450425 ***uauc: 0.6533634712971579 ***u-nDCG: 0.8511396446259394
2025-11-12 23:12:08,732 [INFO] Start training
2025-11-12 23:12:08,738 [INFO] Start training epoch 44, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:12:34,142 [INFO] Averaged stats: lr: 0.000100  loss: 0.601157
2025-11-12 23:12:34,144 [INFO] Evaluating on valid.
2025-11-12 23:14:35,467 [INFO] Averaged stats: loss: 0.668680  acc: 0.631288 ***auc: 0.6740613825164791 ***uauc: 0.6612267538221627 ***u-nDCG: 0.8532076776262497
2025-11-12 23:14:35,473 [INFO] Start training
2025-11-12 23:14:35,481 [INFO] Start training epoch 45, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:15:00,405 [INFO] Averaged stats: lr: 0.000100  loss: 0.605620
2025-11-12 23:15:00,406 [INFO] Evaluating on valid.
2025-11-12 23:17:01,345 [INFO] Averaged stats: loss: 0.651242  acc: 0.622713 ***auc: 0.6754500818816642 ***uauc: 0.6510652928485355 ***u-nDCG: 0.85314909222012
2025-11-12 23:17:01,352 [INFO] Start training
2025-11-12 23:17:01,356 [INFO] Start training epoch 46, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:17:26,534 [INFO] Averaged stats: lr: 0.000100  loss: 0.624382
2025-11-12 23:17:26,536 [INFO] Evaluating on valid.
2025-11-12 23:19:28,295 [INFO] Averaged stats: loss: 0.639903  acc: 0.607088 ***auc: 0.6792430389449062 ***uauc: 0.6443739298172558 ***u-nDCG: 0.849993974208743
2025-11-12 23:19:28,301 [INFO] Start training
2025-11-12 23:19:28,309 [INFO] Start training epoch 47, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:19:53,386 [INFO] Averaged stats: lr: 0.000100  loss: 0.632233
2025-11-12 23:19:53,388 [INFO] Evaluating on valid.
Train: data epoch: [36]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.6880  time: 0.5007  data: 0.0000  max mem: 28728
Train: data epoch: [36]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5750  time: 0.5125  data: 0.0000  max mem: 28728
Train: data epoch: [36] Total time: 0:00:25 (0.5030 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6191  acc: 0.6250  time: 1.0301  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7092  acc: 0.5781  time: 1.4403  data: 0.0025  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6924  acc: 0.6562  time: 1.5128  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6684  acc: 0.6562  time: 1.5044  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6286  acc: 0.6719  time: 1.5122  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6290  acc: 0.6875  time: 1.4834  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5156  acc: 0.6875  time: 1.4279  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4852 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07925224304199219 uauc: 0.6634939256966752
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.002077341079711914 u-nDCG: 0.8579252421268614
rank_0 auc: 0.674115876252595
Train: data epoch: [37]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.8723  time: 0.4888  data: 0.0000  max mem: 28728
Train: data epoch: [37]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5713  time: 0.5039  data: 0.0000  max mem: 28728
Train: data epoch: [37] Total time: 0:00:25 (0.5021 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6274  acc: 0.5469  time: 1.0251  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6937  acc: 0.5625  time: 1.4343  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6548  acc: 0.6406  time: 1.5075  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6499  acc: 0.5938  time: 1.5101  data: 0.0022  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6190  acc: 0.6719  time: 1.5025  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6294  acc: 0.5781  time: 1.4790  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5084  acc: 0.6875  time: 1.4258  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4802 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07950615882873535 uauc: 0.6558826096763501
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003019571304321289 u-nDCG: 0.8533889663089715
rank_0 auc: 0.6752731628446562
Train: data epoch: [38]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5622  time: 0.4898  data: 0.0000  max mem: 28728
Train: data epoch: [38]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5630  time: 0.4968  data: 0.0000  max mem: 28728
Train: data epoch: [38] Total time: 0:00:24 (0.4984 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6410  acc: 0.5469  time: 1.0136  data: 0.0044  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6945  acc: 0.5625  time: 1.4323  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6587  acc: 0.6406  time: 1.5338  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6512  acc: 0.5781  time: 1.5082  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6215  acc: 0.6719  time: 1.5126  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6353  acc: 0.5781  time: 1.4882  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5393  acc: 0.6875  time: 1.4341  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:02 (1.4885 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07287001609802246 uauc: 0.6503063128340721
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030481815338134766 u-nDCG: 0.8502859131495042
rank_0 auc: 0.6775526937352546
Train: data epoch: [39]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7213  time: 0.4711  data: 0.0000  max mem: 28728
Train: data epoch: [39]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5300  time: 0.4991  data: 0.0000  max mem: 28728
Train: data epoch: [39] Total time: 0:00:25 (0.5025 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6426  acc: 0.6562  time: 1.0161  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7361  acc: 0.5781  time: 1.4149  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7300  acc: 0.5938  time: 1.5001  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7079  acc: 0.6406  time: 1.4863  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6547  acc: 0.6562  time: 1.5008  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6460  acc: 0.6875  time: 1.4760  data: 0.0031  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5189  acc: 0.7500  time: 1.4213  data: 0.0029  max mem: 28728
Evaluation Total time: 0:02:00 (1.4681 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07663440704345703 uauc: 0.6451289664881387
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030493736267089844 u-nDCG: 0.8498947798734204
rank_0 auc: 0.6734848922427201
Train: data epoch: [40]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.5480  time: 0.4787  data: 0.0000  max mem: 28728
Train: data epoch: [40]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7265  time: 0.5035  data: 0.0000  max mem: 28728
Train: data epoch: [40] Total time: 0:00:25 (0.5023 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6299  acc: 0.5781  time: 1.0238  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6986  acc: 0.6250  time: 1.4354  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6766  acc: 0.6406  time: 1.5013  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6658  acc: 0.5781  time: 1.4957  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6257  acc: 0.6875  time: 1.5079  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6368  acc: 0.6406  time: 1.4853  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5184  acc: 0.7500  time: 1.4297  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4775 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07938289642333984 uauc: 0.6553642414699711
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030341148376464844 u-nDCG: 0.8511659184463625
rank_0 auc: 0.6760068237442425
Train: data epoch: [41]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.5447  time: 0.4692  data: 0.0000  max mem: 28728
Train: data epoch: [41]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5394  time: 0.4963  data: 0.0000  max mem: 28728
Train: data epoch: [41] Total time: 0:00:24 (0.4993 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6278  acc: 0.5938  time: 1.0325  data: 0.0185  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7023  acc: 0.6094  time: 1.4340  data: 0.0036  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6856  acc: 0.6562  time: 1.5096  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6856  acc: 0.6250  time: 1.5031  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6295  acc: 0.7031  time: 1.5270  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6293  acc: 0.7031  time: 1.4929  data: 0.0030  max mem: 28728
2025-11-12 23:21:54,790 [INFO] Averaged stats: loss: 0.639106  acc: 0.590511 ***auc: 0.6798001520182207 ***uauc: 0.6483115625256114 ***u-nDCG: 0.8500833473588265
2025-11-12 23:21:54,797 [INFO] Saving checkpoint at epoch 47 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 23:21:55,268 [INFO] Start training
2025-11-12 23:21:55,276 [INFO] Start training epoch 48, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:22:20,390 [INFO] Averaged stats: lr: 0.000100  loss: 0.602744
2025-11-12 23:22:20,391 [INFO] Evaluating on valid.
2025-11-12 23:24:22,242 [INFO] Averaged stats: loss: 0.639534  acc: 0.615282 ***auc: 0.6798322988680003 ***uauc: 0.645888791837915 ***u-nDCG: 0.8471312513934506
2025-11-12 23:24:22,248 [INFO] Saving checkpoint at epoch 48 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 23:24:22,715 [INFO] Start training
2025-11-12 23:24:22,723 [INFO] Start training epoch 49, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:24:47,753 [INFO] Averaged stats: lr: 0.000100  loss: 0.604581
2025-11-12 23:24:47,754 [INFO] Evaluating on valid.
2025-11-12 23:26:48,857 [INFO] Averaged stats: loss: 0.647344  acc: 0.624047 ***auc: 0.6788832614991063 ***uauc: 0.6516700168691234 ***u-nDCG: 0.8493272263784098
2025-11-12 23:26:48,864 [INFO] Start training
2025-11-12 23:26:48,874 [INFO] Start training epoch 50, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:27:14,047 [INFO] Averaged stats: lr: 0.000100  loss: 0.592721
2025-11-12 23:27:14,049 [INFO] Evaluating on valid.
2025-11-12 23:29:15,405 [INFO] Averaged stats: loss: 0.658836  acc: 0.627858 ***auc: 0.6745438822317604 ***uauc: 0.6535837084023858 ***u-nDCG: 0.8537112410520437
2025-11-12 23:29:15,412 [INFO] Start training
2025-11-12 23:29:15,419 [INFO] Start training epoch 51, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:29:40,454 [INFO] Averaged stats: lr: 0.000100  loss: 0.590869
2025-11-12 23:29:40,456 [INFO] Evaluating on valid.
2025-11-12 23:31:42,394 [INFO] Averaged stats: loss: 0.651406  acc: 0.620427 ***auc: 0.6779193757007531 ***uauc: 0.6608752962632619 ***u-nDCG: 0.8547345371167795
2025-11-12 23:31:42,400 [INFO] Start training
2025-11-12 23:31:42,406 [INFO] Start training epoch 52, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:32:07,286 [INFO] Averaged stats: lr: 0.000100  loss: 0.596101
2025-11-12 23:32:07,287 [INFO] Evaluating on valid.
2025-11-12 23:34:08,354 [INFO] Averaged stats: loss: 0.642264  acc: 0.606707 ***auc: 0.6754575803385413 ***uauc: 0.6586581927905825 ***u-nDCG: 0.8506314818880228
2025-11-12 23:34:08,360 [INFO] Start training
2025-11-12 23:34:08,367 [INFO] Start training epoch 53, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5213  acc: 0.7500  time: 1.4357  data: 0.0029  max mem: 28728
Evaluation Total time: 0:02:01 (1.4868 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08025407791137695 uauc: 0.6586267650985782
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030422210693359375 u-nDCG: 0.8539138778109377
rank_0 auc: 0.6767199195690272
Train: data epoch: [42]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5376  time: 0.4861  data: 0.0000  max mem: 28728
Train: data epoch: [42]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5199  time: 0.4989  data: 0.0000  max mem: 28728
Train: data epoch: [42] Total time: 0:00:27 (0.5466 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6377  acc: 0.5469  time: 1.0245  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6890  acc: 0.6094  time: 1.4314  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6693  acc: 0.6406  time: 1.5125  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6797  acc: 0.5938  time: 1.5074  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6253  acc: 0.7031  time: 1.5094  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6333  acc: 0.6406  time: 1.4813  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5297  acc: 0.6875  time: 1.4276  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:01 (1.4840 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07668352127075195 uauc: 0.6583690747581802
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003047466278076172 u-nDCG: 0.8522225066399101
rank_0 auc: 0.6793322037638095
Train: data epoch: [43]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5668  time: 0.4835  data: 0.0000  max mem: 28728
Train: data epoch: [43]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6600  time: 0.5045  data: 0.0000  max mem: 28728
Train: data epoch: [43] Total time: 0:00:24 (0.4980 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6309  acc: 0.5469  time: 1.0202  data: 0.0042  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.6888  acc: 0.5625  time: 1.4131  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6590  acc: 0.6562  time: 1.5011  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6789  acc: 0.5625  time: 1.5150  data: 0.0023  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6282  acc: 0.6719  time: 1.4984  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6278  acc: 0.5781  time: 1.4749  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4977  acc: 0.7500  time: 1.4187  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:00 (1.4745 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07867670059204102 uauc: 0.6533634712971579
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.002594470977783203 u-nDCG: 0.8511396446259394
rank_0 auc: 0.6782300048450425
Train: data epoch: [44]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.6458  time: 0.4930  data: 0.0000  max mem: 28728
Train: data epoch: [44]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6961  time: 0.5030  data: 0.0000  max mem: 28728
Train: data epoch: [44] Total time: 0:00:25 (0.5081 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6473  acc: 0.6406  time: 1.0200  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7530  acc: 0.5625  time: 1.4150  data: 0.0023  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7385  acc: 0.5469  time: 1.5069  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7491  acc: 0.6094  time: 1.5010  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6594  acc: 0.6406  time: 1.5154  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6484  acc: 0.6875  time: 1.4847  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4864  acc: 0.8125  time: 1.4286  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4784 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08100104331970215 uauc: 0.6612267538221627
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0032775402069091797 u-nDCG: 0.8532076776262497
rank_0 auc: 0.6740613825164791
Train: data epoch: [45]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.6569  time: 0.4866  data: 0.0000  max mem: 28728
Train: data epoch: [45]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.8849  time: 0.4939  data: 0.0000  max mem: 28728
Train: data epoch: [45] Total time: 0:00:24 (0.4985 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6225  acc: 0.6719  time: 1.0147  data: 0.0047  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7243  acc: 0.6094  time: 1.4141  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.7121  acc: 0.5781  time: 1.4972  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7088  acc: 0.5625  time: 1.5003  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6453  acc: 0.6094  time: 1.4943  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6429  acc: 0.6094  time: 1.4818  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4658  acc: 0.7500  time: 1.4288  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:00 (1.4738 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07399392127990723 uauc: 0.6510652928485355
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030448436737060547 u-nDCG: 0.85314909222012
rank_0 auc: 0.6754500818816642
Train: data epoch: [46]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5139  time: 0.4902  data: 0.0000  max mem: 28728
Train: data epoch: [46]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6256  time: 0.5047  data: 0.0000  max mem: 28728
Train: data epoch: [46] Total time: 0:00:25 (0.5036 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6233  acc: 0.6094  time: 1.0211  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6899  acc: 0.5781  time: 1.4315  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6756  acc: 0.6250  time: 1.5088  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6811  acc: 0.5625  time: 1.5063  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6221  acc: 0.7031  time: 1.5197  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6450  acc: 0.6094  time: 1.4916  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5395  acc: 0.6875  time: 1.4369  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4838 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0735635757446289 uauc: 0.6443739298172558
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0017254352569580078 u-nDCG: 0.849993974208743
rank_0 auc: 0.6792430389449062
Train: data epoch: [47]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.8087  time: 0.4882  data: 0.0000  max mem: 28728
Train: data epoch: [47]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5348  time: 0.5092  data: 0.0001  max mem: 28728
Train: data epoch: [47] Total time: 0:00:25 (0.5016 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6248  acc: 0.5625  time: 1.0278  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6913  acc: 0.5625  time: 1.4264  data: 0.0030  max mem: 28728
2025-11-12 23:34:33,458 [INFO] Averaged stats: lr: 0.000100  loss: 0.611646
2025-11-12 23:34:33,460 [INFO] Evaluating on valid.
2025-11-12 23:36:34,421 [INFO] Averaged stats: loss: 0.659117  acc: 0.632812 ***auc: 0.6769332172582108 ***uauc: 0.6635274256045331 ***u-nDCG: 0.8537810920137155
2025-11-12 23:36:34,427 [INFO] Start training
2025-11-12 23:36:34,433 [INFO] Start training epoch 54, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:36:59,469 [INFO] Averaged stats: lr: 0.000100  loss: 0.600072
2025-11-12 23:36:59,470 [INFO] Evaluating on valid.
2025-11-12 23:39:00,844 [INFO] Averaged stats: loss: 0.644980  acc: 0.613567 ***auc: 0.6785334325010443 ***uauc: 0.6685119087040932 ***u-nDCG: 0.8581869547675445
2025-11-12 23:39:00,850 [INFO] Start training
2025-11-12 23:39:00,858 [INFO] Start training epoch 55, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:39:25,911 [INFO] Averaged stats: lr: 0.000100  loss: 0.627828
2025-11-12 23:39:25,913 [INFO] Evaluating on valid.
2025-11-12 23:41:27,143 [INFO] Averaged stats: loss: 0.647469  acc: 0.614329 ***auc: 0.6732543703753638 ***uauc: 0.6435688116192122 ***u-nDCG: 0.8507779227513077
2025-11-12 23:41:27,150 [INFO] Start training
2025-11-12 23:41:27,156 [INFO] Start training epoch 56, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:41:52,245 [INFO] Averaged stats: lr: 0.000100  loss: 0.587004
2025-11-12 23:41:52,247 [INFO] Evaluating on valid.
2025-11-12 23:43:53,655 [INFO] Averaged stats: loss: 0.646618  acc: 0.619284 ***auc: 0.6801295644257764 ***uauc: 0.666180476357653 ***u-nDCG: 0.8561941579495205
2025-11-12 23:43:53,661 [INFO] Saving checkpoint at epoch 56 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-12 23:43:54,155 [INFO] Start training
2025-11-12 23:43:54,162 [INFO] Start training epoch 57, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:44:19,304 [INFO] Averaged stats: lr: 0.000100  loss: 0.601762
2025-11-12 23:44:19,306 [INFO] Evaluating on valid.
2025-11-12 23:46:20,540 [INFO] Averaged stats: loss: 0.647214  acc: 0.619855 ***auc: 0.6791618180357636 ***uauc: 0.6532663943816143 ***u-nDCG: 0.8520200484999833
2025-11-12 23:46:20,548 [INFO] Start training
2025-11-12 23:46:20,554 [INFO] Start training epoch 58, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:46:45,759 [INFO] Averaged stats: lr: 0.000100  loss: 0.610792
2025-11-12 23:46:45,762 [INFO] Evaluating on valid.
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6628  acc: 0.6250  time: 1.5111  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6552  acc: 0.5781  time: 1.4986  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6186  acc: 0.7031  time: 1.5096  data: 0.0030  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6430  acc: 0.5781  time: 1.4834  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5458  acc: 0.6875  time: 1.4278  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4794 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07921743392944336 uauc: 0.6483115625256114
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003049135208129883 u-nDCG: 0.8500833473588265
rank_0 auc: 0.6798001520182207
Train: data epoch: [48]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5872  time: 0.4911  data: 0.0000  max mem: 28728
Train: data epoch: [48]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6081  time: 0.4969  data: 0.0000  max mem: 28728
Train: data epoch: [48] Total time: 0:00:25 (0.5023 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6226  acc: 0.6250  time: 1.0073  data: 0.0051  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6881  acc: 0.6250  time: 1.4364  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6910  acc: 0.6094  time: 1.5139  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6778  acc: 0.6094  time: 1.5027  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6230  acc: 0.6719  time: 1.5180  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6395  acc: 0.6094  time: 1.4869  data: 0.0023  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5357  acc: 0.7500  time: 1.4310  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:01 (1.4849 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07654809951782227 uauc: 0.645888791837915
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003052949905395508 u-nDCG: 0.8471312513934506
rank_0 auc: 0.6798322988680003
Train: data epoch: [49]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5332  time: 0.4959  data: 0.0000  max mem: 28728
Train: data epoch: [49]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6527  time: 0.5043  data: 0.0000  max mem: 28728
Train: data epoch: [49] Total time: 0:00:25 (0.5006 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6228  acc: 0.6562  time: 1.0205  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7028  acc: 0.5938  time: 1.4413  data: 0.0031  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.7141  acc: 0.5781  time: 1.5138  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7071  acc: 0.5938  time: 1.4894  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6327  acc: 0.6719  time: 1.4996  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6362  acc: 0.6250  time: 1.4652  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5209  acc: 0.7500  time: 1.4126  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4758 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07668399810791016 uauc: 0.6516700168691234
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003036975860595703 u-nDCG: 0.8493272263784098
rank_0 auc: 0.6788832614991063
Train: data epoch: [50]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.4422  time: 0.4863  data: 0.0000  max mem: 28728
Train: data epoch: [50]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6655  time: 0.5040  data: 0.0000  max mem: 28728
Train: data epoch: [50] Total time: 0:00:25 (0.5035 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6205  acc: 0.6562  time: 1.0270  data: 0.0092  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7253  acc: 0.5938  time: 1.4360  data: 0.0033  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7398  acc: 0.5312  time: 1.5066  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7266  acc: 0.5625  time: 1.5105  data: 0.0030  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6528  acc: 0.6250  time: 1.5036  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6428  acc: 0.6250  time: 1.4704  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5043  acc: 0.7500  time: 1.4167  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4788 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07797098159790039 uauc: 0.6535837084023858
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003055572509765625 u-nDCG: 0.8537112410520437
rank_0 auc: 0.6745438822317604
Train: data epoch: [51]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.8152  time: 0.4694  data: 0.0000  max mem: 28728
Train: data epoch: [51]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6732  time: 0.4991  data: 0.0000  max mem: 28728
Train: data epoch: [51] Total time: 0:00:25 (0.5007 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6027  acc: 0.7031  time: 1.0226  data: 0.0051  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6978  acc: 0.6250  time: 1.4337  data: 0.0032  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7031  acc: 0.5938  time: 1.5184  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6911  acc: 0.6094  time: 1.5084  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6286  acc: 0.7031  time: 1.5130  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6479  acc: 0.6250  time: 1.4841  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5000  acc: 0.7500  time: 1.4287  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4859 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0807044506072998 uauc: 0.6608752962632619
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0045735836029052734 u-nDCG: 0.8547345371167795
rank_0 auc: 0.6779193757007531
Train: data epoch: [52]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.7338  time: 0.5169  data: 0.0000  max mem: 28728
Train: data epoch: [52]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.4893  time: 0.4949  data: 0.0000  max mem: 28728
Train: data epoch: [52] Total time: 0:00:24 (0.4976 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6170  acc: 0.5781  time: 1.0216  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.6864  acc: 0.6094  time: 1.4309  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6697  acc: 0.6562  time: 1.5119  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6617  acc: 0.5938  time: 1.5021  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6215  acc: 0.6875  time: 1.5087  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6551  acc: 0.6250  time: 1.4596  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5310  acc: 0.6875  time: 1.4028  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:00 (1.4753 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07996344566345215 uauc: 0.6586581927905825
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030579566955566406 u-nDCG: 0.8506314818880228
rank_0 auc: 0.6754575803385413
2025-11-12 23:48:47,614 [INFO] Averaged stats: loss: 0.647186  acc: 0.614901 ***auc: 0.6725835183323907 ***uauc: 0.6454747353352847 ***u-nDCG: 0.8482579973297718
2025-11-12 23:48:47,621 [INFO] Start training
2025-11-12 23:48:47,628 [INFO] Start training epoch 59, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:49:12,744 [INFO] Averaged stats: lr: 0.000100  loss: 0.598848
2025-11-12 23:49:12,746 [INFO] Evaluating on valid.
2025-11-12 23:51:14,268 [INFO] Averaged stats: loss: 0.646246  acc: 0.619855 ***auc: 0.6763360876675033 ***uauc: 0.6459050006186351 ***u-nDCG: 0.8470897028310458
2025-11-12 23:51:14,274 [INFO] Start training
2025-11-12 23:51:14,281 [INFO] Start training epoch 60, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:51:39,364 [INFO] Averaged stats: lr: 0.000100  loss: 0.626807
2025-11-12 23:51:39,365 [INFO] Evaluating on valid.
2025-11-12 23:53:40,761 [INFO] Averaged stats: loss: 0.646651  acc: 0.626905 ***auc: 0.6777792065266568 ***uauc: 0.6429237128196909 ***u-nDCG: 0.8443738948071013
2025-11-12 23:53:40,767 [INFO] Start training
2025-11-12 23:53:40,773 [INFO] Start training epoch 61, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:54:05,973 [INFO] Averaged stats: lr: 0.000100  loss: 0.627579
2025-11-12 23:54:05,975 [INFO] Evaluating on valid.
2025-11-12 23:56:07,279 [INFO] Averaged stats: loss: 0.639190  acc: 0.603087 ***auc: 0.6781588808679324 ***uauc: 0.6484481899007741 ***u-nDCG: 0.8482716797908176
2025-11-12 23:56:07,284 [INFO] Start training
2025-11-12 23:56:07,292 [INFO] Start training epoch 62, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:56:32,451 [INFO] Averaged stats: lr: 0.000100  loss: 0.614265
2025-11-12 23:56:32,453 [INFO] Evaluating on valid.
2025-11-12 23:58:33,742 [INFO] Averaged stats: loss: 0.649035  acc: 0.623476 ***auc: 0.6753663367395135 ***uauc: 0.6453940048448936 ***u-nDCG: 0.8479838154939044
2025-11-12 23:58:33,748 [INFO] Start training
2025-11-12 23:58:33,756 [INFO] Start training epoch 63, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-12 23:58:58,779 [INFO] Averaged stats: lr: 0.000100  loss: 0.617147
2025-11-12 23:58:58,781 [INFO] Evaluating on valid.
2025-11-13 00:01:00,481 [INFO] Averaged stats: loss: 0.644879  acc: 0.584604 ***auc: 0.6744937687823352 ***uauc: 0.6455710934291833 ***u-nDCG: 0.8506442479473191
2025-11-13 00:01:00,489 [INFO] Start training
2025-11-13 00:01:00,495 [INFO] Start training epoch 64, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:01:25,510 [INFO] Averaged stats: lr: 0.000100  loss: 0.607909
2025-11-13 00:01:25,512 [INFO] Evaluating on valid.
Train: data epoch: [53]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7204  time: 0.4756  data: 0.0000  max mem: 28728
Train: data epoch: [53]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5781  time: 0.4999  data: 0.0000  max mem: 28728
Train: data epoch: [53] Total time: 0:00:25 (0.5018 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6257  acc: 0.7031  time: 1.0192  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7351  acc: 0.5625  time: 1.4293  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7327  acc: 0.5781  time: 1.4995  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7100  acc: 0.6562  time: 1.4936  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6496  acc: 0.6875  time: 1.4976  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6642  acc: 0.5938  time: 1.4776  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5382  acc: 0.7500  time: 1.4254  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:00 (1.4740 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07917594909667969 uauc: 0.6635274256045331
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0048253536224365234 u-nDCG: 0.8537810920137155
rank_0 auc: 0.6769332172582108
Train: data epoch: [54]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.6509  time: 0.4661  data: 0.0000  max mem: 28728
Train: data epoch: [54]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6264  time: 0.5026  data: 0.0000  max mem: 28728
Train: data epoch: [54] Total time: 0:00:25 (0.5007 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6198  acc: 0.6562  time: 1.0221  data: 0.0071  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7137  acc: 0.5938  time: 1.4301  data: 0.0031  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6788  acc: 0.6094  time: 1.5154  data: 0.0023  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6903  acc: 0.6562  time: 1.5001  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6345  acc: 0.6562  time: 1.5110  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6408  acc: 0.6094  time: 1.4783  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4977  acc: 0.8125  time: 1.4241  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4791 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07685637474060059 uauc: 0.6685119087040932
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030918121337890625 u-nDCG: 0.8581869547675445
rank_0 auc: 0.6785334325010443
Train: data epoch: [55]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.4791  time: 0.4988  data: 0.0000  max mem: 28728
Train: data epoch: [55]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6552  time: 0.5009  data: 0.0000  max mem: 28728
Train: data epoch: [55] Total time: 0:00:25 (0.5011 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6313  acc: 0.6406  time: 1.0237  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7225  acc: 0.6094  time: 1.4372  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6782  acc: 0.6406  time: 1.5149  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6928  acc: 0.5938  time: 1.4965  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6535  acc: 0.5938  time: 1.4965  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6501  acc: 0.5625  time: 1.4855  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5455  acc: 0.8125  time: 1.4310  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4773 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07778358459472656 uauc: 0.6435688116192122
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003038644790649414 u-nDCG: 0.8507779227513077
rank_0 auc: 0.6732543703753638
Train: data epoch: [56]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5952  time: 0.4819  data: 0.0000  max mem: 28728
Train: data epoch: [56]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5453  time: 0.5016  data: 0.0000  max mem: 28728
Train: data epoch: [56] Total time: 0:00:25 (0.5018 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6193  acc: 0.6406  time: 1.0150  data: 0.0041  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7290  acc: 0.6250  time: 1.4269  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6842  acc: 0.6562  time: 1.5133  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6976  acc: 0.6406  time: 1.5098  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6357  acc: 0.6562  time: 1.5007  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6527  acc: 0.5781  time: 1.4691  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4900  acc: 0.8125  time: 1.4161  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4794 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07791304588317871 uauc: 0.666180476357653
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030739307403564453 u-nDCG: 0.8561941579495205
rank_0 auc: 0.6801295644257764
Train: data epoch: [57]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5822  time: 0.4986  data: 0.0000  max mem: 28728
Train: data epoch: [57]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5800  time: 0.4983  data: 0.0000  max mem: 28728
Train: data epoch: [57] Total time: 0:00:25 (0.5028 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6320  acc: 0.6406  time: 1.0222  data: 0.0060  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7384  acc: 0.5469  time: 1.4244  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6943  acc: 0.5938  time: 1.5108  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6844  acc: 0.6406  time: 1.4952  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6454  acc: 0.6562  time: 1.5013  data: 0.0025  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6607  acc: 0.6094  time: 1.4772  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4947  acc: 0.7500  time: 1.4216  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4774 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07654476165771484 uauc: 0.6532663943816143
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003061532974243164 u-nDCG: 0.8520200484999833
rank_0 auc: 0.6791618180357636
Train: data epoch: [58]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.4163  time: 0.4985  data: 0.0000  max mem: 28728
Train: data epoch: [58]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5406  time: 0.5102  data: 0.0000  max mem: 28728
Train: data epoch: [58] Total time: 0:00:25 (0.5041 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6206  acc: 0.6406  time: 1.0188  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.7136  acc: 0.5938  time: 1.4477  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6847  acc: 0.6562  time: 1.5153  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:51  loss: 0.6933  acc: 0.6094  time: 1.5107  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6436  acc: 0.6250  time: 1.5083  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6706  acc: 0.5938  time: 1.4793  data: 0.0025  max mem: 28728
2025-11-13 00:03:26,653 [INFO] Averaged stats: loss: 0.663085  acc: 0.568979 ***auc: 0.6765000143287343 ***uauc: 0.652970351928318 ***u-nDCG: 0.8557873280209524
2025-11-13 00:03:26,660 [INFO] Start training
2025-11-13 00:03:26,666 [INFO] Start training epoch 65, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:03:51,623 [INFO] Averaged stats: lr: 0.000100  loss: 0.626509
2025-11-13 00:03:51,625 [INFO] Evaluating on valid.
2025-11-13 00:05:52,811 [INFO] Averaged stats: loss: 0.660854  acc: 0.629573 ***auc: 0.6727673418890974 ***uauc: 0.647351262559991 ***u-nDCG: 0.8504111356197411
2025-11-13 00:05:52,820 [INFO] Start training
2025-11-13 00:05:52,826 [INFO] Start training epoch 66, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:06:17,762 [INFO] Averaged stats: lr: 0.000100  loss: 0.589996
2025-11-13 00:06:17,764 [INFO] Evaluating on valid.
2025-11-13 00:08:19,427 [INFO] Averaged stats: loss: 0.640452  acc: 0.607470 ***auc: 0.6804994388036085 ***uauc: 0.6524478835128227 ***u-nDCG: 0.8519781504636408
2025-11-13 00:08:19,435 [INFO] Saving checkpoint at epoch 66 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-13 00:08:19,925 [INFO] Start training
2025-11-13 00:08:19,931 [INFO] Start training epoch 67, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:08:44,860 [INFO] Averaged stats: lr: 0.000100  loss: 0.589895
2025-11-13 00:08:44,861 [INFO] Evaluating on valid.
2025-11-13 00:10:45,783 [INFO] Averaged stats: loss: 0.645523  acc: 0.586700 ***auc: 0.6793229977375448 ***uauc: 0.6446630351750224 ***u-nDCG: 0.8496563517960101
2025-11-13 00:10:45,790 [INFO] Start training
2025-11-13 00:10:45,796 [INFO] Start training epoch 68, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:11:10,861 [INFO] Averaged stats: lr: 0.000100  loss: 0.581599
2025-11-13 00:11:10,863 [INFO] Evaluating on valid.
2025-11-13 00:13:11,375 [INFO] Averaged stats: loss: 0.647992  acc: 0.618331 ***auc: 0.6799755862122829 ***uauc: 0.6478906680566515 ***u-nDCG: 0.8478372848278514
2025-11-13 00:13:11,383 [INFO] Start training
2025-11-13 00:13:11,389 [INFO] Start training epoch 69, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:13:36,290 [INFO] Averaged stats: lr: 0.000100  loss: 0.582007
2025-11-13 00:13:36,293 [INFO] Evaluating on valid.
2025-11-13 00:15:37,632 [INFO] Averaged stats: loss: 0.652480  acc: 0.630145 ***auc: 0.6809203917787809 ***uauc: 0.6534095827245786 ***u-nDCG: 0.8538196873540784
2025-11-13 00:15:37,638 [INFO] Saving checkpoint at epoch 69 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-13 00:15:38,113 [INFO] Start training
2025-11-13 00:15:38,119 [INFO] Start training epoch 70, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5030  acc: 0.7500  time: 1.4260  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:01 (1.4849 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07441115379333496 uauc: 0.6454747353352847
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003036022186279297 u-nDCG: 0.8482579973297718
rank_0 auc: 0.6725835183323907
Train: data epoch: [59]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.6329  time: 0.4671  data: 0.0000  max mem: 28728
Train: data epoch: [59]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5782  time: 0.5051  data: 0.0000  max mem: 28728
Train: data epoch: [59] Total time: 0:00:25 (0.5023 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6180  acc: 0.6250  time: 1.0215  data: 0.0059  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7216  acc: 0.5781  time: 1.4329  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6804  acc: 0.6562  time: 1.5107  data: 0.0025  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6946  acc: 0.6094  time: 1.5016  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6414  acc: 0.6406  time: 1.5055  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6612  acc: 0.6250  time: 1.4827  data: 0.0029  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4911  acc: 0.8125  time: 1.4277  data: 0.0028  max mem: 28728
Evaluation Total time: 0:02:01 (1.4808 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0794062614440918 uauc: 0.6459050006186351
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0031824111938476562 u-nDCG: 0.8470897028310458
rank_0 auc: 0.6763360876675033
Train: data epoch: [60]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.5623  time: 0.4733  data: 0.0000  max mem: 28728
Train: data epoch: [60]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5241  time: 0.5043  data: 0.0000  max mem: 28728
Train: data epoch: [60] Total time: 0:00:25 (0.5017 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6272  acc: 0.6406  time: 1.0246  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7218  acc: 0.5781  time: 1.4193  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6972  acc: 0.5781  time: 1.5114  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6909  acc: 0.6406  time: 1.5117  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6580  acc: 0.6250  time: 1.5046  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6567  acc: 0.6094  time: 1.4801  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5194  acc: 0.7500  time: 1.4253  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4793 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07932424545288086 uauc: 0.6429237128196909
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003071308135986328 u-nDCG: 0.8443738948071013
rank_0 auc: 0.6777792065266568
Train: data epoch: [61]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.5651  time: 0.5038  data: 0.0000  max mem: 28728
Train: data epoch: [61]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6035  time: 0.4990  data: 0.0000  max mem: 28728
Train: data epoch: [61] Total time: 0:00:25 (0.5040 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6208  acc: 0.6406  time: 1.0084  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7084  acc: 0.5625  time: 1.4303  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6662  acc: 0.6250  time: 1.5060  data: 0.0024  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6615  acc: 0.6094  time: 1.5104  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6497  acc: 0.6562  time: 1.5032  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6473  acc: 0.5938  time: 1.4657  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5299  acc: 0.8125  time: 1.4135  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:01 (1.4782 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0776216983795166 uauc: 0.6484481899007741
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003033876419067383 u-nDCG: 0.8482716797908176
rank_0 auc: 0.6781588808679324
Train: data epoch: [62]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5486  time: 0.4992  data: 0.0000  max mem: 28728
Train: data epoch: [62]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6809  time: 0.5080  data: 0.0000  max mem: 28728
Train: data epoch: [62] Total time: 0:00:25 (0.5032 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6184  acc: 0.6562  time: 1.0207  data: 0.0041  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7135  acc: 0.5469  time: 1.4276  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7094  acc: 0.5625  time: 1.5010  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7033  acc: 0.6250  time: 1.4959  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6709  acc: 0.6250  time: 1.5200  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6504  acc: 0.5781  time: 1.4715  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5471  acc: 0.6875  time: 1.4191  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4781 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07409477233886719 uauc: 0.6453940048448936
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030434131622314453 u-nDCG: 0.8479838154939044
rank_0 auc: 0.6753663367395135
Train: data epoch: [63]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.7229  time: 0.4878  data: 0.0000  max mem: 28728
Train: data epoch: [63]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.4243  time: 0.5025  data: 0.0000  max mem: 28728
Train: data epoch: [63] Total time: 0:00:25 (0.5005 s / it)
Evaluation  [ 0/82]  eta: 0:01:24  loss: 0.6090  acc: 0.5625  time: 1.0247  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:35  loss: 0.6975  acc: 0.5469  time: 1.4421  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:14  loss: 0.6555  acc: 0.6094  time: 1.5129  data: 0.0031  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6709  acc: 0.5938  time: 1.5057  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6431  acc: 0.6406  time: 1.5040  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6449  acc: 0.5312  time: 1.4752  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5414  acc: 0.7500  time: 1.4191  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4831 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07750082015991211 uauc: 0.6455710934291833
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030517578125 u-nDCG: 0.8506442479473191
rank_0 auc: 0.6744937687823352
Train: data epoch: [64]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.7415  time: 0.5014  data: 0.0000  max mem: 28728
Train: data epoch: [64]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7497  time: 0.5056  data: 0.0000  max mem: 28728
Train: data epoch: [64] Total time: 0:00:25 (0.5003 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6401  acc: 0.5312  time: 1.0205  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7215  acc: 0.5781  time: 1.4274  data: 0.0028  max mem: 28728
2025-11-13 00:16:03,021 [INFO] Averaged stats: lr: 0.000100  loss: 0.601990
2025-11-13 00:16:03,023 [INFO] Evaluating on valid.
2025-11-13 00:18:04,244 [INFO] Averaged stats: loss: 0.643078  acc: 0.626143 ***auc: 0.6814855972461509 ***uauc: 0.6525395005426905 ***u-nDCG: 0.8526158031492542
2025-11-13 00:18:04,257 [INFO] Saving checkpoint at epoch 70 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-13 00:18:04,748 [INFO] Start training
2025-11-13 00:18:04,754 [INFO] Start training epoch 71, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:18:29,773 [INFO] Averaged stats: lr: 0.000100  loss: 0.588310
2025-11-13 00:18:29,774 [INFO] Evaluating on valid.
2025-11-13 00:20:30,251 [INFO] Averaged stats: loss: 0.642678  acc: 0.630716 ***auc: 0.6852228726989203 ***uauc: 0.657100536837365 ***u-nDCG: 0.8549647420553866
2025-11-13 00:20:30,257 [INFO] Saving checkpoint at epoch 71 to D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\Qwen\Qwen2.5-1.5rec_log\collm\20251112212\checkpoint_best.pth.
2025-11-13 00:20:30,720 [INFO] Start training
2025-11-13 00:20:30,728 [INFO] Start training epoch 72, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:20:56,050 [INFO] Averaged stats: lr: 0.000100  loss: 0.607495
2025-11-13 00:20:56,052 [INFO] Evaluating on valid.
2025-11-13 00:22:56,738 [INFO] Averaged stats: loss: 0.641195  acc: 0.614520 ***auc: 0.6798435836743895 ***uauc: 0.6556489957431146 ***u-nDCG: 0.8541621683223973
2025-11-13 00:22:56,744 [INFO] Start training
2025-11-13 00:22:56,752 [INFO] Start training epoch 73, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:23:21,670 [INFO] Averaged stats: lr: 0.000100  loss: 0.604761
2025-11-13 00:23:21,671 [INFO] Evaluating on valid.
2025-11-13 00:25:22,534 [INFO] Averaged stats: loss: 0.644255  acc: 0.622523 ***auc: 0.6780856038685504 ***uauc: 0.6441418874406878 ***u-nDCG: 0.849367505538801
2025-11-13 00:25:22,541 [INFO] Start training
2025-11-13 00:25:22,548 [INFO] Start training epoch 74, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:25:47,623 [INFO] Averaged stats: lr: 0.000100  loss: 0.562455
2025-11-13 00:25:47,624 [INFO] Evaluating on valid.
2025-11-13 00:27:49,189 [INFO] Averaged stats: loss: 0.661101  acc: 0.637957 ***auc: 0.6802147201687256 ***uauc: 0.6550943220401664 ***u-nDCG: 0.8555974008327654
2025-11-13 00:27:49,197 [INFO] Start training
2025-11-13 00:27:49,203 [INFO] Start training epoch 75, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:28:14,226 [INFO] Averaged stats: lr: 0.000100  loss: 0.602091
2025-11-13 00:28:14,228 [INFO] Evaluating on valid.
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6358  acc: 0.6094  time: 1.5066  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6741  acc: 0.5781  time: 1.4909  data: 0.0030  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6409  acc: 0.6406  time: 1.5009  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6714  acc: 0.5469  time: 1.4755  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5423  acc: 0.6875  time: 1.4217  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4761 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08398246765136719 uauc: 0.652970351928318
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030219554901123047 u-nDCG: 0.8557873280209524
rank_0 auc: 0.6765000143287343
Train: data epoch: [65]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.8159  time: 0.4894  data: 0.0000  max mem: 28728
Train: data epoch: [65]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.9448  time: 0.5019  data: 0.0000  max mem: 28728
Train: data epoch: [65] Total time: 0:00:24 (0.4991 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6236  acc: 0.6875  time: 1.0152  data: 0.0048  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7329  acc: 0.5625  time: 1.4207  data: 0.0031  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7256  acc: 0.5625  time: 1.5091  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7356  acc: 0.6406  time: 1.5024  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6653  acc: 0.6250  time: 1.5177  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6661  acc: 0.5938  time: 1.4683  data: 0.0029  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5405  acc: 0.7500  time: 1.4125  data: 0.0028  max mem: 28728
Evaluation Total time: 0:02:01 (1.4767 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07915544509887695 uauc: 0.647351262559991
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003030538558959961 u-nDCG: 0.8504111356197411
rank_0 auc: 0.6727673418890974
Train: data epoch: [66]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.4593  time: 0.5001  data: 0.0000  max mem: 28728
Train: data epoch: [66]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6040  time: 0.4999  data: 0.0000  max mem: 28728
Train: data epoch: [66] Total time: 0:00:24 (0.4987 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6192  acc: 0.6406  time: 1.0103  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7069  acc: 0.5781  time: 1.4357  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6606  acc: 0.5625  time: 1.5112  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6764  acc: 0.6250  time: 1.5066  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6512  acc: 0.6719  time: 1.5051  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6559  acc: 0.5781  time: 1.4771  data: 0.0023  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5181  acc: 0.6875  time: 1.4243  data: 0.0021  max mem: 28728
Evaluation Total time: 0:02:01 (1.4824 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08786654472351074 uauc: 0.6524478835128227
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.001508474349975586 u-nDCG: 0.8519781504636408
rank_0 auc: 0.6804994388036085
Train: data epoch: [67]  [ 0/50]  eta: 0:00:22  lr: 0.000100  loss: 0.5299  time: 0.4591  data: 0.0000  max mem: 28728
Train: data epoch: [67]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.4081  time: 0.4989  data: 0.0000  max mem: 28728
Train: data epoch: [67] Total time: 0:00:24 (0.4986 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6238  acc: 0.6094  time: 1.0128  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7116  acc: 0.5781  time: 1.4278  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6416  acc: 0.5781  time: 1.5190  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6696  acc: 0.5938  time: 1.5004  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6406  acc: 0.6250  time: 1.4815  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6515  acc: 0.5625  time: 1.4794  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5178  acc: 0.6875  time: 1.4278  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:00 (1.4736 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07692217826843262 uauc: 0.6446630351750224
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030412673950195312 u-nDCG: 0.8496563517960101
rank_0 auc: 0.6793229977375448
Train: data epoch: [68]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.7487  time: 0.4914  data: 0.0000  max mem: 28728
Train: data epoch: [68]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5936  time: 0.4980  data: 0.0000  max mem: 28728
Train: data epoch: [68] Total time: 0:00:25 (0.5013 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6251  acc: 0.6250  time: 1.0085  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7294  acc: 0.5469  time: 1.4253  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6557  acc: 0.5781  time: 1.4928  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6729  acc: 0.6562  time: 1.5027  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6432  acc: 0.6719  time: 1.4970  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6534  acc: 0.6094  time: 1.4700  data: 0.0030  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4828  acc: 0.8125  time: 1.4149  data: 0.0028  max mem: 28728
Evaluation Total time: 0:02:00 (1.4686 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07547211647033691 uauc: 0.6478906680566515
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003072500228881836 u-nDCG: 0.8478372848278514
rank_0 auc: 0.6799755862122829
Train: data epoch: [69]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5678  time: 0.4877  data: 0.0000  max mem: 28728
Train: data epoch: [69]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5335  time: 0.4963  data: 0.0000  max mem: 28728
Train: data epoch: [69] Total time: 0:00:24 (0.4980 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6290  acc: 0.6562  time: 1.0082  data: 0.0051  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7518  acc: 0.5781  time: 1.4188  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6963  acc: 0.6250  time: 1.5040  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6872  acc: 0.6875  time: 1.5140  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6613  acc: 0.6406  time: 1.5122  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6564  acc: 0.6094  time: 1.4834  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4832  acc: 0.7500  time: 1.4278  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4786 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07867288589477539 uauc: 0.6534095827245786
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003021717071533203 u-nDCG: 0.8538196873540784
rank_0 auc: 0.6809203917787809
2025-11-13 00:30:15,386 [INFO] Averaged stats: loss: 0.650096  acc: 0.571265 ***auc: 0.6790704259524414 ***uauc: 0.6475460816022155 ***u-nDCG: 0.8515096812106765
2025-11-13 00:30:15,392 [INFO] Start training
2025-11-13 00:30:15,399 [INFO] Start training epoch 76, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:30:40,547 [INFO] Averaged stats: lr: 0.000100  loss: 0.626073
2025-11-13 00:30:40,548 [INFO] Evaluating on valid.
2025-11-13 00:32:41,213 [INFO] Averaged stats: loss: 0.657408  acc: 0.638529 ***auc: 0.6776794250806901 ***uauc: 0.6498557992973016 ***u-nDCG: 0.8526213687826673
2025-11-13 00:32:41,219 [INFO] Start training
2025-11-13 00:32:41,225 [INFO] Start training epoch 77, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:33:06,225 [INFO] Averaged stats: lr: 0.000100  loss: 0.612832
2025-11-13 00:33:06,225 [INFO] Evaluating on valid.
2025-11-13 00:35:07,977 [INFO] Averaged stats: loss: 0.640960  acc: 0.594512 ***auc: 0.6791466726377151 ***uauc: 0.6515654808145455 ***u-nDCG: 0.8543797843736205
2025-11-13 00:35:07,984 [INFO] Start training
2025-11-13 00:35:07,990 [INFO] Start training epoch 78, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:35:32,765 [INFO] Averaged stats: lr: 0.000100  loss: 0.593588
2025-11-13 00:35:32,767 [INFO] Evaluating on valid.
2025-11-13 00:37:33,266 [INFO] Averaged stats: loss: 0.643819  acc: 0.601372 ***auc: 0.6798849365504337 ***uauc: 0.6497543328390993 ***u-nDCG: 0.8522577394248437
2025-11-13 00:37:33,273 [INFO] Start training
2025-11-13 00:37:33,279 [INFO] Start training epoch 79, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:37:58,275 [INFO] Averaged stats: lr: 0.000100  loss: 0.606859
2025-11-13 00:37:58,276 [INFO] Evaluating on valid.
2025-11-13 00:39:59,146 [INFO] Averaged stats: loss: 0.649725  acc: 0.579840 ***auc: 0.6786428654261596 ***uauc: 0.6541971725138601 ***u-nDCG: 0.855478057821144
2025-11-13 00:39:59,153 [INFO] Start training
2025-11-13 00:39:59,160 [INFO] Start training epoch 80, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:40:24,069 [INFO] Averaged stats: lr: 0.000100  loss: 0.605185
2025-11-13 00:40:24,071 [INFO] Evaluating on valid.
2025-11-13 00:42:25,321 [INFO] Averaged stats: loss: 0.655294  acc: 0.633003 ***auc: 0.6763037180912819 ***uauc: 0.6546167351181655 ***u-nDCG: 0.855209325434777
2025-11-13 00:42:25,327 [INFO] Start training
2025-11-13 00:42:25,333 [INFO] Start training epoch 81, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:42:50,327 [INFO] Averaged stats: lr: 0.000100  loss: 0.603766
2025-11-13 00:42:50,327 [INFO] Evaluating on valid.
Train: data epoch: [70]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.7132  time: 0.4915  data: 0.0000  max mem: 28728
Train: data epoch: [70]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7199  time: 0.4980  data: 0.0000  max mem: 28728
Train: data epoch: [70] Total time: 0:00:24 (0.4980 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6130  acc: 0.6719  time: 1.0171  data: 0.0035  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7225  acc: 0.5938  time: 1.4229  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6890  acc: 0.5625  time: 1.5178  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6924  acc: 0.5625  time: 1.5078  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6629  acc: 0.6406  time: 1.5017  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6453  acc: 0.6094  time: 1.4659  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4766  acc: 0.8125  time: 1.4134  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4772 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07938241958618164 uauc: 0.6525395005426905
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030362606048583984 u-nDCG: 0.8526158031492542
rank_0 auc: 0.6814855972461509
Train: data epoch: [71]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.5533  time: 0.4639  data: 0.0000  max mem: 28728
Train: data epoch: [71]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6355  time: 0.5037  data: 0.0000  max mem: 28728
Train: data epoch: [71] Total time: 0:00:25 (0.5004 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6151  acc: 0.6719  time: 1.0097  data: 0.0057  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7361  acc: 0.5469  time: 1.4195  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6968  acc: 0.5938  time: 1.5028  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6856  acc: 0.6406  time: 1.4993  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6674  acc: 0.6094  time: 1.4926  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6445  acc: 0.6406  time: 1.4665  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4739  acc: 0.8125  time: 1.4133  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:00 (1.4681 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07886767387390137 uauc: 0.657100536837365
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030469894409179688 u-nDCG: 0.8549647420553866
rank_0 auc: 0.6852228726989203
Train: data epoch: [72]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.6719  time: 0.5111  data: 0.0000  max mem: 28728
Train: data epoch: [72]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5186  time: 0.5090  data: 0.0000  max mem: 28728
Train: data epoch: [72] Total time: 0:00:25 (0.5064 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.5990  acc: 0.6719  time: 1.0032  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7369  acc: 0.5312  time: 1.4147  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6782  acc: 0.5625  time: 1.4981  data: 0.0031  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6667  acc: 0.5625  time: 1.4884  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6652  acc: 0.6406  time: 1.5020  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6444  acc: 0.5781  time: 1.4790  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4787  acc: 0.8125  time: 1.4263  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:00 (1.4707 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07520818710327148 uauc: 0.6556489957431146
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0042917728424072266 u-nDCG: 0.8541621683223973
rank_0 auc: 0.6798435836743895
Train: data epoch: [73]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.6544  time: 0.4812  data: 0.0000  max mem: 28728
Train: data epoch: [73]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6948  time: 0.5006  data: 0.0000  max mem: 28728
Train: data epoch: [73] Total time: 0:00:24 (0.4984 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.5925  acc: 0.6719  time: 1.0112  data: 0.0058  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7294  acc: 0.5156  time: 1.4158  data: 0.0031  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6853  acc: 0.5938  time: 1.4944  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6928  acc: 0.5938  time: 1.4947  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6752  acc: 0.6406  time: 1.5106  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6451  acc: 0.5938  time: 1.4797  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4893  acc: 0.8125  time: 1.4241  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:00 (1.4728 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07649898529052734 uauc: 0.6441418874406878
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003090381622314453 u-nDCG: 0.849367505538801
rank_0 auc: 0.6780856038685504
Train: data epoch: [74]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.5397  time: 0.5147  data: 0.0000  max mem: 28728
Train: data epoch: [74]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.3768  time: 0.4992  data: 0.0000  max mem: 28728
Train: data epoch: [74] Total time: 0:00:25 (0.5015 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6040  acc: 0.7031  time: 1.0078  data: 0.0056  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7757  acc: 0.5469  time: 1.4279  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7248  acc: 0.5469  time: 1.5059  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7411  acc: 0.6250  time: 1.5092  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6985  acc: 0.6406  time: 1.5113  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6597  acc: 0.6406  time: 1.4848  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4613  acc: 0.8125  time: 1.4275  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:01 (1.4814 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07870626449584961 uauc: 0.6550943220401664
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.002034902572631836 u-nDCG: 0.8555974008327654
rank_0 auc: 0.6802147201687256
Train: data epoch: [75]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.6250  time: 0.4889  data: 0.0000  max mem: 28728
Train: data epoch: [75]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.4935  time: 0.5011  data: 0.0000  max mem: 28728
Train: data epoch: [75] Total time: 0:00:25 (0.5005 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.5996  acc: 0.5625  time: 1.0069  data: 0.0047  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7432  acc: 0.5156  time: 1.4205  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6568  acc: 0.6094  time: 1.5135  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6573  acc: 0.6250  time: 1.5026  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6674  acc: 0.6250  time: 1.5157  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6551  acc: 0.5469  time: 1.4729  data: 0.0028  max mem: 28728
2025-11-13 00:44:51,552 [INFO] Averaged stats: loss: 0.664252  acc: 0.637005 ***auc: 0.6789392400781682 ***uauc: 0.6628422171754824 ***u-nDCG: 0.8590406763746108
2025-11-13 00:44:51,559 [INFO] Start training
2025-11-13 00:44:51,565 [INFO] Start training epoch 82, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:45:16,660 [INFO] Averaged stats: lr: 0.000100  loss: 0.608883
2025-11-13 00:45:16,661 [INFO] Evaluating on valid.
2025-11-13 00:47:17,124 [INFO] Averaged stats: loss: 0.646220  acc: 0.623857 ***auc: 0.6783542119574699 ***uauc: 0.6595802492604056 ***u-nDCG: 0.8589113058855108
2025-11-13 00:47:17,130 [INFO] Start training
2025-11-13 00:47:17,136 [INFO] Start training epoch 83, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:47:42,212 [INFO] Averaged stats: lr: 0.000100  loss: 0.582679
2025-11-13 00:47:42,213 [INFO] Evaluating on valid.
2025-11-13 00:49:43,846 [INFO] Averaged stats: loss: 0.654108  acc: 0.636623 ***auc: 0.6823998150479627 ***uauc: 0.6676504669749894 ***u-nDCG: 0.8608790714045756
2025-11-13 00:49:43,853 [INFO] Start training
2025-11-13 00:49:43,859 [INFO] Start training epoch 84, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:50:11,221 [INFO] Averaged stats: lr: 0.000100  loss: 0.601539
2025-11-13 00:50:11,223 [INFO] Evaluating on valid.
2025-11-13 00:52:11,878 [INFO] Averaged stats: loss: 0.662657  acc: 0.638529 ***auc: 0.6794331730841332 ***uauc: 0.6673825554186024 ***u-nDCG: 0.8607899861184072
2025-11-13 00:52:11,884 [INFO] Start training
2025-11-13 00:52:11,890 [INFO] Start training epoch 85, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:52:36,900 [INFO] Averaged stats: lr: 0.000100  loss: 0.515969
2025-11-13 00:52:36,902 [INFO] Evaluating on valid.
2025-11-13 00:54:38,763 [INFO] Averaged stats: loss: 0.674953  acc: 0.639291 ***auc: 0.6819735166381848 ***uauc: 0.6665708957113033 ***u-nDCG: 0.8635363305096306
2025-11-13 00:54:38,770 [INFO] Start training
2025-11-13 00:54:38,776 [INFO] Start training epoch 86, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:55:03,573 [INFO] Averaged stats: lr: 0.000100  loss: 0.586781
2025-11-13 00:55:03,574 [INFO] Evaluating on valid.
2025-11-13 00:57:04,291 [INFO] Averaged stats: loss: 0.654043  acc: 0.603659 ***auc: 0.6717200079171826 ***uauc: 0.6593406034926912 ***u-nDCG: 0.8603109991589136
2025-11-13 00:57:04,297 [INFO] Start training
2025-11-13 00:57:04,303 [INFO] Start training epoch 87, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4996  acc: 0.7500  time: 1.4166  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4764 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07931017875671387 uauc: 0.6475460816022155
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030150413513183594 u-nDCG: 0.8515096812106765
rank_0 auc: 0.6790704259524414
Train: data epoch: [76]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.5223  time: 0.4718  data: 0.0000  max mem: 28728
Train: data epoch: [76]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.4500  time: 0.5006  data: 0.0000  max mem: 28728
Train: data epoch: [76] Total time: 0:00:25 (0.5030 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6137  acc: 0.7344  time: 1.0127  data: 0.0041  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7558  acc: 0.5312  time: 1.4225  data: 0.0023  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7307  acc: 0.5625  time: 1.4980  data: 0.0023  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7125  acc: 0.6562  time: 1.4924  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6780  acc: 0.6250  time: 1.5096  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6561  acc: 0.6406  time: 1.4645  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5281  acc: 0.7500  time: 1.4112  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:00 (1.4704 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07966017723083496 uauc: 0.6498557992973016
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003175973892211914 u-nDCG: 0.8526213687826673
rank_0 auc: 0.6776794250806901
Train: data epoch: [77]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.6954  time: 0.5064  data: 0.0000  max mem: 28728
Train: data epoch: [77]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7178  time: 0.4966  data: 0.0000  max mem: 28728
Train: data epoch: [77] Total time: 0:00:25 (0.5000 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6107  acc: 0.5781  time: 1.0121  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7267  acc: 0.5312  time: 1.4189  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6604  acc: 0.6250  time: 1.5202  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6524  acc: 0.6250  time: 1.5108  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6515  acc: 0.6719  time: 1.5198  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6454  acc: 0.5469  time: 1.4886  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4918  acc: 0.7500  time: 1.4329  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4836 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07846713066101074 uauc: 0.6515654808145455
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.004628181457519531 u-nDCG: 0.8543797843736205
rank_0 auc: 0.6791466726377151
Train: data epoch: [78]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.5959  time: 0.4702  data: 0.0000  max mem: 28728
Train: data epoch: [78]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5753  time: 0.5000  data: 0.0000  max mem: 28728
Train: data epoch: [78] Total time: 0:00:24 (0.4955 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6061  acc: 0.5938  time: 1.0113  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7135  acc: 0.5312  time: 1.4181  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6683  acc: 0.6094  time: 1.4942  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6551  acc: 0.6250  time: 1.5033  data: 0.0030  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6576  acc: 0.6562  time: 1.4892  data: 0.0026  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6471  acc: 0.5781  time: 1.4580  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4802  acc: 0.8125  time: 1.4053  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:00 (1.4684 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07814550399780273 uauc: 0.6497543328390993
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0020284652709960938 u-nDCG: 0.8522577394248437
rank_0 auc: 0.6798849365504337
Train: data epoch: [79]  [ 0/50]  eta: 0:00:22  lr: 0.000100  loss: 0.4961  time: 0.4580  data: 0.0000  max mem: 28728
Train: data epoch: [79]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6109  time: 0.5046  data: 0.0000  max mem: 28728
Train: data epoch: [79] Total time: 0:00:24 (0.4999 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6237  acc: 0.5781  time: 1.0106  data: 0.0056  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7118  acc: 0.5312  time: 1.4165  data: 0.0027  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6562  acc: 0.6250  time: 1.5199  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6467  acc: 0.6250  time: 1.5042  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6535  acc: 0.6094  time: 1.5096  data: 0.0022  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6550  acc: 0.5312  time: 1.4550  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5044  acc: 0.7500  time: 1.4013  data: 0.0023  max mem: 28728
Evaluation Total time: 0:02:00 (1.4729 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07907390594482422 uauc: 0.6541971725138601
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0022101402282714844 u-nDCG: 0.855478057821144
rank_0 auc: 0.6786428654261596
Train: data epoch: [80]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7925  time: 0.4616  data: 0.0000  max mem: 28728
Train: data epoch: [80]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6067  time: 0.4989  data: 0.0000  max mem: 28728
Train: data epoch: [80] Total time: 0:00:24 (0.4982 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6006  acc: 0.7188  time: 1.0115  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7218  acc: 0.5938  time: 1.4183  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7250  acc: 0.5625  time: 1.5086  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7132  acc: 0.6562  time: 1.5187  data: 0.0024  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6692  acc: 0.6562  time: 1.5076  data: 0.0023  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6532  acc: 0.5938  time: 1.4695  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4813  acc: 0.8750  time: 1.4131  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4775 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07922005653381348 uauc: 0.6546167351181655
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003034830093383789 u-nDCG: 0.855209325434777
rank_0 auc: 0.6763037180912819
Train: data epoch: [81]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7945  time: 0.4624  data: 0.0000  max mem: 28728
Train: data epoch: [81]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.4008  time: 0.4967  data: 0.0000  max mem: 28728
Train: data epoch: [81] Total time: 0:00:24 (0.4999 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6155  acc: 0.7031  time: 1.0031  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7389  acc: 0.5781  time: 1.4259  data: 0.0024  max mem: 28728
2025-11-13 00:57:29,330 [INFO] Averaged stats: lr: 0.000100  loss: 0.547619
2025-11-13 00:57:29,331 [INFO] Evaluating on valid.
2025-11-13 00:59:30,193 [INFO] Averaged stats: loss: 0.742955  acc: 0.618902 ***auc: 0.6626295766757306 ***uauc: 0.6499820242565835 ***u-nDCG: 0.8557981037695963
2025-11-13 00:59:30,199 [INFO] Start training
2025-11-13 00:59:30,205 [INFO] Start training epoch 88, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 00:59:55,172 [INFO] Averaged stats: lr: 0.000100  loss: 0.599663
2025-11-13 00:59:55,174 [INFO] Evaluating on valid.
2025-11-13 01:01:56,153 [INFO] Averaged stats: loss: 0.657962  acc: 0.579078 ***auc: 0.6602977050712879 ***uauc: 0.6594580520661861 ***u-nDCG: 0.8606040922683557
2025-11-13 01:01:56,159 [INFO] Start training
2025-11-13 01:01:56,165 [INFO] Start training epoch 89, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 01:02:21,512 [INFO] Averaged stats: lr: 0.000100  loss: 0.576328
2025-11-13 01:02:21,513 [INFO] Evaluating on valid.
2025-11-13 01:04:22,110 [INFO] Averaged stats: loss: 0.659064  acc: 0.612614 ***auc: 0.6678121982520726 ***uauc: 0.6790466972378064 ***u-nDCG: 0.8664346850078342
2025-11-13 01:04:22,117 [INFO] Start training
2025-11-13 01:04:22,124 [INFO] Start training epoch 90, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 01:04:47,016 [INFO] Averaged stats: lr: 0.000100  loss: 0.593670
2025-11-13 01:04:47,017 [INFO] Evaluating on valid.
2025-11-13 01:06:48,350 [INFO] Averaged stats: loss: 0.654393  acc: 0.581364 ***auc: 0.672059146046034 ***uauc: 0.6627969065311574 ***u-nDCG: 0.8597161044103949
2025-11-13 01:06:48,356 [INFO] Start training
2025-11-13 01:06:48,362 [INFO] Start training epoch 91, 50 iters per inner epoch.
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\tasks\base_task.py:219: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  with torch.cuda.amp.autocast(enabled=use_amp):
D:\Pycoding\CoLLM-main\CoLLM-main\minigpt4\models\rec_model.py:48: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.
  return torch.cuda.amp.autocast(dtype=dtype)
2025-11-13 01:07:13,321 [INFO] Averaged stats: lr: 0.000100  loss: 0.573979
2025-11-13 01:07:13,322 [INFO] Evaluating on valid.
2025-11-13 01:09:13,883 [INFO] Averaged stats: loss: 0.657606  acc: 0.626905 ***auc: 0.6744312568943114 ***uauc: 0.6645784687349322 ***u-nDCG: 0.8605971297670348
2025-11-13 01:09:13,886 [INFO] Early stop. The results has not changed up to 20 epochs.
2025-11-13 01:09:13,886 [INFO] Training time 3:45:21
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7388  acc: 0.5938  time: 1.5015  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7156  acc: 0.6562  time: 1.4997  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6830  acc: 0.6406  time: 1.5084  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6710  acc: 0.5938  time: 1.4778  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5034  acc: 0.8125  time: 1.4255  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4772 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07819509506225586 uauc: 0.6628422171754824
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.001504659652709961 u-nDCG: 0.8590406763746108
rank_0 auc: 0.6789392400781682
Train: data epoch: [82]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.6377  time: 0.5002  data: 0.0000  max mem: 28728
Train: data epoch: [82]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5581  time: 0.4993  data: 0.0000  max mem: 28728
Train: data epoch: [82] Total time: 0:00:25 (0.5019 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6029  acc: 0.6406  time: 1.0068  data: 0.0047  max mem: 28728
Evaluation  [16/82]  eta: 0:01:32  loss: 0.7287  acc: 0.5312  time: 1.4044  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6850  acc: 0.5938  time: 1.4999  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6767  acc: 0.6250  time: 1.4818  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6741  acc: 0.6406  time: 1.5003  data: 0.0030  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6510  acc: 0.6094  time: 1.4788  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4868  acc: 0.8125  time: 1.4227  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:00 (1.4679 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07937455177307129 uauc: 0.6595802492604056
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0030755996704101562 u-nDCG: 0.8589113058855108
rank_0 auc: 0.6783542119574699
Train: data epoch: [83]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.7988  time: 0.4713  data: 0.0000  max mem: 28728
Train: data epoch: [83]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.7240  time: 0.5027  data: 0.0000  max mem: 28728
Train: data epoch: [83] Total time: 0:00:25 (0.5015 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6252  acc: 0.6562  time: 1.0137  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7316  acc: 0.5469  time: 1.4143  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7175  acc: 0.5625  time: 1.5123  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6946  acc: 0.6562  time: 1.5147  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6919  acc: 0.5938  time: 1.5221  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6677  acc: 0.5938  time: 1.4827  data: 0.0027  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4816  acc: 0.8125  time: 1.4261  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:01 (1.4822 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07611751556396484 uauc: 0.6676504669749894
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.002540111541748047 u-nDCG: 0.8608790714045756
rank_0 auc: 0.6823998150479627
Train: data epoch: [84]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.6288  time: 0.4928  data: 0.0000  max mem: 28728
Train: data epoch: [84]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5249  time: 0.6095  data: 0.0000  max mem: 28728
Train: data epoch: [84] Total time: 0:00:27 (0.5472 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6213  acc: 0.6719  time: 1.0122  data: 0.0045  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7332  acc: 0.5781  time: 1.4231  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.7378  acc: 0.5625  time: 1.4830  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7181  acc: 0.6719  time: 1.5087  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6853  acc: 0.6406  time: 1.4927  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6621  acc: 0.5938  time: 1.4806  data: 0.0025  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4984  acc: 0.8750  time: 1.4252  data: 0.0024  max mem: 28728
Evaluation Total time: 0:02:00 (1.4703 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0783846378326416 uauc: 0.6673825554186024
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003041505813598633 u-nDCG: 0.8607899861184072
rank_0 auc: 0.6794331730841332
Train: data epoch: [85]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.4623  time: 0.4988  data: 0.0000  max mem: 28728
Train: data epoch: [85]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.4460  time: 0.4955  data: 0.0000  max mem: 28728
Train: data epoch: [85] Total time: 0:00:25 (0.5002 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6223  acc: 0.6562  time: 1.0088  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7676  acc: 0.6094  time: 1.4373  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7271  acc: 0.6250  time: 1.5134  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7215  acc: 0.6562  time: 1.5151  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6766  acc: 0.6875  time: 1.5172  data: 0.0028  max mem: 28728
Evaluation  [80/82]  eta: 0:00:03  loss: 0.6758  acc: 0.6406  time: 1.4820  data: 0.0029  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4901  acc: 0.8125  time: 1.4262  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:01 (1.4850 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07662224769592285 uauc: 0.6665708957113033
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003049135208129883 u-nDCG: 0.8635363305096306
rank_0 auc: 0.6819735166381848
Train: data epoch: [86]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.5437  time: 0.5020  data: 0.0000  max mem: 28728
Train: data epoch: [86]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5844  time: 0.4976  data: 0.0000  max mem: 28728
Train: data epoch: [86] Total time: 0:00:24 (0.4959 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.5958  acc: 0.6562  time: 1.0145  data: 0.0047  max mem: 28728
Evaluation  [16/82]  eta: 0:01:32  loss: 0.7126  acc: 0.5625  time: 1.4080  data: 0.0028  max mem: 28728
Evaluation  [32/82]  eta: 0:01:12  loss: 0.6794  acc: 0.5781  time: 1.4944  data: 0.0026  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6918  acc: 0.5781  time: 1.5050  data: 0.0029  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6348  acc: 0.6250  time: 1.5090  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6427  acc: 0.5781  time: 1.4677  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5217  acc: 0.7500  time: 1.4134  data: 0.0026  max mem: 28728
Evaluation Total time: 0:02:00 (1.4710 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.08028244972229004 uauc: 0.6593406034926912
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003278970718383789 u-nDCG: 0.8603109991589136
rank_0 auc: 0.6717200079171826
Train: data epoch: [87]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.6702  time: 0.4821  data: 0.0000  max mem: 28728
Train: data epoch: [87]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5811  time: 0.5002  data: 0.0000  max mem: 28728
Train: data epoch: [87] Total time: 0:00:25 (0.5005 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6545  acc: 0.7188  time: 1.0241  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:32  loss: 0.8255  acc: 0.5625  time: 1.4054  data: 0.0029  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.8823  acc: 0.5000  time: 1.5053  data: 0.0027  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.8881  acc: 0.5469  time: 1.4943  data: 0.0028  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.7410  acc: 0.6250  time: 1.5003  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.7030  acc: 0.6250  time: 1.4880  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5767  acc: 0.6875  time: 1.4324  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:00 (1.4728 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07813596725463867 uauc: 0.6499820242565835
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0029997825622558594 u-nDCG: 0.8557981037695963
rank_0 auc: 0.6626295766757306
Train: data epoch: [88]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.7087  time: 0.4897  data: 0.0000  max mem: 28728
Train: data epoch: [88]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.6392  time: 0.4979  data: 0.0000  max mem: 28728
Train: data epoch: [88] Total time: 0:00:24 (0.4994 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6039  acc: 0.5312  time: 1.0227  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7113  acc: 0.5156  time: 1.4252  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6462  acc: 0.6406  time: 1.5047  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6858  acc: 0.5938  time: 1.5029  data: 0.0025  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6690  acc: 0.5781  time: 1.5074  data: 0.0024  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6819  acc: 0.5469  time: 1.4704  data: 0.0024  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5355  acc: 0.7500  time: 1.4143  data: 0.0022  max mem: 28728
Evaluation Total time: 0:02:00 (1.4742 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07635259628295898 uauc: 0.6594580520661861
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.0032274723052978516 u-nDCG: 0.8606040922683557
rank_0 auc: 0.6602977050712879
Train: data epoch: [89]  [ 0/50]  eta: 0:00:24  lr: 0.000100  loss: 0.5703  time: 0.4893  data: 0.0000  max mem: 28728
Train: data epoch: [89]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.3855  time: 0.5102  data: 0.0000  max mem: 28728
Train: data epoch: [89] Total time: 0:00:25 (0.5069 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6014  acc: 0.5938  time: 1.0151  data: 0.0061  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7203  acc: 0.5781  time: 1.4123  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6722  acc: 0.6250  time: 1.5058  data: 0.0029  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7019  acc: 0.6094  time: 1.5048  data: 0.0026  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6839  acc: 0.6562  time: 1.4934  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6858  acc: 0.5625  time: 1.4687  data: 0.0028  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5028  acc: 0.8125  time: 1.4144  data: 0.0027  max mem: 28728
Evaluation Total time: 0:02:00 (1.4696 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07832527160644531 uauc: 0.6790466972378064
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003047466278076172 u-nDCG: 0.8664346850078342
rank_0 auc: 0.6678121982520726
Train: data epoch: [90]  [ 0/50]  eta: 0:00:25  lr: 0.000100  loss: 0.6687  time: 0.5068  data: 0.0000  max mem: 28728
Train: data epoch: [90]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.5966  time: 0.5004  data: 0.0000  max mem: 28728
Train: data epoch: [90] Total time: 0:00:24 (0.4978 s / it)
Evaluation  [ 0/82]  eta: 0:01:23  loss: 0.6146  acc: 0.5781  time: 1.0170  data: 0.0046  max mem: 28728
Evaluation  [16/82]  eta: 0:01:34  loss: 0.7139  acc: 0.5625  time: 1.4263  data: 0.0030  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.6611  acc: 0.6406  time: 1.5113  data: 0.0030  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.6700  acc: 0.5781  time: 1.5126  data: 0.0027  max mem: 28728
Evaluation  [64/82]  eta: 0:00:27  loss: 0.6664  acc: 0.6250  time: 1.5103  data: 0.0027  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6828  acc: 0.5156  time: 1.4709  data: 0.0026  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.5182  acc: 0.7500  time: 1.4149  data: 0.0025  max mem: 28728
Evaluation Total time: 0:02:01 (1.4785 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.0783085823059082 uauc: 0.6627969065311574
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003053426742553711 u-nDCG: 0.8597161044103949
rank_0 auc: 0.672059146046034
Train: data epoch: [91]  [ 0/50]  eta: 0:00:23  lr: 0.000100  loss: 0.6470  time: 0.4679  data: 0.0000  max mem: 28728
Train: data epoch: [91]  [49/50]  eta: 0:00:00  lr: 0.000100  loss: 0.3793  time: 0.4988  data: 0.0000  max mem: 28728
Train: data epoch: [91] Total time: 0:00:24 (0.4992 s / it)
Evaluation  [ 0/82]  eta: 0:01:22  loss: 0.6077  acc: 0.6406  time: 1.0111  data: 0.0041  max mem: 28728
Evaluation  [16/82]  eta: 0:01:33  loss: 0.7288  acc: 0.5781  time: 1.4214  data: 0.0026  max mem: 28728
Evaluation  [32/82]  eta: 0:01:13  loss: 0.7241  acc: 0.5625  time: 1.4907  data: 0.0028  max mem: 28728
Evaluation  [48/82]  eta: 0:00:50  loss: 0.7216  acc: 0.6562  time: 1.5049  data: 0.0030  max mem: 28728
Evaluation  [64/82]  eta: 0:00:26  loss: 0.6760  acc: 0.6562  time: 1.4920  data: 0.0029  max mem: 28728
Evaluation  [80/82]  eta: 0:00:02  loss: 0.6733  acc: 0.5781  time: 1.4700  data: 0.0030  max mem: 28728
Evaluation  [81/82]  eta: 0:00:01  loss: 0.4887  acc: 0.8125  time: 1.4180  data: 0.0029  max mem: 28728
Evaluation Total time: 0:02:00 (1.4691 s / it)
only one interaction users: 48
computed user: 239 can not users: 44
uauc for validation Cost: 0.07777738571166992 uauc: 0.6645784687349322
only one interaction users (for nDCG): 48
computed user (for nDCG): 239 can not users: 44
u-nDCG for validation Cost: 0.003095865249633789 u-nDCG: 0.8605971297670348
rank_0 auc: 0.6744312568943114
